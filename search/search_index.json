{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"RenamedTask2/","title":"Task 2: ThousandEyes Overview","text":"<p>Feel free to take a few minutes while the lab spins up and review the Getting Started with Endpoint Agents guide.</p> <p></p> <p></p> <p></p> <p>Connectivity is your business, but it\u2019s changing rapidly. Your brand is only as good as your network.\u200b Digital experience is how you are measured, but most of the path is outside your control (outside the core)\u200b What do you need to do about it?\u200b How can you understand digital experience to the things your customers are accessing\u200b and understand health of the Internet cloud and peering providers. Continue your journey to learn how ThousandEyes can help answer these questions and help solve your network and application acceess issues.</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>Now that you have a great background on ThousandEyes it's time to go back and verify the lab has started and login. Task 3.</p> <p>Also feel free to check our awesome TE Blog and Webex site.</p>"},{"location":"RenamedTask7a/","title":"Techniques for Finetuning LLMs","text":""},{"location":"RenamedTask7a/#introduction","title":"Introduction","text":"<p>In this lesson, we will examine the main techniques for fine-tuning Large Language Models for superior performance on specific tasks. We explore why and how to fine-tune LLMs, the strategic importance of instruction fine-tuning, and several fine-tuning methods, such as  Low-Rank Adaptation (LoRA), Supervised Finetuning (SFT). We also touch upon the benefits of the Parameter-Efficient Fine-tuning (PEFT) approach using Hugging Face's PEFT library, promising both efficiency and performance gains in fine-tuning.</p>"},{"location":"RenamedTask7a/#why-we-finetune-llms","title":"Why We Finetune LLMs","text":"<p>While pretrained Large Language Models (LLMs) provide a broad understanding of language, it doesn't equip them with the specialized knowledge needed for complex tasks. For instance, a pre-trained LLM may excel at generating text but encounter difficulties when tasked with sentiment analysis or even providing information from your own Knowledge base. This is where fine-tuning comes into play.</p> <p>Fine-tuning is the process of adapting a pretrained model to a specific task by further training it using task-specific data. For example, if we aim to make an LLM proficient in answering questions about Webex Calling or Webex CC, we would fine-tune it using a dataset comprising Webex question-answer pairs. This process enables the model to recalibrate its internal parameters and representations to align with the intended task, enhancing its capacity to address domain-specific challenges effectively.</p> <p>However, fine-tuning LLMs conventionally can be resource-intensive and costly. It involves adjusting  the parameters in the pretrained LLM models, which can number in the billions, necessitating significant computational power and time. Consequently, it's crucial to explore more efficient and cost-effective methods for fine-tuning, such as Low-Rank Adaptation (LoRA).</p>"},{"location":"RenamedTask7a/#a-reminder-on-instruction-and-conversational-finetuning","title":"A Reminder On Instruction and Conversational Finetuning","text":"<p>In Conversational fine tuning the model engages in a dialogue with the user, maintaining context over multiple turns.The interaction mimics a natural conversation, with the model responding in a way that feels like a human interlocutor.</p> <p>Instruction fine-tuning is a specific type of fine-tuning that grants precise control over a model's behavior. The objective is to train a Language Model (LLM) to interpret prompts as instructions rather than simply treating them as text to continue generating. </p>"},{"location":"RenamedTask7a/#introduction-to-efficient-finetuning-with-parameter-efficient-fine-tuning-peft","title":"Introduction to Efficient Finetuning with Parameter-Efficient Fine-tuning (PEFT)","text":"<p>Parameter-Efficient Fine-tuning (PEFT) approaches address the need for computational and storage efficiency in fine-tuning LLMs. Hugging Face developed the PEFT library specifically for this purpose. PEFT leverages architectures that only fine-tune a small number of additional model parameters while freezing most parameters of the pretrained LLMs, significantly reducing computational and storage costs.</p> <p>PEFT methods offer benefits beyond just efficiency. These methods have been proven to outperform standard fine-tuning methods, particularly in low-data situations, and provide improved generalization for out-of-domain scenarios. Furthermore, they contribute to the portability of models by generating tiny model checkpoints that require substantially less storage space compared to extensive full fine-tuning checkpoints.</p> <p>The PEFT library supports popular methods such as Low-Rank Adaptation (LoRA) and Prompt Tuning. </p>"},{"location":"RenamedTask7a/#a-reminder-of-the-techniques-for-finetuning-llms","title":"A Reminder of the Techniques For Finetuning LLMs","text":"<p>There are several techniques to make the finetuning process more efficient and effective:</p> <ul> <li> <p>Full Finetuning: This method involves adjusting all the parameters in the pretrained LLM models to adapt to a specific task. While effective, it is resource-intensive and requires extensive computational power, therefore it\u2019s rarely used. Not in our Scope</p> </li> <li> <p>Low-Rank Adaptation (LoRA): LoRA is a technique that aims to adapt LLMs to specific tasks and datasets while simultaneously reducing computational resources and costs. By applying low-rank approximations to the downstream layers of LLMs, LoRA significantly reduces the number of parameters to be trained, thereby lowering the GPU memory requirements and training costs. We\u2019ll also see QLoRA, a variant of LoRA that is more optimized and leverages quantization.</p> </li> </ul> <p>With a focus on the number of parameters involved in finetuning, there are multiple methods, such as:</p> <ul> <li> <p>Supervised Finetuning (SFT): SFT involves doing standard supervised finetuning with a pretrained LLM on a small amount of demonstration data. This method is less resource-intensive than full finetuning but still requires significant computational power. Scope of this lab</p> </li> <li> <p>Reinforcement Learning from Human Feedback (RLHF): RLHF is a training methodology where models are trained to follow human feedback over multiple iterations. This method can be more effective than SFT, as it allows for continuous improvement based on human feedback. We\u2019ll also see some alternatives to RLHF, such as Direct Preference Optimization (DPO), and Reinforcement Learning from AI Feedback (RLAIF).Not in our Scope</p> </li> </ul>"},{"location":"RenamedTask7a/#conclusion","title":"Conclusion","text":"<p>In this lesson, we've learned that while pretraining equips LLMs with a broad understanding of language, fine-tuning is necessary to specialize these models for complex tasks. We've looked into various fine-tuning techniques, including Full Finetuning, Low-Rank Adaptation (LoRA), Supervised Finetuning (SFT), and Reinforcement Learning from Human Feedback (RLHF). </p>"},{"location":"RnamedTask1/","title":"Task 1: Lab Login and Setup","text":"<p>Click to access the lab</p> <p>This lab requires a set of characters which will be aligned with roles to access ThousandEyes and Webex. Optional you can also register your Webex device on the platform that can be used with your demo.</p> <p>Click My Characters then click Add New Character as shown in the below image. You only need to create one character for the lab.</p> <p></p> <p>Click Create Character.  Note (They will be randomly created so yours may not match the below screenshot. Also you have an option to modify the names as per your preferences.)</p> <p></p> <p>Optional Step Click on the My Devices tab, select Add New Room Device, if you want your device to be available in the demo and thousandEyes agent installed on your device. Please remember its an optional step.</p> <p></p> <p>Make sure you are on your demo page Click Start Demo (you may have to use the back arrow to navigate back to the main overview page)</p> <p></p> <p>Next we need to provide a few details in order for the lab to be spun up.</p> <ul> <li>Audience: External</li> <li>External Type: Trade Show</li> <li>Tradeshow Name: Roadshow</li> <li>Demo Session Name: Enter your name \u2013 or leave it default</li> </ul> <p></p> <p>Click Next and then choose the character you created previously. (Note: this will be needed for automated session testing - AST)</p> <p></p> <p>Click Next and add a virtual workstation using the '+\" sign. This will be used to install the ThousandEyes Endpoint Agent (EPA) which can be configured to monitor web browser sessions, automtically monitor dynamic Webex meeting network connections and run scheduled tests in the background. Note you also have an option to install the ThousandEyes agent on your personal machine</p> <p></p> <p>Optional Step  If you have a Webex device select your device and click Next </p> <p></p> <p>Click Next select your duration and Click Start Demo as shown in the below screenshot.</p> <p></p> <p>This is roughly a 45 min lab but the access duration can be upto 3 days. It will take a few minutes for the lab to spin up. While this is occurring proceed on to the ThousandEyes Overview content and extra background information in Task 2.</p>"},{"location":"Task1/","title":"Pre-Requisites and Setup","text":""},{"location":"Task1/#google-collab-accessing-google-collab-and-creating-account","title":"Google Collab- Accessing Google Collab and creating account","text":"<p>Google Colab is a free, cloud-based platform that provides a convenient environment for running notebooks. If you want to create a machine learning model but don't have a computer that can handle the workload, Google Colab is the platform for you. In our lab, we will be using Google Colab to test and run our code. However, if you have your own Python environment and prefer to run the code on your local machine, please feel free to do so.</p> <p>Here are some reasons why using Google Colab can be beneficial for this lab:</p> <ul> <li>Free Access to GPUs and TPUs: Google Colab offers free access to powerful GPUs and TPUs, which can significantly accelerate the training and fine-tuning of machine learning models.</li> <li>No Setup Required: With Colab, there is no need to set up your local environment. Everything runs in the cloud, which saves time and avoids configuration issues.</li> <li>Easy Collaboration: Colab notebooks can be easily shared and collaborated on with team members, making it an ideal tool for collaborative projects.</li> <li>Integration with Google Drive: Colab integrates seamlessly with Google Drive, allowing you to save and manage your work conveniently.</li> <li>Pre-installed Libraries: Many popular machine learning libraries, including TensorFlow and PyTorch, come pre-installed in Colab, making it easy to start working on your projects immediately.</li> </ul>"},{"location":"Task1/#getting-started-with-google-colab","title":"Getting Started With Google Colab","text":"<p>To start working with Google Collaboratory Notebook you first need to log in to your Google account, then go to this link Google Colab</p> <ul> <li>Create a new Jupyter Notebook  </li> </ul> <p></p> <ul> <li>On creating a new notebook, it will create a Jupyter notebook with Untitled0.ipynb and save it to your google drive in a folder named Colab Notebooks. Now as it is essentially a Jupyter Notebook, all commands of Jupyter Notebooks will work here. </li> </ul> <p></p> <ul> <li> <p>There might be times when we need to fine-tune models or perform specific tasks that require changing the runtime environment in Colab. Google Colab offers different runtime environments that can be selected based on your requirements:</p> </li> <li> <p>Python Versions: You can select between different versions of Python (e.g., Python 2 or Python 3 )depending on the compatibility of the code and libraries. We will be using Python3 for our lab.</p> </li> <li> <p>Hardware Accelerators: Colab provides access to hardware accelerators, which can be particularly useful for intensive computations. You can choose between:</p> </li> </ul> <pre><code>None: No hardware acceleration, suitable for basic tasks.\n\nGPU: Accelerate your computations with a Graphics Processing Unit.\n\nTPU: Use a Tensor Processing Unit for even faster performance, especially beneficial for deep learning tasks.\n</code></pre> <ul> <li>Change Runtime Environment: Click the \u201cRuntime\u201d dropdown menu at the top of the Colab interface.</li> </ul> <p></p> <ul> <li> <p>Select \u201cChange runtime type\u201d: This will open a dialog box where you can configure the runtime environment.</p> </li> <li> <p>Select Python Version: Choose Python 3 from the \u201cRuntime type\u201d dropdown menu.</p> </li> <li> <p>Select Hardware Accelerator: From the \u201cHardware accelerator\u201d dropdown menu, choose  GPU, or TPU based on your needs.</p> </li> </ul> <p></p> <ul> <li> <p>Save Settings: Click \u201cSave\u201d to apply the changes.</p> </li> <li> <p>New Cell: Whenever you want to copy the code in Google Colab and run it, be sure to click on + Code to add a new code cell.</p> </li> </ul> <p></p> <ul> <li>Execute Code: Click the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\" while the cell is selected.</li> </ul> <p></p>"},{"location":"Task1/#notes-on-gpu-and-tpu-access","title":"Notes: On GPU and TPU Access:","text":"<p>While Google Colab offers free access to GPUs and TPUs, there are limitations. For more consistent access to high-performance GPUs and TPUs, you might need to subscribe to Colab Pro or Colab Pro+ accounts. These paid plans provide priority access to better hardware, longer runtimes, and more memory.</p>"},{"location":"Task1/#using-huggingface-hub-to-share-our-datasets","title":"Using Huggingface Hub to share our Datasets","text":"<p>In this lab, we will be utilizing the Hugging Face Hub to load our custom datasets. Hugging Face provides an extensive repository of datasets that can be easily integrated into your machine learning workflows. For the purposes of this lab, we will demonstrate how to access/upload and use our custom datasets effectively.</p> <p>However, when fine-tuning models in your own work environment, especially if you are using private data, there are important considerations to keep in mind:</p> <ul> <li>Private Datastores: If you are working with proprietary or sensitive data, it is crucial to use your organization's secure datastores. Ensure that all data handling complies with your organization's data privacy policies and regulations.</li> <li>Hugging Face Datasets: If you prefer to use Hugging Face for dataset storage and management, make sure to mark your datasets as private. This setting ensures that your data cannot be accessed by anyone outside your organization, maintaining the confidentiality and integrity of your information. Please refer to Huggingface documentation for more info.</li> </ul> <p>Few more Condsideration</p> <ul> <li>Upload Dataset: When uploading your dataset to Hugging Face, choose the appropriate privacy settings. You can set your dataset to private during the upload process.</li> <li>Check Permissions: Regularly review and manage the permissions of your datasets to ensure they remain private and secure.</li> <li>Collaborator Access: If you need to share the dataset with specific team members, use the Hugging Face interface to grant access to trusted collaborators only.</li> </ul> <p>By following these guidelines, you can ensure that your data remains secure while leveraging the powerful tools and resources provided by Hugging Face. This approach not only enhances your workflow efficiency but also upholds the best practices in data security and privacy.</p>"},{"location":"Task1/#accessing-hugging-face-hub-and-creating-account","title":"Accessing Hugging Face Hub and creating account","text":"<p>Hugging Face can be accessed by browsing to huggingface.co</p> <p></p>"},{"location":"Task1/#signing-up","title":"Signing up","text":"<ul> <li>Browse to Hugging Face home page and click on Sign up. Follow the instructions as per below images</li> </ul> <ul> <li>Please check your email address for a confirmation link and click to verify your account </li> </ul> <ul> <li>Organization Creation (Optional): While you can upload datasets and fine-tune models directly on Hugging Face without creating an organization, you have the option to create an organization on Hugging Face. This can be particularly useful for team collaboration, as it allows you to upload all your datasets and models in one centralized location.</li> </ul> <ul> <li>At this stage, you will see no models or datasets created under your account.</li> </ul> <ul> <li>Access Your Models and Datasets: The same can be accessed by clicking your profile picture on the top right corner of the Hugging Face website. This will take you to your personal dashboard where you can view and manage your models and datasets.</li> </ul>"},{"location":"Task1/#hugging-face-api-keys","title":"Hugging Face API Keys","text":"<p>Create an API Key: As we will be uploading our datasets to the Hugging Face Hub, we need to create an API key for our account. This API key will be used to authenticate and interact with the Hugging Face services programmatically.</p> <p>you can browse to huggingface API Key</p> <p>or </p> <p>Click on your profile picture &gt; Settings &gt; Access Tokens</p> <p></p> <p></p> <p>Under the \"Access Tokens\" section, click on \"Create new token.\" You will see options to select the token type and provide a token name. For example, you might name your token \"Webexone\" and select the approperiate permissions.  </p> <ul> <li> <p>fine-grained: tokens with this role can be used to provide fine-grained access to specific resources, such as a specific model or models in a specific organization. This type of token is useful in production environments, as you can use your own token without sharing access to all your resources.</p> </li> <li> <p>read: tokens with this role can only be used to provide read access to repositories you could read. That includes public and private repositories that you, or an organization you\u2019re a member of, own. Use this role if you only need to read content from the Hugging Face Hub (e.g. when downloading private models or doing inference).</p> </li> <li> <p>write: tokens with this role additionally grant write access to the repositories you have write access to. Use this token if you need to create or push content to a repository (e.g., when training a model or modifying a model card).</p> </li> </ul> <p>As we have a lab envoirnment we will be using the \"Write\" permission. This token will have read and write access to all your resources and can make calls to inference API on your behalf, as shown in the image below.</p> <p></p> <p>Save and Secure the Token: Once the token is generated, save it securely. This token will be required for accessing and managing your datasets via the API. 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</p> <p></p>"},{"location":"Task1/#accessing-hugging-face-api-in-google-colab","title":"Accessing Hugging Face API in Google Colab","text":"<ul> <li>Open the Google Colab notebook and navigate to the new \u201cSecrets\u201d section in the sidebar.</li> </ul> <ul> <li> <p>Click on \u201cAdd a new secret.\u201d Enter the name example: HF_TOKEN and value of the secret. Note: The name is permanent once set. </p> </li> <li> <p>The list of secrets is global across all your notebooks.</p> </li> <li> <p>Use the \u201cNotebook access\u201d toggle to grant or revoke access to a secret for each notebook.</p> </li> </ul> <p></p> <p> Optional Steps below  </p>"},{"location":"Task1/#incorporating-secrets-into-your-code-we-will-use-it-later-in-our-lab","title":"Incorporating Secrets into Your Code - We will use it later in our lab","text":"<ul> <li>To use a secret in your notebook, use the following code snippet</li> </ul> <pre><code>from google.colab import userdata\nmy_secret_key = userdata.get('HF_TOKEN')\n</code></pre> <ul> <li>Replace  with your secret's name."},{"location":"Task1/#using-secrets-as-environment-variables-optional-step-we-will-use-it-later-in-our-lab","title":"Using Secrets as Environment Variables -  Optional Step , we will use it later in our lab","text":"<ul> <li>For Python modules requiring API keys as environment variables, use the below snippet:</li> </ul> <pre><code># Import Colab Secrets userdata module\n\nfrom google.colab import userdata\nimport os\n\n# Set other API keys similarly\nos.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n</code></pre>"},{"location":"Task2/","title":"AI/ML Revolution Unveiled","text":""},{"location":"Task2/#different-types-of-ai","title":"Different Types of AI","text":"<p>Remember: Subset of AI is ML and kind of ML is Gen-AI . LLM e.g GPT are subset of Gen-AI </p>"},{"location":"Task2/#neural-network","title":"Neural Network","text":"<p> Note: The way nodes are connected called weights </p> <p></p> <p></p> <p></p> <p> Note: Neural network rely on training data to learn and improve their accuracy over time. We used supervised learning to train the algorithm.  There are multiple types of Neural network other than the Feed forward network that we have defined here. Example: CNN: Convolutional Neural Network - Unique architecture for identifying patterns like image recognition, or RNN: Recurrent neural network, that uses time series data to make prediction about future events like sales forecasting. </p>"},{"location":"Task20/","title":"Logging Out and Ending the Lab Session","text":"<p>Close out of the Chrome Browser Close out Webex Close the Windows VM browser tab Log out of the ThousandEyes and close the incognito browser</p> <p>In the Webex Demo Toolbox browser tab scroll to the bottom and click End</p> <p></p> <p>Click End Session in the pop up to shutdown the lab and close the tab</p> <p></p> <p>Time to wrap things and with the Lab Conclusion.</p>"},{"location":"Task3/","title":"Tokenization","text":"<ul> <li>Language models have a limit on how much text they can handle at once, known as their context window. While these limits are expanding, research shows that LLM's often perform better when provided with less, but more relevant, information. However, selecting the most relevant information is straightforward for humans but challenging for computers. </li> </ul> <p>A common approach to manage large amounts of data is to break it down into smaller, more manageable parts a process often referred to as Tokenization or Chunking. Tokenization is a key step in this process, where raw text is divided into smaller units, called tokens, which can then be processed by a neural network.</p> <p></p> <p>In order to do this you need to pick a chunk strategy. Just to name a few:</p> <ul> <li> <p>Word-Based: A simple and straightforward method that most of us would propose is to use word-based tokens, splitting the text by spaces.</p> </li> <li> <p>Character based tokenization: Individual words are considered as tokens . Lot of computing resources needed as now e.g for a 3 word serentence where you might need 3 tokens now 15 \u2013 20 tokens needed </p> </li> <li> <p>Sentence Based: We need a .(fullstop) for it to work </p> </li> </ul> <p> Note: We've all heard of GPT and OpenAI. They utilize a tokenization method called Byte Pair Encoding (BPE), which is a middle ground between word-based and character-based tokenization. In BPE, words are broken down into smaller character sequences that the model encountered during training, allowing it to make informed predictions. </p>"},{"location":"Task3/#why-we-need-tokenization-or-text-splitting","title":"Why we need Tokenization or Text Splitting?","text":"<p>Historically, applications perform better when they are provided with your own data. However, you can't feed unlimited data to your LLMs due to two key limitations:</p> <ul> <li> <p>Context window limit: LLMs have a finite context window for processing data.</p> </li> <li> <p>Signal-to-noise ratio (SNR): LLMs perform better when the SNR is high, meaning the information provided is useful, relevant, and clear. Clear, unambiguous instructions help the model deliver more accurate and detailed results, while ambiguous or complex input can lead to less accurate or incomplete outputs.</p> </li> </ul> <p>As noted, chunking or splitting refers to breaking your data into smaller, manageable pieces.</p> <p></p>"},{"location":"Task3/#task-1-log-into-the-lab-environment","title":"Task 1: Log into the Lab Environment","text":"<ul> <li>Open Google Colab and create a new notebook. Click on \"File\" &gt; \"New notebook\". Please refer to the following section to create Google Colab account.</li> </ul> <ul> <li>Make sure you are connected to a runtime. For this task, you can use the CPU as the runtime environment.</li> </ul> <p>Reminder: Whenever you want to copy the code in Google Colab and run it, be sure to click on + Code to add a new code cell.</p> <p></p> <p>Reminder: Click the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\" while the cell is selected.</p> <p></p>"},{"location":"Task3/#manual-testing-for-chunking","title":"Manual testing for Chunking","text":"<p>We will create Chunks of 35 charectors, so first 35 charectors as chunk 1 , next 35 charectors chunk2 and so on </p> <pre><code># Manual Splitting\ntext = \"\"\"WebexOne is an annual in-person and virtual event that takes place over four days. It\u2019s an event focused on AI collaboration and customer experience.  \nIt features a range of activities such as insightful breakout sessions, technical training courses, hands-on labs, inspiring keynotes, epic entertainment, a solutions showcase and expo, customer awards, meet the experts, 1:1 executive meetings, a partner program, and more!\"\"\"\n\n# Create a list that will hold your chunks\nchunks = []\n\nchunk_size = 35 \n\n# Run through the a range with the length of your text and iterate every chunk_size you want\nfor i in range(0, len(text), chunk_size):\n    chunk = text[i:i + chunk_size]\n    chunks.append(chunk)\n\nprint(chunks)\n</code></pre> <p></p> <p>Note:  The text contained a total of 422 characters, divided into 13 chunks. Problem with the above chunking technique is that it got split at 'r'. How we know when to chunk . Before we look into that. Lets look into Langchain Splitter </p>"},{"location":"Task3/#langchain-text-splitter","title":"LangChain Text Splitter","text":"<ul> <li>Let's retrieve the langchain library from the Python Package. In the example below, we'll configure the chunk_overlap parameter, which ensures that our chunks are blended together\u2014meaning the end of chunk 1 will overlap with the beginning of chunk 2.</li> </ul> <pre><code>!pip install langchain\n</code></pre> <pre><code>text = \"\"\"WebexOne is an annual in-person and virtual event that takes place over four days. It\u2019s an event focused on AI collaboration and customer experience.  \nIt features a range of activities such as insightful breakout sessions, technical training courses, hands-on labs, inspiring keynotes, epic entertainment, a solutions showcase and expo, customer awards, meet the experts, 1:1 executive meetings, a partner program, and more!\"\"\"\n</code></pre> <p><pre><code>from langchain.text_splitter import CharacterTextSplitter\n\ntext_splitter = CharacterTextSplitter(chunk_size=35, chunk_overlap=3, separator='', strip_whitespace=False) # seprate means you splt by charector\n\na = text_splitter.create_documents([text])\n\nprint(a)\n</code></pre> Note: Seprators are charectors sequence you wanna split on. </p> <p></p>"},{"location":"Task3/#recursive-charector-text-splitting","title":"Recursive Charector Text Splitting","text":"<p>In the previous example, when we used Character Splitting, we split the text based on a fixed number of characters. Specifically, we divided the text into chunks of 35 characters each.</p> <p>However, with Recursive Text Splitting (RTS), the process is more dynamic and considers the physical structure of the text to determine the appropriate chunk size.</p> <p>Here\u2019s how RTS works:</p> <ul> <li> <p>Instead of relying on a static number of characters, RTS examines the structure of the document.</p> </li> <li> <p>It begins by identifying the largest logical divisions, such as paragraphs, and splits the text at each double newline (indicating paragraph breaks).</p> </li> <li> <p>If any of these chunks are still too large, RTS will then move to the next level of separation, which is single newlines (often indicating sentences or list items).</p> </li> <li> <p>If necessary, it will continue to break down the text further, using spaces and eventually individual characters as separators.</p> </li> </ul> <p>With RTS, you don\u2019t need to manually specify the chunk size by character count. You simply pass your text to the RTS process, and it will intelligently determine how to split the text based on its structure, resulting in chunks that are logically organized and more contextually meaningful.</p> <p></p> <pre><code>text = \"\"\"WebexOne is an annual in-person and virtual event that takes place over four days. It\u2019s an event focused on AI collaboration and customer experience.  \nIt features a range of activities such as insightful breakout sessions, technical training courses, hands-on labs, inspiring keynotes, epic entertainment, a solutions showcase and expo, customer awards, meet the experts, 1:1 executive meetings, a partner program, and more!\"\"\"\n</code></pre> <p><pre><code>from langchain.text_splitter import RecursiveCharacterTextSplitter\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size = 35, chunk_overlap = 0)\n# how many chunks we have \nprint(len(text_splitter.create_documents([text])))\n\ntext_splitter.create_documents([text])\n</code></pre> Note: We avoid splitting in the middle of words by using spaces as one of the separators, ensuring that each chunk ends on a complete word. This is crucial because RCS (Recursive Character Splitting) helps maintain the context within sentences by keeping related words together.</p> <p></p> <p>Note:If you're new to AI, I would personally recommend starting with Recursive Text Splitting (RTS). </p>"},{"location":"Task3/#document-level-splitting","title":"Document Level Splitting","text":"<p>So far, we've been working with splitting regular documents. But what if we have markdown files or  PDF or Python documentation? There's a better way to handle those cases, and that's where specialized document splitting comes into play.</p>"},{"location":"Task3/#pdf-with-table","title":"PDF with table","text":"<p>PDFs often contain tables and other structured data that can be challenging to split accurately using character-based methods. For PDFs, it's important to extract and chunk all elements, including tables, effectively. We'll accomplish this using the Unstructured library, which is specifically designed for handling such tasks. If you have a large collection of PDFs, Unstructured is an excellent tool to manage them efficiently.</p> <p></p> <ul> <li>Install relevant libraries for Unstructured</li> </ul> <pre><code>!pip install scikit-learn langchain_community unstructured[all-docs] unstructured pdfminer pdfminer.six pdf2image pillow_heif opencv-python unstructured_inference pytesseract unstructured_pytesseract python-dotenv openai\n</code></pre> <p></p> <pre><code>!apt-get install -y poppler-utils &amp;&amp; apt-get install -y tesseract-ocr\n</code></pre> <p></p> <ul> <li> <p>Let's load our PDF files into Google Colab. For this example, we can use the Cisco Financial Results. Please Download the file here as we will be using in the next step.</p> </li> <li> <p>Within Google Colab, Click on Folder and create a new folder called \"data\"</p> </li> </ul> <p></p> <ul> <li>Click on [...], select Upload</li> </ul> <p></p> <ul> <li>Choose your CiscoReport.pdf file and click Open</li> </ul> <p></p> <ul> <li>We'll use the following code from the Unstructured library to demonstrate how tables can be extracted</li> </ul> <pre><code>import os\nfrom unstructured.partition.pdf import partition_pdf\nfrom unstructured.staging.base import elements_to_json\n\n# Let's load up our PDF and then partition it.\nfilename = \"/content/data/CiscoReport.pdf\"# Use relative path since the file is in the same directory\n\n# Extracts the elements from the PDF\nelements = partition_pdf(\n    filename=filename,\n    extract_images_in_pdf=True,\n    strategy=\"hi_res\",\n    infer_table_structure=True,\n    hi_res_model_name=\"yolox\"\n)\n\n# Let's look at our elements\nprint(elements)\n</code></pre> <p></p> <ul> <li>Lets grab element 37 as its the one where our table is</li> </ul> <p><pre><code>elements[37].metadata.text_as_html\n</code></pre> OUTPUT</p> <pre><code>'&lt;table&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Revenue&lt;/th&gt;&lt;th&gt;$8.51 - $8.53 Billion&lt;/th&gt;&lt;th&gt;$34.5 - $34.7 Billion&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Y/Y Growth&lt;/td&gt;&lt;td&gt;~10%&lt;/td&gt;&lt;td&gt;~10%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;FX Impact)&lt;/td&gt;&lt;td&gt;no impact&lt;/td&gt;&lt;td&gt;no impact&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GAAP Operating Margin&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;~11.4%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Non-GAAP Operating Margin\u2019)&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;~28.0%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GAAP Earnings per Share?)&lt;/td&gt;&lt;td&gt;$0.79 - $0.80&lt;/td&gt;&lt;td&gt;$2.67 - $2.69&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Non-GAAP Earnings per Share()&lt;/td&gt;&lt;td&gt;$1.89 - $1.90&lt;/td&gt;&lt;td&gt;$7.41 - $7.43&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Operating Cash Flow Growth (Y/Y)\u00b0)&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;16% - 17%&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Current Remaining Performance Obligation Growth (Y/Y)&lt;/td&gt;&lt;td&gt;~10%&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;'\n</code></pre> <ul> <li>Tables are straightforward for humans to read, but they aren't as easy for language models to interpret. Language models are typically trained on HTML tables, so when you pass HTML-formatted tables to an LLM, it will better understand the structure and content. You can paste the HTML into an HTML viewer to see how it looks.</li> </ul> <p></p> <p>Note: That's how you handle tables within a PDF.</p>"},{"location":"Task3/#multi-modal-text-images","title":"Multi-Modal (Text + images)","text":"<p>What if there are images within a PDF or other documents? How can you extract them? We'll use the Unstructured library again to handle this.</p>"},{"location":"Task3/#extract-images-within-pdf","title":"Extract Images within PDF","text":"<ul> <li>Install relevant libraries</li> </ul> <pre><code>from typing import Any\nfrom pydantic import BaseModel\nfrom unstructured.partition.pdf import partition_pdf  \n</code></pre> <pre><code>filepath = \"/content/data/CiscoReport.pdf\"\n# Get elements\nraw_pdf_elements = partition_pdf(\n    filename=filepath,\n\n    # Using pdf format to find embedded image blocks\n    extract_images_in_pdf=True,\n\n    # Use layout model (YOLOX) to get bounding boxes (for tables) and find titles\n    infer_table_structure=True,\n\n    # Specifies the strategy to be used for chunking the text. In our case, it will chunk the text based on titles found in the document.\n    chunking_strategy=\"by_title\",\n\n    # Sets a hard limit on the number of characters allowed in each chunk. \n    max_characters=4000,\n    # This function will attempt to create a new chunk after every 3,800 characters, allowing some flexibility while chunking.\n    new_after_n_chars=3800,\n    # If a chunk has fewer than 2,000 characters, the function will \n    # attempt to combine it with neighboring text blocks to create a larger, more meaningful chunk.\n    combine_text_under_n_chars=2000\n)\n</code></pre> <p>Note: You'll notice that a folder called 'figures' is created, where all the extracted images are stored. To make these images more useful, we can generate embeddings for them, which can later be used for semantic search. Typically, embedding models are specialized\u2014they either handle text or images, but not both. This means the vector lengths won't align, and using different models for text and image embeddings can complicate similarity searches. However, the CLIP model can generate embeddings for both images and text, making it a versatile option for this purpose. To simplify things, we can first create a text summary for each image, and then generate embeddings based on those summaries. This approach allows us to leverage text-based semantic search while still incorporating the visual information from the images. </p> <p></p> <p>Note: After extracting images from a PDF or any other source, you can use the below method to send them to a multimodal model like GPT-4o to understand and generate insights about the images. This approach allows you to combine textual and visual data for a richer understanding of the content.</p>"},{"location":"Task3/#set-openai-token-multimodal","title":"Set OpenAI token - MultiModal","text":"<p>Note: First, create an account from the OpenAI official website.</p> <p>https://platform.openai.com/api-keys</p> <ul> <li>Create a new project API key by browsing to API Keys web page. Select Create new secret key. The API key is automatically generated. Save the APi Key as we will be using it in the later steps .</li> </ul> <p></p>"},{"location":"Task3/#prepare-your-python-envoirnment-using-hugging-face","title":"Prepare your python envoirnment using Hugging Face","text":"<ul> <li>Within your existing Google Colab notebook navigate to the new \u201cSecrets\u201d section in the sidebar.</li> </ul> <ul> <li> <p>Click on \u201cAdd a new secret.\u201d Enter the name example: OPENAI_API_KEY and value of the secret(the API key created above). Note: The name is permanent once set. </p> </li> <li> <p>The list of secrets is global across all your notebooks.</p> </li> <li> <p>Use the \u201cNotebook access\u201d toggle to grant or revoke access to a secret for each notebook.</p> </li> </ul> <p></p>"},{"location":"Task3/#lets-import-and-load-the-envoirnment-variables","title":"Lets import and load the envoirnment variables","text":"<pre><code>from langchain.chat_models import ChatOpenAI\nfrom langchain.schema.messages import HumanMessage\nimport os\nfrom dotenv import load_dotenv\nfrom PIL import Image\nimport base64\nimport io\nload_dotenv()\n</code></pre>"},{"location":"Task3/#incorporating-secrets-into-your-code-we-will-use-it-later-in-our-lab","title":"Incorporating Secrets into Your Code - We will use it later in our lab","text":"<pre><code>import os\nfrom google.colab import userdata\nos.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\nllm = ChatOpenAI(model=\"gpt-4o\")\n</code></pre>"},{"location":"Task3/#function-to-convert-image-to-base64","title":"Function to Convert Image to Base64:","text":"<p><pre><code># Function to convert image to base64\ndef image_to_base64(image_path):\n    with Image.open(image_path) as image:\n        buffered = io.BytesIO()\n        image.save(buffered, format=image.format)\n        img_str = base64.b64encode(buffered.getvalue())\n        return img_str.decode('utf-8')\n\nimage_str = image_to_base64(\"/content/figures/figure-1-1.jpg\")\n</code></pre> Note: This is the image that was extracted from our data and saved in the figures folder.</p> <p><pre><code>print(image_str)\n</code></pre> Output: Our base64-encoded string </p> <pre><code>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\n</code></pre>"},{"location":"Task3/#initializing-the-multimodal-and-sending-the-image-to-gpt-4o-for-analysis","title":"Initializing the Multimodal and sending the Image to GPT-4o for Analysis:","text":"<pre><code>chat = ChatOpenAI(model=\"gpt-4o\", max_tokens=1024)\n\nmsg = chat.invoke(\n    [\n        HumanMessage(\n            content=[\n                {\"type\": \"text\", \"text\": \"Please give a summary of the image provided. Be descriptive\"},\n                {\"type\": \"image_url\", \"image_url\": {\n                    \"url\": f\"data:image/jpeg;base64,{image_str}\"\n                    }\n                 },\n            ]\n        )\n    ]\n)\n</code></pre> <ul> <li>Retrieving the Response:</li> </ul> <p><pre><code>msg.content\n</code></pre> Output: The response from the model is stored in msg.content, which will contain the descriptive summary of the image. </p> <p>The image is the logo of Cisco Systems, Inc., commonly known as Cisco. The logo features the company name \"cisco\" written in lowercase letters in a distinct, modern sans-serif font. Above the text, there is a series of vertical bars of varying heights, which is stylized to resemble the Golden Gate Bridge. The logo is rendered in a light blue color. The design is clean, professional, and easily recognizable, reflecting Cisco's identity as a major tech company specializing in networking hardware, telecommunications equipment, and other high-technology services and products.</p> <p>Note: The description of your image may vary depending on the image retrieved.</p>"},{"location":"Task4/","title":"Task 4: Embeddings and Vector Database","text":"<ul> <li>Embeddings and vector databases are essential if you are building any kind of AI product.</li> </ul>"},{"location":"Task4/#what-are-embeddings","title":"What are embeddings?","text":"<p>Embeddings are basically data.</p> <p></p> <p>That are converted into array of numbers called vectors thats contain pattern of relationship, and can be used for similarity search.</p> <p></p> <p>Let me explain this concept using a 2D graph. In this graph, words like \"Webex\" and \"collaboration\" are often used in similar context, so their embeddings essentially vector representations are positioned close to each other. These vectors are numerical arrays that computers can easily interpret.  </p> <p>The advantage of using vectors is that you can find similar items by calculating the distances between their vectors, a process known as nearest neighbor search. However, simply storing these embeddings isn't enough. Performing queries across thousands of vectors can be incredibly slow. To overcome this, these vectors also need to be indexed in the vector database.</p> <p> Note: In reality vectors can have hundred of dimensions </p> <p></p> <p>Similarly, images are also broken into vectors, which are arrays of numbers that machines can process. Once these embeddings (both for words and images) are generated, they are stored in a specialized database known as a vector database.</p> <p></p> <p>There are numerous embedding models available, such as Google's Word2Vec, CLIP (Contrastive Language\u2013Image Pretraining), and even those provided by OpenAI, which offer excellent capabilities for generating embeddings. However, the challenge is that these models don't include tools for storing and managing those embeddings. That's where vector databases become essential.</p> <p></p> <p> Note: In this lab session, we will be using OpenAI embeddings. More info can be found here </p>"},{"location":"Task4/#why-vector-databases-when-we-have-relational-dbs","title":"Why Vector Databases when we have relational DB's?","text":"<p>Around 80% of the data we encounter is unstructured, including social media posts, images, and videos. This type of data doesn\u2019t easily fit into traditional relational databases, which is where vector databases come into play.</p> <p></p>"},{"location":"Task4/#understanding-working-of-embeddings-and-vector-databases","title":"Understanding working of Embeddings and Vector Databases","text":""},{"location":"Task4/#practical-example-of-embedding-techniques-using-postman","title":"Practical Example of Embedding Techniques Using Postman","text":""},{"location":"Task4/#set-openai-token","title":"Set OpenAI token","text":"<p>Note: If you\u2019ve already obtained the token in previous steps, you can skip this section </p> <p>Note: First, create an account from the OpenAI official website.</p> <ul> <li>Create a new project API key by browsing to API Keys web page. Select Create new secret key. The API key is automatically generated. Save the APi Key as we will be using it in the later steps .</li> </ul> <p></p> <p>Note: We will use the OpenAI key in Postman to generate embeddings.</p>"},{"location":"Task4/#login-to-postman","title":"Login to Postman","text":"<p>If you haven't installed Postman on your machine yet, you can download it from the following link</p> <p>As we will be using embedding APIs to create an embedding vector that represents our input text, more information can be found at the following link</p> <p>The POST request we will be using:</p> <p><pre><code>https://api.openai.com/v1/embeddings\n</code></pre> * Open Postman, create a new request by pressing +. Select POST as your request and enter the request url  </p> <p></p> <ul> <li>Click on the Headers tab and enter the Following creds</li> </ul> <pre><code>Authorization: Bearer &lt;replace with your openAi API key&gt;\nContent-Type : application/json\n</code></pre> <p></p> <ul> <li>In this lab, we will be using the text-embedding-ada-002 model, but feel free to use any other embedding model of your choice.</li> </ul> <p></p> <ul> <li>In Postman, click on the \"Body\" tab, enter the following information, and then press \"Send.\"</li> </ul> <pre><code>{\n    \"input\": \"What is WebexOne 2024? WebexOne is an annual in-person and virtual event that takes place over four days. It\u2019s an event focused on AI collaboration and customer experience, and it features a range of activities such as insightful breakout sessions, technical training courses, hands-on labs, inspiring keynotes, epic entertainment, a solutions showcase and expo, customer awards, meet the experts, 1:1 executive meetings, a partner program, and more! \",\n    \"model\": \"text-embedding-ada-002\"\n}\n</code></pre> <p></p> <ul> <li>You will receive a 200 OK message, confirming success, and you'll notice that our text has been converted into embeddings (vectors). In the upcoming steps, I will show you on how to manually save this information in a vector database.</li> </ul> <p></p> <p>Note: Text embedding models, convert text into numerical data(embeddings) that represent text meaning.</p>"},{"location":"Task4/#inserting-values-in-vector-database","title":"Inserting values in Vector Database","text":"<p>We have a variety of databases available. In the upcoming step, I will demonstrate how to use SingleStore as a vector database and save our embeddings there.</p> <p>Note: This manual step is simply to illustrate how embeddings are stored in vector databases.</p> <p></p> <p>Note: We will create a Free account on SingleStoresince it provides some credits to set up a trial account.</p> <p></p> <ul> <li>I\u2019m choosing to create an account using Google, but feel free to use any other method that works for you.</li> </ul> <p></p> <ul> <li>Select Continue</li> </ul> <p></p> <p></p> <p></p> <ul> <li>Click on New Deployment</li> </ul> <p></p> <ul> <li>Give your workspace a name, keep all other settings at their default, and click \"Next.\"</li> </ul> <p></p> <ul> <li>Then, leave everything as is and click on \"Create Workspace.\"</li> </ul> <p></p> <p></p> <ul> <li>Now we can create a database</li> </ul> <p></p> <p></p> <ul> <li>Click on Database tab</li> </ul> <p></p> <p></p> <ul> <li>Return to the home screen and navigate to Develop &gt; Data Studio. Open the SQL Editor.</li> </ul> <p></p> <ul> <li>Be sure to select your workspace and database.</li> </ul> <p></p> <ul> <li>Run a SQL command to create a table - Press Run</li> </ul> <p><pre><code>create table if not exists myvectortable (\ntext TEXT,\nvector BLOB\n);\n</code></pre> </p> <ul> <li>You can navigate to the Databases tab and verify that the table has been created.</li> </ul> <p></p> <ul> <li> <p>Let's copy the embeddings we generated earlier using Postman so that we can insert them into our database.</p> </li> <li> <p>To proceed, copy the input text and  all the embedding values, including the square brackets [], as shown in the image. These will be used for insertion into our database.</p> </li> </ul> <p></p> <ul> <li>Let's head back to our SQL editor and insert the values into our database. Once done press \"Run\"</li> </ul> <p><pre><code>insert into myvectortable (text ,vector) values (\"your_input_text\", JSON_ARRAY_PACK(\"your_embeddings\"))\n</code></pre> In this query:</p> <pre><code>* Replace \"your_input_text\" with the input values from Postman.\n\n* Replace your_embeddings with the embeddings you copied earlier, including the square brackets [].\n</code></pre> <pre><code>insert into myvectortable (text ,vector) values (\"What is WebexOne 2024? WebexOne is an annual in-person and virtual event that takes place over four days. It\u2019s an event focused on AI collaboration and customer experience, and it features a range of activities such as insightful breakout sessions, technical training courses, hands-on labs, inspiring keynotes, epic entertainment, a solutions showcase and expo, customer awards, meet the experts, 1:1 executive meetings, a partner program, and more!\", JSON_ARRAY_PACK(\"[\n                -0.0042485874,\n                -0.02296605,\n                0.011213377,\n                0.01114761,\n                -0.027280405,\n                0.0023528363,\n                -0.004350527,\n                0.0043768343,\n                -0.00068562734,\n                -0.011660597,\n                0.010397859,\n                0.018730614,\n                -0.0158763,\n                -0.013469206,\n                0.0026997605,\n                -0.00003768792,\n                0.014850326,\n                -0.03183152,\n                0.0026175508,\n                -0.0459321,\n                -0.0055803815,\n                -0.008247258,\n                -0.011713211,\n                0.0006169824,\n                -0.017112732,\n                -0.002885554,\n                -0.004113764,\n                -0.01348236,\n                ........\n            ]\"))\n</code></pre> <ul> <li>After running the above command, you will see that our table now contains both the input text and the corresponding embeddings.</li> </ul> <p></p>"},{"location":"Task4/#retrieving-values-from-the-vector-database","title":"Retrieving Values from the Vector Database","text":"<ul> <li> <p>Searching the vector database is quite simple. Example: we want to find anything related to WebexOne. To do this, we'll create embeddings for our query, \"Is WebexOne an annual event?\" and then search the vector database to find matches against the existing embeddings.</p> </li> <li> <p>Let's open Postman and create an embedding for our question. Be sure to click on \"Send.\"</p> </li> </ul> <p></p> <ul> <li>Let's head over to the SQL editor and run a query for our search.</li> </ul> <p><pre><code>select text,dot_product(vector,JSON_ARRAY_PACK(\"[your_embeddings]\")) as score\nfrom myvectortable\norder by score desc\nlimit 5;\n</code></pre> * In this query:     * Replace your_embeddings with the embeddings you copied earlier, including the square brackets [] for the question.</p> <pre><code>select text,dot_product(vector,JSON_ARRAY_PACK(\"[\n                -0.0015118581,\n                -0.021267666,\n                0.023597047,\n                -0.0072638104,\n                -0.02286653,\n                0.005909599,\n                -0.026119394,\n                -0.010268575,\n                0.0052169873,\n                -0.009551842,\n                0.024065679,\n                0.020178782,\n                0.015464887,\n                0.016815653,\n                -0.016333235,\n                -0.0006641838,\n                0.018069934,\n                -0.010564916,\n                0.007911626,\n                -0.026367495,\n                -0.0019417254,\n                -0.005547787,\n                -0.012604848,\n                0.0003715036,\n                -0.013962504,\n                0.011729606,\n                -0.00078737224,\n                -0.011881223,\n                0.007815143,\n                0.009992908,\n                0.020316616,\n                -0.0032580325,\n                -0.0066401153,\n                0.0097310245,\n                -0.0028652078,\n                -0.008145943,\n                -0.0074843434,\n                ........\n            ]\")) as score\nfrom myvectortable\norder by score desc\nlimit 5;\n</code></pre> <p></p> <p>Note: You\u2019ll be able to see the success of the vector database\u2014higher scores indicate better matches for the answer.</p>"},{"location":"Task4/#conclusion","title":"Conclusion","text":"<p>In summary, vector databases allow LLMs to have long-term memory. In this section, we explored how to use embeddings and vector databases by generating embeddings with the OpenAI API through Postman. After setting up a free SingleStore account, embeddings were stored in a vector database. The process included creating an embedding for a query, searching the database, and confirming that it effectively retrieved relevant information. This demonstrated how vector databases can efficiently manage and query embeddings, making it easier to find relevant information based on the data stored.</p>"},{"location":"Task5/","title":"Task 5: Configure ThousandEyes Automated Session tests and EPA Monitoring","text":""},{"location":"Task5/#set-up-automated-session-tests-for-webex-meetings-optional-step","title":"Set up Automated Session tests for Webex Meetings - Optional Step","text":"<p>Automated Session Tests enable the Endpoint Agents installed on your  workstations to monitor and identify network connections between a user\u2019s application and the destination node (Webex); thereby, removing the ambiguity of knowing whether the IP addresses created in synthetic tests are going to the right datacentre or service. Automated Session Tests capture the performance of a desktop application e.g. Webex App, without you having to manually configure an IP address or hostname for the application.</p> <p>Note: The below configuration steps are for information purpose only</p> <ul> <li>Navigate to the Endpoint Agents &gt; Monitoring Settings &gt; Automated Session Tests tab.</li> <li>Click the Add New Test button.</li> </ul> <p></p> <ul> <li>Create an AST to monitor Webex Meetings in your organization  </li> </ul> <p></p> <p>Note: The above steps have already been configured. Showing for information purpose only. </p> <p>Note: More info can be found on Webex help that explains how to create a configuration between ControlHub and ThousandEyes platform.</p> <p>When the user (that was created by you) initiate and join a Webex meeting from the WebexApp, you be able to view the ThousandEyes path in ControlHub troubleshooting section.</p> <ul> <li>If you have logged out, log back in ControlHub using Readonly admin creds provided . Click on Troubleshooting,  search for your userid that you have used to join the Webex meeting and click the meeting that is in progress.</li> </ul> <p>Note Make sure the Webex meeting is still going on in the virtual machine. As you are the only participant, it will disconnect in some time. If disconnected, please start the meeting again.</p> <p></p> <ul> <li>Click your demo user id</li> </ul> <p></p> <ul> <li>You will notice ThousandEyes path. ThousandEyes AST starts capturing network path data as soon as the meeting starts. However, there could be a delay of up to five minutes before that data populates in Troubleshooting section. </li> </ul> <p></p> <ul> <li>The network path route shows the details for each node that the hop connected to. Click on any of the dotted lines </li> </ul> <p></p> <ul> <li> <p>You can hover over a dotted line to see the user's latency (round-trip) average value during that interval. The color changes depending on the threshold that the value met. Thresholds in Webex are are calculated as:</p> <pre><code>- Poor (red)\u2014Latency &gt; 400ms or Loss (round-trip) &gt; 5%\n- Good (green)\u2014Latency &lt; 300ms or Loss (round-trip) &lt; 3%\n- Fair (yellow)\u2014Neither of the above.\n- Unknown (grey)\u2014Not available yet. You still be able to retrieve the metric from the TE dashboard.\n</code></pre> </li> <li> <p>You can also click on Launch the ThousandEyes dashboard . It will cross-launch from the Webex ControlHub Network Path into ThousandEyes platform. You will be navigated to the Automated Session Tests view, which is found within the Endpoint Agents &gt; Views &gt; Automated Session Tests section of the web application. The view is pre-filtered to the corresponding user and time segment from Webex Control Hub.</p> </li> </ul> <p></p>"},{"location":"Task5/#understanding-scheduled-tests","title":"Understanding Scheduled tests","text":"<p>Before setting up scheduled tests it's a good idea to create an Agent Label and assign your EPA to it. Labels are a super powerful way to dynamically manage how ThousandEyes Endpoint Agents are configured for testing and reporting.</p> <p>For more information on Endpoint Agent Labels check out our documentation.</p> <p>Click the Agent Labels if you are still viewing your EPA otherwise navigate to Endpoint Agents &gt; Agent Settings &gt; Agent Labels.</p> <p>Click Add New Label. Name the label e.g RS_PC, select any color.</p> <p>In the Filter section select Agent in and use the pull down to select your agent (note you can use the search field to quickly find your agent). Click Save. See the image below for and example of how to add your agent to your label.</p> <p></p>"},{"location":"Task5/#set-up-scheduled-tests-for-your-thousandeyes-epa","title":"Set up Scheduled Tests for your ThousandEyes EPA","text":"<p>You will build a test that will run every minute to https://office.com for this lab but feel free to build other tests. You can have up to 10 tests run on an EPA.</p> <p>Navigate to Endpoint Agents &gt; Monitoring Settings</p> <p>Click Add New Test</p> <ul> <li>Type Web, HTTP Server (this is the default)</li> <li>Test Name: Set a unique name</li> <li>URL: https://office.com</li> <li>Interval: 1 minute</li> <li>Agents: Agent label then select the label you created</li> <li>Click the prioritize slider (as this is an important test)</li> <li>Click Add New Test (note you can also Run Once but if you do this don\u2019t forget to save the test!)</li> </ul> <p></p>"},{"location":"Task5/#set-up-browser-sessions-for-your-thousandeyes-epa","title":"Set up Browser Sessions for your ThousandEyes EPA","text":"<p>Set up domains to be monitored when the browser on the Windows VM accesses them (Note: Only Chrome, Edge or IE 11+ browsers are supported). Typically these consist of the domains that are critical for your users and businses operations. You'll see shortly how powerful this can for troubleshooting users issues. </p> <p>Navigate to Endpoint Agents &gt; Monitoring Settings &gt; Browser Sessions. For more information on Browser Session monitoring click here.</p> <p>Click Add New Monitored Domain Set</p> <ul> <li>Domain Set Name: Set a unique name</li> <li>Monitored Domains: office.com, webex.com, cisco.com (feel free to add in other domains)</li> <li>Agents: Agent Labels and select your agent label that you created earlier  </li> <li>Click Add New Monitored Domain Set</li> </ul> <p></p>"},{"location":"Task5/#automated-sessions-tests-ast-for-your-thousandeyes-epa","title":"Automated Sessions Tests (AST) for your ThousandEyes EPA","text":""},{"location":"Task5/#navigate-back-to-your-vm","title":"Navigate back to your VM","text":"<p>Open the Chrome Browser and navigate to the domains you set for browser sessions. Open a tab and bring up a site in each tab:</p> <ul> <li>https://cisco.com</li> <li>https://webex.com</li> <li>https://office.com</li> </ul> <p></p> <p>Click refresh on each tab a few times to create some extra sessions. Do this for a few minutes randomly to generate web browser traffic which we will analyze later. If you need to test out having browser traffic randomly generated to a site or set of sites a great chrome plug in to use is Auto Refresh Plus. We won't go into configuring or installing it for this lab.</p> <p>You should have some good data captured with the Webex session running in the background on the VM being catpured with the Webex AST, the scheduled tests runing in background providing a baseline and then the browser sessions. Time to move onto Task 6 and start analyzing the data!</p>"},{"location":"Task6/","title":"Analyzing ThousandEyes EPA Data","text":"<p>Typically when a user experiences an issue they will either suffer in silence, wait for the issue to go away and when it crops up again get frustrated and call in for help. Sometimes while they are working with support or the helpdesk the issue resolves itself. This makes it really difficult to troubleshoot issues if they aren't presistent. ThousandEyes stores 30 days of data so you have the abilty to go back in time and see what was occuring or see if this issue has been occuring and the user just didn't call into support.</p>"},{"location":"Task6/#code-annotation","title":"Code Annotation","text":""},{"location":"Task6/#codeblocks","title":"CODEBLOCKS","text":"<p>Some <code>Code</code> will be below:</p>"},{"location":"Task6/#a-plain-code-block","title":"A plain Code Block","text":"<pre><code>Some Code here\n\nprint(A)\n</code></pre> omer.py<pre><code>Some Code here\n\nprint(A)\n</code></pre> <pre><code>Some Code here\n\nprint(A)\n</code></pre> <pre><code>Some Code here\n\nprint(A)\n</code></pre> <p> If you are troubleshooting a issue and want to quickly see all the test data for a users system Agent Views provides the perfect visualization.</p> <p>Navigate to VM session and browse to ThousandEyes portal. Open Endpoint Agents &gt; Agent Views (be sure to use the incognito browser). Use the search box to find your agent which will be what you named your VM. Then you can begin to explore the metrics and tests. The top section contains your system\u2019s performance metrics.</p> <ul> <li>Use the Metrics pull down to view the different system metrics</li> </ul> <p></p> <p>The middle section shows Automated Session Tests (ASTs) and Scheduled Tests (up to 10 max).</p> <ul> <li>Use the pull down to view the different web and network metrics.</li> </ul> <p></p> <p>The bottom section shows browser sessions. If you don\u2019t see anything you might need to refresh the tabs in your VM\u2019s browser a few extra times or refresh the Agent Views page.</p> <ul> <li>Use the pull down to view the different browser and network metrics.</li> </ul> <p></p>"},{"location":"Task6/#drill-into-a-automated-session-test","title":"Drill into a Automated Session Test","text":"<p>Now that you\u2019ve explored the Agent Views page click on the AST metric to dive into the detailed view associated with the Webex Test. If you don\u2019t have any network loss try changing the metric to latency.</p> <p></p> <p>You will now see a filtered view for your agent showing the network path which is dynamically created based on the endpoints your Webex session is connected to while the Webex session is running.</p> <p>Here\u2019s an example view. I used the upper right Save and Share feature to create a snapshot that anyone can view for a full year! This can be very helpful as it can be attached to tickets, shared with the end user, anoter team or a service provider. They will see what you see making it simple to collaborate and reduce any finger pointing. (think back to the last slide in the ThousandEyes Overview).</p> <ul> <li>Open the snapshot in another browser tab</li> <li>You can mouse over the nodes for extra information</li> <li>Try changing the metric and drag over and navigate the time bar to see how the test changes</li> </ul> <p></p> <p>From this same view you can change the grouping to show IP Addresses and adjust the number of hops to get more a granular hop by hop network path.</p> <ul> <li>You can mouse over the nodes and links for extra information.</li> <li>You can also adjust the link delay. In the below screenshot used 10ms. You can also click on the 8 links to see all links highlighted that are over 10ms.</li> </ul> <p></p> <p>Feel free to navigate back to your Automated Session Test view showing your agent and click around to expermiement with how to see similar data.</p>"},{"location":"Task6/#drill-into-scheduled-tests","title":"Drill into Scheduled Tests","text":"<p>Scheduled tests provide a consistent baseline. Whenever an Endpoint Agent is online the test runs at the specified interval. Navigate back to Agent Views and search and select your agent.</p> <ul> <li>Click Agent Views and use the search box to find your agent.</li> <li>Click into the scheduled test to drill into a filtered view. (If you set up other scheduled tests feel free to use one of them instead)</li> </ul> <p></p> <p>Now you're in a filtered test view. Note the filters at the top of the screen showing the test and your agent. See the below screen shot as an example.</p> <ul> <li>Adjust the metric to latency and change the grouping to IP Address</li> <li>Adjust the hops to max using the slider</li> <li>Set the link delay to 10ms and then click on the links to highlight them in the network path</li> </ul> <p></p> <p>If you wanted to see all agents that are runnig the scheduled test you could just remove the agent filter (this won't work in this lab as we have only one agent). This would be a great way to figure out if an issue is effecting multiple users or start to isolate the users that are having issues as they might all be in the same building or connecting through the same router that is causing congestion, latency or loss. You can also right click on the agent to pull up the traceroute which is run every time the test is executed.</p> <p>Another powerful feature is the Run Now option for when you are actively troubleshooting and need test results right away or you can make changes and run it. Feel free to test it out.</p> <p></p> <p>Note: It might take a few minutes for the test to complete and then be processed for visualization. So you may want to kick it off and then continue on with the lab and come back to the tab in a few minutes.</p>"},{"location":"Task6/#drill-into-browser-sessions","title":"Drill into Browser Sessions","text":"<p>Browser Sessions are generated using the browser plugin and will monitor the user experience and network path for your monitored domain set. The experience score is a calculated metric to help gauge the end users web performance. You can change the metric based on what you are wanting to use for troubleshooting. Navigate back to Agent Views and search and select your agent. Click on the www.cisco.com session to drill into a filtered view. Note if your browser sessions aren\u2019t showing up, verify your agent is associated with the agent label and then make sure to go back to the browser and refresh the tabs.</p> <p></p> <p>The browser session view shows the visited pages and experience score. See the below screenshot for an example. Note the filter for the Visited Site and Agent which was automatically applied based on the browser session test you clicked from the Agent View.</p> <p></p> <p>You can easily explore the other metrics from the session. Click on the web site to bring up the session, system and network details and review the tabs for the path trace and waterfall details. Additional metric will be pulled in based on how the Enpoint Agent is connected to the network like wireless, vpn or proxy.</p> <p> </p> <p>ThousandEyes takes a layered approach with visualizing the data to help you isolate and troubleshoot issues. The Network Layer will show the network path filter on the browser session. Click on the Network Layer that is associated with the Browser Session. Explore the different metrics that are captured in context in time like CPU Load.</p> <p></p>"},{"location":"Task6/#local-network-view","title":"Local Network View","text":"<p>The Local Networks view will provide the local network and DNS information. This can be very helpful for finding bad DNS settings or Wi-Fi related issues. Click into the Local Networks &gt; Network Access layer and make sure your agent is still in the agent filter or clear it out with the X to see all agents. Explore the different metrics as well using the pull down. If this was a production environment the filters could be used for isolation of issues.</p> <p></p>"},{"location":"Task6/#endpoint-agent-overview","title":"Endpoint Agent Overview","text":"<p>This page provides a quick overall health view of your Endpoint Agents. Navigate to the Endpoint Agents &gt; Overview to see all the stats from all the agents. Try adjusting the time range as well.</p> <p></p> <p>Now that you've learned about the metrics, tests and various way that ThousandEyes can help you troubleshoot, isolate and resolve end users issues you're one short step from the final stage of this learning jounery. The last step will be learning about some of the ways a dashboard can be used to visualize the endpoint agent data and shared with other stakeholders. Check out Task 7 to learn about Endpoint Agent data in Dashboards.</p>"},{"location":"Task7/","title":"Understanding Fine-Tuning - Large Language Models","text":""},{"location":"Task7/#fine-tuning-llms","title":"Fine-Tuning LLMs","text":"<p>Goals: Equip audience with knowledge and practical skills in finetuning techniques accompanied by code examples. Discuss the approach to finetuning LLMs.</p> <p>The section centers around fine-tuning LLMs, addressing their various aspects and methodologies. As the module progresses, the focus will be given to specialized instruction tuning techniques, namely \u00a0LoRA. It will examine domain-specific applications (Webex Calling), ensuring a holistic understanding of fine-tuning techniques and their real-world implications.</p> <ul> <li>Techniques for Finetuning LLMs: The lesson highlights the challenges, particularly the resource intensity of traditional approaches. We will introduce instruction tuning methods like \u00a0LoRA.</li> <li>Deep Dive into LoRA and SFT: This lesson offers an in-depth exploration of LoRA and SFT techniques. We will uncover the mechanics and underlying principles of these methods.</li> <li>Finetuning using LoRA : This lesson guides a practical application of LoRA and SFT to finetune an LLM to follow instructions, using data from the \u201cHuggingFace Dataset\u201d .</li> </ul>"},{"location":"Task7/#techniques-for-finetuning-llms","title":"Techniques for Finetuning LLMs","text":""},{"location":"Task7/#introduction","title":"Introduction","text":"<p>In this lesson, we will examine the main techniques for fine-tuning Large Language Models for superior performance on specific tasks. We explore why and how to fine-tune LLMs, the strategic importance of instruction fine-tuning, and several fine-tuning methods, such as  Low-Rank Adaptation (LoRA), Supervised Finetuning (SFT). We also touch upon the benefits of the Parameter-Efficient Fine-tuning (PEFT) approach using Hugging Face's PEFT library, promising both efficiency and performance gains in fine-tuning.</p>"},{"location":"Task7/#why-we-finetune-llms","title":"Why We Finetune LLMs","text":"<p>While pretrained Large Language Models (LLMs) provide a broad understanding of language, it doesn't equip them with the specialized knowledge needed for complex tasks. For instance, a pre-trained LLM may excel at generating text but encounter difficulties when tasked with sentiment analysis or even providing information from your own Knowledge base. This is where fine-tuning comes into play.</p> <p>Fine-tuning is the process of adapting a pretrained model to a specific task by further training it using task-specific data. For example, if we aim to make an LLM proficient in answering questions about Webex Calling or Webex CC, we would fine-tune it using a dataset comprising Webex question-answer pairs. This process enables the model to recalibrate its internal parameters and representations to align with the intended task, enhancing its capacity to address domain-specific challenges effectively.</p> <p>However, fine-tuning LLMs conventionally can be resource-intensive and costly. It involves adjusting  the parameters in the pretrained LLM models, which can number in the billions, necessitating significant computational power and time. Consequently, it's crucial to explore more efficient and cost-effective methods for fine-tuning, such as Low-Rank Adaptation (LoRA).</p>"},{"location":"Task7/#a-reminder-on-instruction-and-conversational-finetuning","title":"A Reminder On Instruction and Conversational Finetuning","text":"<p>In Conversational fine tuning the model engages in a dialogue with the user, maintaining context over multiple turns.The interaction mimics a natural conversation, with the model responding in a way that feels like a human interlocutor.</p> <p>Instruction fine-tuning is a specific type of fine-tuning that grants precise control over a model's behavior. The objective is to train a Language Model (LLM) to interpret prompts as instructions rather than simply treating them as text to continue generating. </p>"},{"location":"Task7/#introduction-to-efficient-finetuning-with-parameter-efficient-fine-tuning-peft","title":"Introduction to Efficient Finetuning with Parameter-Efficient Fine-tuning (PEFT)","text":"<p>Parameter-Efficient Fine-tuning (PEFT) approaches address the need for computational and storage efficiency in fine-tuning LLMs. Hugging Face developed the PEFT library specifically for this purpose. PEFT leverages architectures that only fine-tune a small number of additional model parameters while freezing most parameters of the pretrained LLMs, significantly reducing computational and storage costs.</p> <p>PEFT methods offer benefits beyond just efficiency. These methods have been proven to outperform standard fine-tuning methods, particularly in low-data situations, and provide improved generalization for out-of-domain scenarios. Furthermore, they contribute to the portability of models by generating tiny model checkpoints that require substantially less storage space compared to extensive full fine-tuning checkpoints.</p> <p>The PEFT library supports popular methods such as Low-Rank Adaptation (LoRA) and Prompt Tuning. </p>"},{"location":"Task7/#a-reminder-of-the-techniques-for-finetuning-llms","title":"A Reminder of the Techniques For Finetuning LLMs","text":"<p>There are several techniques to make the finetuning process more efficient and effective:</p> <ul> <li> <p>Full Finetuning: This method involves adjusting all the parameters in the pretrained LLM models to adapt to a specific task. While effective, it is resource-intensive and requires extensive computational power, therefore it\u2019s rarely used. Not in our Scope</p> </li> <li> <p>Low-Rank Adaptation (LoRA): LoRA is a technique that aims to adapt LLMs to specific tasks and datasets while simultaneously reducing computational resources and costs. By applying low-rank approximations to the downstream layers of LLMs, LoRA significantly reduces the number of parameters to be trained, thereby lowering the GPU memory requirements and training costs. We\u2019ll also see QLoRA, a variant of LoRA that is more optimized and leverages quantization.</p> </li> </ul> <p>With a focus on the number of parameters involved in finetuning, there are multiple methods, such as:</p> <ul> <li> <p>Supervised Finetuning (SFT): SFT involves doing standard supervised finetuning with a pretrained LLM on a small amount of demonstration data. This method is less resource-intensive than full finetuning but still requires significant computational power. Scope of this lab</p> </li> <li> <p>Reinforcement Learning from Human Feedback (RLHF): RLHF is a training methodology where models are trained to follow human feedback over multiple iterations. This method can be more effective than SFT, as it allows for continuous improvement based on human feedback. We\u2019ll also see some alternatives to RLHF, such as Direct Preference Optimization (DPO), and Reinforcement Learning from AI Feedback (RLAIF).Not in our Scope</p> </li> </ul>"},{"location":"Task7/#conclusion","title":"Conclusion","text":"<p>In this lesson, we've learned that while pretraining equips LLMs with a broad understanding of language, fine-tuning is necessary to specialize these models for complex tasks. We've looked into various fine-tuning techniques, including Full Finetuning, Low-Rank Adaptation (LoRA), Supervised Finetuning (SFT), and Reinforcement Learning from Human Feedback (RLHF). </p>"},{"location":"Task8/","title":"Deep Dive into Quantization, LoRA and SFT","text":""},{"location":"Task8/#introduction","title":"Introduction","text":"<p>In this lesson, we will dive deeper into Quantization and the mechanics of LoRA, a powerful method for optimizing the fine-tuning process of Large Language Models, its practical uses in various fine-tuning tasks, and the open-source resources that simplify its implementation. We will also introduce QLoRA, a highly efficient version of LoRA. By the end of this lesson, you will have an in-depth understanding of quantization and how LoRA and QLoRA can enhance the efficiency and accessibility of fine-tuning LLMs.</p>"},{"location":"Task8/#understanding-quantization","title":"Understanding Quantization","text":"<p>As large language models, grow more advanced, their increasing number of parameters leads to significant memory usage. This, in turn, increases the costs of hosting and deploying these tools.</p> <p>In this section, we will quickly learn about quantization. Quantization is a process that converts data that\u2019s in your memory from high bit to low bit rate.</p>"},{"location":"Task8/#quantization-in-machine-learning","title":"Quantization in Machine Learning","text":"<p>Neural Networks have millions or billions of parameters (floating point values) representing their weights and biases, a characteristic known as precision. The precision of these data types directly impacts the amount of memory required by the model. Using higher precision types, such as Float32 or Float64, offers greater accuracy but demands more memory. By default when you train your neural network  ususally the parameters are stored in FP32, which means each paraeter takes 32 bits. The idea of Quantization is to reduce parameters that takes less space example 16 bit floating points(FP16) or Int8. If we store all the parameters in INT8 , it means everything be saved between 0 - 255, which will result in saving space 4 times comapred to FP32</p> <p>Quantization can significantly reduce this memory requirement by representing parameters with fewer bits. For example, converting from 32-bit to smaller bit representations allows us to perform inference with the models more efficiently. Once models are quantized, they can be deployed on edge devices like phones, smartwatches, etc. However, using lower precision types, such as Float16 or BFloat16 or Int8, while saving memory, may result in a slight loss of accuracy. To overcome this loss in accuracy, techniques like Lora and QLoRA can be utilized.</p> <p>Benefits of Quantization:</p>"},{"location":"Task8/#fp16-quantization","title":"FP16 Quantization:","text":"<ul> <li>Reduces the model size by half.</li> <li>Maintains higher precision than INT8.</li> <li>Suitable for GPUs and TPUs that support FP16 arithmetic.</li> </ul>"},{"location":"Task8/#int8-quantization","title":"INT8 Quantization:","text":"<ul> <li>Significantly reduces model size and improves latency.</li> <li>Suitable for CPUs and hardware accelerators that support INT8 arithmetic.</li> </ul> <p>By applying quantization, we can make large models more efficient and capable of running on a variety of devices, ensuring a balance between performance and resource utilization.</p> <p>In the figure below, you can see the main floating point data types.</p> <p></p>"},{"location":"Task8/#why-quantization-uses-less-memory","title":"Why Quantization uses less memory","text":"<p>As mentioned above, the primary advantage of using quantization (4-bit) is the reduction in model size and memory usage. Here's a simple explanation:</p> <p></p> <ul> <li>A float32 number takes up 32 bits of memory.</li> <li>A 4-bit quantized number takes up only 4 bits of memory. So, theoretically, you can fit 8 times more 4-bit quantized numbers into the same memory space as float32 numbers. This allows you to load larger models into the GPU memory or use smaller GPUs that might not have been able to handle the model otherwise.</li> </ul> <p>Note: The amount of memory used by an integer in a computer system is directly related to the number of bits used to represent that integer.</p> <p>Memory Usage for 4-bit Integer A 4-bit integer uses 4 bits of memory</p> <p>Memory Usage for 32-bit Integer A 32-bit integer uses 32 bits of memory.</p> <p>Conversion to Bytes To convert these to bytes (since memory is often measured in bytes):</p> <pre><code>1 byte = 8 bits\nA 4-bit integer would use ( 4/8 = 0.5 ) bytes.\nA 16-bit integer would use ( 16/8 = 2 ) bytes.\n</code></pre> <p>Lets Understand by taking Llama 2 as an example:</p> <p>For example, you may come across config like this in Llama 2 model:</p> <p>Note: The bitsandbytes library will be used for quantization and fine-tuning of models. It provides tools to reduce memory footprint and improve computational efficiency.</p> <pre><code>bnb_config = transformers.BitsAndBytesConfig(\nload_in_4bit=True,\nbnb_4bit_quant_type='nf4',\nbnb_4bit_use_double_quant=True,\nbnb_4bit_compute_dtype=bfloat16\n)\nload_in_4bit=True //Enables 4-bit quantization.\nbnb_4bit_quant_type='nf4' //Specifies the type of 4-bit quantization.\nbnb_4bit_use_double_quant=True //Enables double quantization for better accuracy.\nbnb_4bit_compute_dtype=bfloat16 //Specifies the data type for computation, which is bfloat16 here.\n</code></pre> <p>By using 4-bit quantization, you can load the Llama 2 model with significantly less GPU memory, making it more accessible for devices with limited resources.</p>"},{"location":"Task8/#understanding-quantization-lab-example","title":"Understanding Quantization - Lab Example","text":"<p>We will be using and running the code in Google Colab. This code demonstrates how much memory can be saved by using 4-bit quantization compared to 32-bit floating-point precision for a hypothetical model with 1000 weights. It calculates the total memory required for both 32-bit and 4-bit representations, determines the memory savings, and converts the result to bytes for easier understanding.</p> <p>By quantizing the model weights from 32-bit to 4-bit, significant memory savings are achieved, making it more efficient to deploy models on resource-constrained devices like phones and smartwatches.</p> <p>If you have not yet created a Google Colab account, please refer to the following section</p> <ul> <li>Browse to Google Colab and create a new Notebook</li> </ul> <p></p> <ul> <li>Select your runtime envoirnment</li> </ul> <p></p> <p> NOTE:  As we will be running a hypothetical model in Google Colab, you can use the CPU to run the code below. Our goal is to understand how quantization can help us use less memory.</p> <p> Reminder:  Whenever you want to copy the below code  into Google Colab and run it on individual line, be sure to click on + Code to add a new code cell. Also make sure to press the Play button to execute the code</p> <p></p> <p></p> <ul> <li>Let's break down the code step by step and explain what it does:</li> </ul> <p> Step 1:  Define Memory Weight for Float32:</p> <pre><code>float32_memory = 32  # in bits\nnum_weights = 1000  # hypothetical number of weights\n</code></pre> <ul> <li>float32_memory is set to 32 bits, which is the memory required for each weight when using 32-bit floating-point precision (Float32).</li> <li>num_weights is set to 1000, representing a hypothetical number of weights in the model.</li> </ul> <p> Step 2:  Calculate Total Memory for Float32 Weights:</p> <pre><code>float32_total_memory = float32_memory * num_weights  # in bits\n</code></pre> <ul> <li>float32_total_memory calculates the total memory required for all the weights when using Float32. This is done by multiplying the memory per weight (float32_memory) by the number of weights (num_weights).</li> </ul> <p> Step 3:  CDefine Memory Per Weight for 4-bit Quantization:</p> <pre><code>bit4_memory = 4  # in bits\n</code></pre> <ul> <li>bit4_memory is set to 4 bits, which is the memory required for each weight when using 4-bit quantization.</li> </ul> <p> Step 4:  Calculate Total Memory for 4-bit Quantized Weights:</p> <pre><code>bit4_total_memory = bit4_memory * num_weights  # in bits\n</code></pre> <ul> <li>bit4_total_memory calculates the total memory required for all the weights when using 4-bit quantization. This is done by multiplying the memory per weight (bit4_memory) by the number of weights (num_weights).</li> </ul> <p> Step 5:  Calculate Memory Saved:</p> <pre><code>memory_saved = float32_total_memory - bit4_total_memory  # in bits\nmemory_saved_in_bytes = memory_saved / 8  # convert bits to bytes\n</code></pre> <ul> <li>memory_saved calculates the total amount of memory saved by using 4-bit quantization instead of Float32. This is done by subtracting the total memory required for 4-bit weights (bit4_total_memory) from the total memory required for Float32 weights (float32_total_memory).</li> <li>memory_saved_in_bytes converts the saved memory from bits to bytes by dividing by 8 (since there are 8 bits in a byte).</li> </ul> <p> Step 5:  Print the Result: <pre><code>print(f\"Memory saved by using 4-bit quantization: {memory_saved_in_bytes} bytes\")\n</code></pre>  OUTPUT </p> <p><code>Memory saved by using 4-bit quantization: 3500.0 bytes</code></p> <ul> <li>Will changing the model from 32-bit to 4-bit reduce the model's accuracy?  Yes </li> </ul> <p> NOTE:  Let's sets up the context of the code, indicating that reducing the bit-width from 32-bit to 4-bit quantization can introduce a loss of accuracy. Please us ethe same notebook as above to continue with your code.</p> <p> Step 1:  Import Python Library NumPY</p> <p><pre><code>import numpy as np\n</code></pre> * Import the NumPy library, which is used for numerical operations on arrays.</p> <p> Step 2:  Simulate Original float32 Weights:</p> <p><pre><code>original_weights = np.random.rand(1000).astype(np.float32)\n</code></pre> * Generate an array of 1000 random floating-point numbers between 0 and 1, simulating the original model weights with 32-bit precision (float32).</p> <p> Step 3:  Simulate 4-bit Quantized Weights:</p> <p><pre><code>quantized_weights = np.round(original_weights * 15).astype(np.uint8)\n</code></pre> * Normalize the original weights to a range of 0 to 15 because 4-bit integers can represent 16 values (0 to 15). * Use np.round() to round the normalized weights to the nearest integer. * Convert the rounded values to 8-bit unsigned integers (np.uint8), which effectively simulates the 4-bit quantized weights.</p> <p> Step 4:  De-normalize to Get the Approximated Original Weights:</p> <p><pre><code>approximated_weights = quantized_weights / 15.0\n</code></pre> * De-normalize the quantized weights back to the original range by dividing by 15.0. This gives an approximation of the original weights after quantization.</p> <p> Step 5:  Calculate the Error</p> <p><pre><code>error = np.abs(original_weights - approximated_weights).mean()\n</code></pre> * Calculate the absolute difference between the original weights and the approximated weights. * Compute the mean of these differences to get the average quantization error.</p> <p> Step 6:  Print the Result:</p> <p><pre><code>print(f\"Average Quantization Error: {error}\")\n</code></pre> * Print the average quantization error to show the potential loss of accuracy introduced by reducing the bit-width from 32-bit to 4-bit.</p> <p> OUTPUT  </p> <p><code>Average Quantization Error: 0.016423573800129817</code></p> <p> Optional Step  Lets see the original generated randon floating point weights </p> <pre><code>original_weights\n</code></pre> <p><code>0.9047668 , 0.81753767, 0.15176044, 0.82469964, 0.26190883,        0.25543845, 0.91670144, 0.44082588, 0.8387138 , 0.5301147 ,        0.597587  , 0.28645265, 0.31866026, 0.8412814 , 0.87486124,        0.14635882, 0.00842665, 0.40396062, 0.7154632 , 0.92024857,        0.58492464, 0.369594  , 0.3199917 , 0.01947883, 0.5505348 ,        0.09161595, 0.75082487, 0.9818501 , 0.800069  , 0.55406606,        0.87903994, 0.6254798 , 0.8290317 , 0.73905164, 0.42614278,        0.6899402 , 0.03985518, 0.3132978 , 0.97768533, 0.42348453,        0.60850483, 0.80669063, 0.18966372, 0.79855096, 0.73046243,        0.3299927 , 0.79309106, 0.01327937, 0.01851322, 0.9269705 ,        0.8274083 , 0.45073316, 0.51967096, 0.7210426 , 0.41424063,        0.24505323, 0.90779364, 0.64724004, 0.65470797, 0.14317876,        0.91511154, 0.57397956, 0.83594376, 0.09163648, 0.3037902 ,        0.01362608, 0.92493033, 0.6721083 , 0.5777128 , 0.98029524,        0.29148692, 0.5840548 , 0.805403  , 0.17140059, 0.9880919 ,        0.01023464, 0.8627494 , 0.89710003, 0.76805186, 0.9278038 ,        0.9041322 , 0.19642776, 0.78401035, 0.16597563, 0.16709319,        0.41655192, 0.6231926 , 0.95298046, 0.6890473 , 0.79470664,        0.7721617 , 0.2800831 , 0.32485998, 0.83056533, 0.84955883,        0.9345336 , 0.20025656, 0.31240928, 0.0943019 , 0.92295516,        0.07533643, 0.2782531 , 0.34772104, 0.20622289, 0.6932999 ,        0.01451688, 0.05406734, 0.69295406, 0.56339973, 0.74457246,        0.8313878 , 0.51609147, 0.4473876 , 0.29768255, 0.9012652 ,        0.7957006 , 0.5588959 , 0.54948616, 0.41233262, 0.04758253,        0.09688636, 0.19657251, 0.60875326, 0.6305743 , 0.62236613,        0.53727114, 0.60597694, 0.27432016, 0.5396689 , 0.35570994,        0.7779527 , 0.62765694, 0.5046841 , 0.95913595, 0.37506285,        0.06490876, 0.5690066 , 0.5926366 , 0.8343261 , 0.00439525,        0.75573623, 0.89352626, 0.45979103, 0.16634902, 0.2184745,        0.39872894, 0.68869066, 0.08809475, 0.8567979 , 0.2187864,        0.21870795, 0.52296937, 0.16986693, 0.6928503 , 0.41990125,        0.5135413 , 0.45609972, 0.38769007, 0.00987561, 0.15869647,        0.80649745, 0.8347802 , 0.7420551 , 0.07340008, 0.6842359 ,        0.33549812, 0.6722021 , 0.3444218 , 0.7548876 , 0.67199737,        0.04117178, 0.24504112, 0.39629644, 0.6458071 , 0.4220033 ,        0.44719183, 0.00884627, 0.8429784 , 0.5802084 , 0.07012173,        0.2552524 , 0.23461716, 0.08043662, 0.17875864, 0.35063305,        0.99479717, 0.3229556 , 0.7217851 , 0.09103325, 0.00775268,        0.3796975 , 0.24862018, 0.32581842, 0.530216  , 0.71165705,        0.5170614 , 0.06309021, 0.6869316 , 0.9265822 , 0.04267561,        0.44075203, 0.28398433, 0.46985227, 0.5829586 , 0.23592392,        0.95805424, 0.52453846, 0.8329666 , 0.14974083, 0.48412293,        0.04571012, 0.8544567 , 0.89506125, 0.10473824, 0.29405326,        0.29569003, 0.59090966, 0.66576856, 0.35182896, 0.12008226,        0.49510583, 0.8308251 , 0.14861059, 0.5513083 , 0.45685318,        0.8333833 , 0.9543581 , 0.42451006, 0.6116371 , 0.76232755,        0.81956553, 0.89240205, 0.2516925 , 0.92773354, 0.9864879 ,        0.04117434, 0.78647643, 0.21779937, 0.3965154 , 0.6441789 ,        0.6636646 , 0.547766  , 0.8827409 , 0.24284157, 0.1969708 ,        0.5668731 , 0.78194785, 0.6832345 , 0.10209882, 0.97626406,        0.5010292 , 0.12451114, 0.32503366, 0.17754969, 0.53745407],       dtype=float32)</code></p> <p> Optional Step  Lets see the quantized_weights (4- bit)</p> <pre><code>quantized_weights\n</code></pre> <p><code>6,  1,  2,  1,  8, 14,  3,  9, 13,  1, 10,  5, 14, 12, 13,  9,  2,         4,  1,  6,  7,  5, 15,  3,  0,  9,  9, 12,  2,  6, 11,  4,  3, 13,         8,  7, 14,  4,  9, 10,  0,  8,  9,  6,  9, 10,  8,  4,  1, 13,  1,         7,  3, 13,  5,  3, 11,  6, 12,  8,  8,  2,  8, 13, 10,  6,  6,  0,         0,  3,  7, 10, 11,  4, 11, 13,  3,  8,  8,  1,  5,  5,  7,  2, 13,         5, 12,  4, 11,  6,  9,  6,  8, 13,  4, 13,  6,  6, 15, 13,  2,  0,         4, 15,  7,  7,  5,  5,  2,  4,  8,  8, 15,  6, 11,  9, 12,  1, 13,         3, 14,  8,  1,  5, 15,  1,  9,  7,  1,  1, 13, 11, 12,  4,  5,  9,        14, 11, 14,  0, 12, 12,  2,  4,  9, 10,  8,  7,  3,  7,  9,  1, 13,         7,  9,  7, 12, 14, 11,  3, 11,  9, 11,  1, 13,  9,  4,  5,  2, 15,         8, 13,  1,  9,  3, 15,  3,  3, 12,  8, 14,  7, 11, 13,  3,  0, 10,        15, 11, 14,  4, 11,  7,  6, 13,  1,  4, 10,  1, 11,  9,  2, 10, 11,         8,  1,  5,  7,  8, 11, 13,  3,  3, 14,  4, 10, 10,  1,  6, 12, 13,        12,  7,  6,  8,  9, 10,  7, 12, 11,  1,  7, 14, 13,  8, 14,  1, 13,         7,  9, 12, 14, 14,  1, 14, 14, 11, 13,  2,  9, 11,  1, 13,  1, 13,         2,  8, 12,  1,  6,  7,  1, 12,  7,  4,  6,  8,  9,  8,  4,  1,  7,        13,  7, 12,  0,  6,  7, 11, 15,  7,  6, 13, 12, 12, 10,  8,  9, 12,         0, 10,  1, 13,  9,  3,  2, 14,  9,  6,  9,  6,  4, 15,  5,  5,  5,        12,  5, 15,  4,  7,  0,  3,  3, 15, 15,  3, 10,  2, 15,  7,  8,  2,         2, 10, 11, 14,  4,  0,  8,  1,  8,  5,  1, 12,  5,  6, 14, 11, 10,         2,  6, 11, 12,  8, 12,  0, 14, 12,  4,  9, 11,  7, 14,  2,  4,  4,        10,  4, 13,  1, 14,  0, 15,  8,  6,  5, 12, 10,  6,  1,  4,  7,  7,         7, 10, 10,  5,  8, 12,  8,  6, 12,  2,  1, 14, 15, 13,  9,  3,  3,         8,  7,  3, 10,  7,  1, 10,  7,  6,  4,  8,  2, 11,  2, 15,  2, 11,        12, 10,  5,  7, 13,  2,  6, 15, 13,  6,  1, 10, 12, 10, 11,  4,  1,         8,  3,  4, 12, 15, 12,  9,  8,  1, 12,  2,  2, 14,  2,  9,  7,  4,         4,  3,  2, 11,  0,  5,  9, 12, 15, 14, 13,  1, 15,  3, 12, 10,  3,        13,  5,  8,  9, 15,  2, 14,  8,  8,  6,  7,  1,  6,  3, 15,  3,  0,        13,  9,  6, 12,  5,  5,  5,  9,  9,  2, 13, 15,  3,  9, 11,  1,  8,        13,  9, 12, 14,  5,  9,  2,  8, 14, 10,  4, 12,  8,  9, 10, 13, 14,         3,  1, 14,  9,  9, 12,  2,  1,  7,  4,  2,  0,  4, 10,  2,  6,  3,        10, 10,  9, 11,  9,  8, 15, 12,  3,  2,  5,  9,  6, 11,  1,  9,  5,        14,  7, 14,  4, 13, 14,  5,  8, 14, 10, 12,  3,  1, 12,  9, 14,  1,         2, 11, 11,  2,  2, 13, 12,  3,  4, 12,  7,  1,  9,  3,  4,  4, 14,        14,  8,  0, 12,  8,  6, 12, 13,  6, 11,  6, 10,  9,  6,  2, 14, 10,         4, 10,  2, 15,  9, 14,  0,  4,  0, 10,  1, 15,  5,  7, 10,  6, 12,        10, 11,  6,  7,  2, 14,  8, 12,  7, 14,  9, 13,  0,  5,  7,  2, 11,         9, 11, 13, 10, 14,  8,  8, 14,  4, 10,  1, 11, 15, 10,  0,  6,  0,        13, 14,  9,  4,  4, 12,  5,  9,  4,  6,  2, 10,  3,  4,  1, 14, 11,         6,  7,  1,  4, 11,  1,  7, 12,  8, 14,  2,  8,  8,  3, 11, 15, 10,         2, 14, 12,  2, 12,  4,  4, 14,  7, 13,  8,  9,  4,  5, 13, 13,  2,         0,  6, 11, 14,  9,  6,  5,  0,  8,  1, 11, 15, 12,  8, 13,  9, 12,        11,  6, 10,  1,  5, 15,  6,  9, 12,  3, 12, 11,  5, 12,  0,  0, 14,        12,  7,  8, 11,  6,  4, 14, 10, 10,  2, 14,  9, 13,  1,  5,  0, 14,        10,  9, 15,  4,  9, 12,  3, 15,  0, 13, 13, 12, 14, 14,  3, 12,  2,         3,  6,  9, 14, 10, 12, 12,  4,  5, 12, 13, 14,  3,  5,  1, 14,  1,         4,  5,  3, 10,  0,  1, 10,  8, 11, 12,  8,  7,  4, 14, 12,  8,  8,         6,  1,  1,  3,  9,  9,  9,  8,  9,  4,  8,  5, 12,  9,  8, 14,  6,         1,  9,  9, 13,  0, 11, 13,  7,  2,  3,  3, 14, 12, 11,  4, 13, 15,         4,  7, 13, 13,  0,  8, 13, 13, 15,  8, 15,  3, 11,  4,  8,  9,  2,         2, 11,  3,  7,  4,  7, 11,  6, 10,  1, 13,  3,  8,  3, 10,  6,  8,         7,  6,  0,  2, 12, 13, 11,  1, 10,  5, 10,  5, 11, 10,  1,  4,  6,        10,  6,  7,  0, 13,  9,  1,  4,  4,  1,  3,  5, 15,  5, 11,  1,  0,         6,  4,  5,  8, 11,  8,  1, 10, 14,  1,  7,  4,  7,  9,  4, 14,  8,        12,  2,  7,  1, 13, 13,  2,  4,  4,  9, 10,  5,  2,  7, 12,  2,  8,         7, 13, 14,  6,  9, 11, 12, 13,  4, 14, 15,  1, 12,  3,  6, 10, 10,         8, 13,  4,  3,  9, 12, 10,  2, 15,  8,  2,  5,  3,        dtype=uint8)</code></p> <p></p> <ul> <li> <p>After quantizing LLMs (Large Language Models) from 32-bit to 8-bit precision, we achieve significant reductions in memory usage and computational demands. However, this process can also result in some loss of information and a decrease in accuracy. This brings up an important question: why should we fine-tune a quantized model?</p> </li> <li> <p>Fine-tuning becomes crucial in this context because it helps to restore or even enhance the model's performance after quantization. By fine-tuning, we can adapt the model to specific tasks or datasets, which can mitigate the accuracy loss that occurs during quantization.</p> </li> </ul>"},{"location":"Task8/#the-functioning-of-lora-in-fine-tuning-llms","title":"The Functioning of LoRA in Fine-tuning LLMs","text":"<p>LoRA, or Low-Rank Adaptation, is a method developed by Microsoft researchers to optimize the fine-tuning of Large Language Models. This technique tackles the issues related to the fine-tuning process, such as extensive memory demands and computational inefficiency. LoRA introduces a compact set of parameters, referred to as low-rank matrices, to store the necessary changes in the model instead of altering all parameters.</p> <p>Here are the key features of how LoRA operates:</p> <ul> <li>Maintaining Pretrained Weights: LoRA adopts a unique strategy by preserving the pretrained weights of the model. This approach reduces the risk of catastrophic forgetting, ensuring the model maintains the valuable knowledge it gained during pretraining.</li> <li>Efficient Rank-Decomposition: LoRA incorporates rank-decomposition weight matrices, known as update matrices, to the existing weights. Rank decomposition is a way to simplify a large, complex matric by breaking it down into the product of smaller matrices. These update matrices have significantly fewer parameters than the original model, making them highly memory-efficient. By training only these newly added weights, LoRA achieves a faster training process with reduced memory demands. These LoRA matrices are typically integrated into the attention layers of the original model.</li> </ul> <p>By using the low-rank decomposition approach, the memory demands for training large language models are significantly reduced. This allows running fine-tuning tasks on consumer-grade GPUs, making the benefits of LoRA available to a broader range of researchers and developers.</p> <p></p>"},{"location":"Task8/#open-source-resources-for-lora","title":"Open-source Resources for LoRA","text":"<p>The following libraries offer a mix of tools that enhance the efficiency of fine-tuning large language models. They provide optimizations, compatibility with different data types, resource efficiency, and user-friendly interfaces that accommodate various tasks and hardware configurations.</p> <ul> <li>PEFT Library: Parameter-efficient fine-tuning (PEFT) methods facilitate efficient adaptation of pre-trained language models to various downstream applications without fine-tuning all the model's parameters. By fine-tuning only a portion of the model's parameters, PEFT methods like LoRA, Prefix Tuning, and P-Tuning, including QLoRA, significantly reduce computational and storage costs.</li> <li>Lit-GPT: Lit-GPT from LightningAI is an open-source resource designed to simplify the fine-tuning process, making it easier to apply LoRA's techniques without manually altering the core model architecture. Models available for this purpose include Vicuna, Pythia, and Falcon. Specific configurations can be applied to different weight matrices, and precision settings can be adjusted to manage memory consumption.</li> </ul> <p>In our lab, we\u2019ll focus on the PEFT library.</p>"},{"location":"Task8/#qlora-an-efficient-variant-of-lora","title":"QLoRA: An Efficient Variant of LoRA","text":"<p>QLoRA, or Quantized Low-Rank Adaptation, is a popular variant of LoRA that makes fine-tuning large language models even more efficient. QLoRA introduces several innovations to save memory without sacrificing performance.</p> <p>The technique involves backpropagating gradients through a frozen, 4-bit quantized pretrained language model into Low-Rank Adapters. This approach significantly reduces memory usage, enabling the fine-tuning of even larger models on consumer-grade GPUs. For instance, QLoRA can fine-tune a 65 billion parameter model on a single 48GB GPU while preserving full 16-bit fine-tuning task performance.</p> <p>QLoRA uses a new data type known as 4-bit NormalFloat (NF4), which is optimal for normally distributed weights. It also employs double quantization to reduce the average memory footprint by quantizing the quantization constants and paged optimizers to manage memory spikes.</p> <p>The practical implementation of QLoRA for fine-tuning LLMs is very accessible, thanks to open-source libraries and tools. For instance, the BitsAndBytes library offers functionalities for 4-bit quantization. In the coming sections we will see a code example showing how to use QLoRA with PEFT.</p>"},{"location":"Task8/#conclusion","title":"Conclusion","text":"<p>In this lesson, we explored LoRA and QLoRA, two powerful techniques for fine-tuning Large Language Models (LLMs). We examined how LoRA operates by preserving pretrained weights and introducing low-rank matrices, thereby enhancing the memory and computational efficiency of the fine-tuning process. We also highlighted open-source libraries like PEFT and Lit-GPT that facilitate the implementation of LoRA.</p> <p>Additionally, we discussed QLoRA, an efficient variant of LoRA that employs 4-bit NormalFloat and double quantization to further reduce memory usage. This technique allows for significant memory savings but can introduce quantization errors, impacting model accuracy.</p> <p>By quantizing weights to lower precision, we achieve reduced memory usage and potentially increased processing speed, at the cost of a possible minor loss in accuracy. The provided code example illustrates this trade-off by converting a set of 32-bit floating-point weights into 4-bit integer weights, demonstrating the balance between memory efficiency and model accuracy.</p> <p>Overall, you have successfully learned how to use quantization to optimize LLMs, understanding the benefits and potential drawbacks of this approach.</p>"},{"location":"Task8a/","title":"Task 8a - Configuring and Fine Tuning - Using llama2","text":""},{"location":"Task8a/#introduction","title":"Introduction","text":"<p>This diagram represents the workflow of training and using a LLM. Here\u2019s a step-by-step explanation:</p> <ul> <li>Build Dataset: Once we have determined that fine-tuning is the right solution, we need to create a dataset to fine-tune our model. Datasets are collections of structuorange or unstructuorange data used to train machine learning models.</li> <li>Choose Base Model: A base model is selected. This could be a pre-trained model that will be fine-tuned with the new dataset e.g Llama2 or Llama3 (in our lab)</li> <li>Setup Lora Adapter: The LoRA (Low-Rank Adaptation) adapter is set up a technique used to fine-tune the model efficiently.</li> <li>Train and Monitor: The model is trained using the dataset. During training, the process is monitoorange to ensure it\u2019s proceeding correctly and to make adjustments if necessary.</li> <li>Merged Model: Once the model has been tested and validated, it is consideorange a merged model. This model is ready to handle user queries.</li> <li>User Interaction: Users can now interact with the model by sending queries. The model processes these queries and returns appropriate responses.</li> </ul>"},{"location":"Task8a/#pre-requisites","title":"Pre-requisites","text":""},{"location":"Task8a/#usecase-1-fine-tuning-using-llama2","title":"UseCase 1 - Fine Tuning Using Llama2","text":""},{"location":"Task8a/#datasets-creation","title":"Datasets Creation","text":"<p>There are several ways to create datasets:</p> <ul> <li>Using existing open source datasets e.g The Pile, Common Crawl , Wiki or even HuggingFace</li> <li>Using LLM to create synthetic datasets faster and can be less expensive</li> <li>Using your own custom datasets e.t.c &lt;-- Focus for our lab</li> </ul> <p></p>"},{"location":"Task8a/#custom-datasets","title":"Custom datasets","text":"<p>As we will be using and fine tuning Llam2  we need to convert them(datasets) into a uniform format compatible with training regimens More Info</p>"},{"location":"Task8a/#example-format-for-llama2","title":"Example Format for Llama2","text":"Sample Format - Dont Copy - reference ONLY<pre><code>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\n{{ system_prompt }}\n&lt;&lt;/SYS&gt;&gt;\n{{ user_message }} [/INST] Model answer &lt;/s&gt;\n</code></pre>"},{"location":"Task8a/#datasets-creation_1","title":"Datasets Creation","text":"<p>After defining the problem and confirming that LLMs are a suitable solution, the next step is to prepare a dataset for fine-tuning. If you already have a clean, high-quality dataset, that's great. However, let's assume you don't have one readily available.</p> <p>In my scenario, I was able to generate synthetic dataset from the Cisco Preferorange Architecture for Webex Calling.</p>"},{"location":"Task8a/#creating-a-dataset-from-a-pdf-summary","title":"Creating a Dataset from a PDF - Summary","text":"<p>To delve into the intricacies of dataset creation, let's explore a scenario where we aim to train an AI to replicate our preferorange architecture. In this lab, we will transform a PDF document into a dataset. Specifically, we will use a PDF about Webex Calling as our source material.</p> <p>Our goal is to convert the PDF into a dynamic and engaging dialogue, similar to an interview format. This will allow us to create a more interactive and informative dataset.</p> <p>Steps Involved</p> <p>Converting the PDF to Text</p> <ul> <li>Begin by extracting the text content from the PDF document.</li> </ul> <p>Paragraph Analysis and Segmentation:</p> <ul> <li>Once the PDF is in text form, analyze and segment it into individual paragraphs. Combine short paragraphs and split longer ones to ensure each segment is coherent and self-contained, while still contributing to the overall narrative.</li> </ul> <p>Generating Interview Questions:</p> <ul> <li>For each paragraph, create an artificial interview scenario where a language model (LLM) acts as the interviewer.</li> <li>Develop questions that naturally elicit responses based on the content of the paragraph.</li> <li>The objective is to simulate an insightful dialogue, making it seem as though the PDF is responding to questions about its content and experiences.</li> </ul> <p>By following these steps, we will convert the static information in the PDF into a dynamic and interactive dataset, facilitating a deeper understanding and more engaging learning experience. You can find the complete code that worked for me here.</p> <p>Here's an example of the resulting file. Please note that for this lab demonstration, only a few data points were converted from the PDF.</p> <p>Note: We will use the following file to create and eventually train downstream tasks for our LLM, specifically the Llama2 model.</p> <p>Download example.txt</p>"},{"location":"Task8a/#sample-file-content","title":"Sample File Content","text":"example.txt<pre><code>human_text: What is the solution provided by Webex Calling? assistant_text: Webex Calling provides enterprise-grade PBX features, functionality, and performance.\nhuman_text: What options are available for PSTN access in Webex Calling? assistant_text: The options are Cisco Calling Plans, Cloud Connected PSTN, and Premises-based PSTN.\nhuman_text: What type of devices does Webex Calling support? assistant_text: Webex Calling supports Cisco MPP Series IP Phones, Webex Devices, and a variety of third-party devices.\nhuman_text: How are Webex Calling data centers distributed? assistant_text: Webex Calling data centers are globally distributed and geo-orangeundant, located in six regions: US, Canada, Europe, UK, Australia, and Japan.\nhuman_text: What is the function of the Local Gateway in Webex Calling? assistant_text: The Local Gateway connects to the PSTN and registers with Webex Calling to handle all calls between the PSTN and Webex Calling.\nhuman_text: What are the key benefits of Webex Calling for large enterprises? assistant_text: Webex Calling offers scalability, advanced call management, and integration with collaboration tools for large enterprises.\nhuman_text: How does Webex Calling handle call encryption? assistant_text: SRTP and TLS are used in Webex Calling to encrypt media and signaling for secure communications.\nhuman_text: What features are included in the Webex Calling analytics suite? assistant_text: Call quality, usage patterns, and performance metrics are part of the Webex Calling analytics suite.\nhuman_text: How does Webex Calling integrate with third-party devices? assistant_text: Integration with third-party SIP phones provides flexibility in device choices for Webex Calling users.\nhuman_text: What disaster recovery mechanisms are available in Webex Calling? assistant_text: Geo-orangeundant data centers and automatic failover mechanisms support disaster recovery in Webex Calling.\nhuman_text: How does Webex Calling manage international call routing? assistant_text: A global network of data centers manages international call routing in Webex Calling.\nhuman_text: What role does the Webex Control Hub play in Webex Calling? assistant_text: Provisioning, configuring, and managing Webex Calling services are handled through the Webex Control Hub.\nhuman_text: What are the main security protocols used in Webex Calling? assistant_text: SRTP and TLS are the main security protocols used in Webex Calling.\nhuman_text: How does Webex Calling support mobile users? assistant_text: The Webex App enables mobile users to make and receive calls on smartphones and tablets in Webex Calling.\nhuman_text: What are the benefits of Webex Calling for remote teams? assistant_text: Remote teams benefit from enterprise-grade calling features, mobility, and collaboration tool integration in Webex Calling.\nhuman_text: How does Webex Calling ensure compliance with regulatory requirements? assistant_text: Compliance with regulatory requirements in Webex Calling is ensuorange through call recording, monitoring, and secure data handling.\nhuman_text: What orangeundancy features are built into Webex Calling? assistant_text: Geo-orangeundant data centers and automatic failover ensure continuous service in Webex Calling.\nhuman_text: What user management capabilities are available in Webex Calling? assistant_text: User settings and permissions are managed through the Webex Control Hub in Webex Calling.\nhuman_text: How does Webex Calling handle call routing? assistant_text: Dial plans and customizable routing rules manage call routing in Webex Calling.\nhuman_text: What kind of customer support does Cisco provide for Webex Calling? assistant_text: Technical assistance, training, and deployment resources are part of Cisco's support for Webex Calling.\nhuman_text: How does Webex Calling support hybrid deployments? assistant_text: Integration with cloud and on-premises PBX systems supports hybrid deployments in Webex Calling.\nhuman_text: What are the call management features in Webex Calling? assistant_text: Call management features in Webex Calling include call forwarding, call transfer, call hold, and voicemail.\nhuman_text: How does Webex Calling support video calls? assistant_text: Video calls are supported between video-capable devices in Webex Calling.\nhuman_text: What compliance features are available in Webex Calling? assistant_text: Compliance features in Webex Calling include call recording, logging, and monitoring.\nhuman_text: What is the function of SRTP in Webex Calling? assistant_text: SRTP encrypts media streams in Webex Calling to ensure secure communication.\nhuman_text: How does Webex Calling support call analytics? assistant_text: Webex Calling provides detailed call analytics on call quality, usage patterns, and performance.\nhuman_text: What kind of orangeundancy features are available in Webex Calling? assistant_text: orangeundancy features in Webex Calling include geo-orangeundant data centers and automatic failover.\nhuman_text: How does Webex Calling ensure secure voice communications? assistant_text: Encryption protocols like SRTP for media and TLS for signaling ensure secure voice communications in Webex Calling.\nhuman_text: What integrations does Webex Calling offer with contact center solutions? assistant_text: Integration with Webex Contact Center offers advanced features like call routing, IVR, and analytics.\nhuman_text: How does Webex Calling handle call monitoring and recording? assistant_text: Call monitoring and recording features in Webex Calling support compliance, training, and quality assurance.\nhuman_text: What options are available for user authentication in Webex Calling? assistant_text: Webex Calling supports user authentication through secure protocols and integration with identity providers for SSO.\nhuman_text: What is the role of the Webex App in Webex Calling? assistant_text: The Webex App unifies messaging, video conferencing, and calling for a seamless communication experience.\nhuman_text: How does Webex Calling support international business operations? assistant_text: Global data centers support reliable and high-quality voice communication for international operations in Webex Calling.\nhuman_text: What management capabilities does Webex Calling provide? assistant_text: The Webex Control Hub provides centralized provisioning, configuration, and monitoring for Webex Calling services.\nhuman_text: How does Webex Calling handle voice and video integration? assistant_text: Integration with Webex Meetings and Webex Teams allows for seamless voice and video communication in Webex Calling.\nhuman_text: What are the benefits of Webex Calling for large enterprises? assistant_text: Scalability, advanced call management, and integration with collaboration tools are benefits for large enterprises using Webex Calling.\nhuman_text: What disaster recovery options are available with Webex Calling? assistant_text: Geo-orangeundant data centers and automatic failover provide disaster recovery options in Webex Calling.\nhuman_text: How does Webex Calling manage call quality? assistant_text: Call quality in Webex Calling is managed through network optimization, advanced codecs, and QoS policies.\nhuman_text: What user profile management features are available in Webex Calling? assistant_text: User profile management features in Webex Calling include settings and permissions configuration through the Webex Control Hub.\nhuman_text: How does Webex Calling integrate with CRM systems? assistant_text: Integration with CRM systems enhances customer interactions and business processes in Webex Calling.\nhuman_text: What compliance features does Webex Calling offer? assistant_text: Compliance features in Webex Calling include call recording, monitoring, and secure data handling.\nhuman_text: How does Webex Calling support remote teams? assistant_text: Remote teams benefit from enterprise-grade calling features, mobility, and collaboration tool integration in Webex Calling.\nhuman_text: What are the main security features of Webex Calling? assistant_text: Security features in Webex Calling include encryption, secure voice, and industry-standard compliance.\nhuman_text: How does Webex Calling handle emergency call routing? assistant_text: Porangeefined routing rules manage emergency call routing in Webex Calling.\nhuman_text: What kind of support does Cisco provide for Webex Calling? assistant_text: Technical assistance, training, and deployment resources are part of Cisco's support for Webex Calling.\nhuman_text: How does Webex Calling support hybrid work environments? assistant_text: Webex Calling supports hybrid work environments by integrating with cloud and on-premises PBX systems.\nhuman_text: What management tools are available in Webex Calling? assistant_text: Management tools in Webex Calling include the Webex Control Hub for provisioning, configuring, and managing services.\nhuman_text: How does Webex Calling handle call quality issues? assistant_text: Tools for monitoring and diagnosing issues ensure high-quality voice communication in Webex Calling.\nhuman_text: What kind of analytics does Webex Calling offer? assistant_text: Analytics on call quality, usage patterns, and performance metrics are available in Webex Calling.\nhuman_text: What devices are compatible with Webex Calling? assistant_text: Compatible devices for Webex Calling include Cisco IP Phones, Webex Room Devices, and third-party SIP phones.\nhuman_text: How does Webex Calling integrate with Webex Meetings? assistant_text: Integration with Webex Meetings provides a seamless experience for scheduling and joining video meetings in Webex Calling.\nhuman_text: What role does Webex Control Hub play in Webex Calling? assistant_text: Webex Control Hub provides a centralized interface for provisioning, configuring, and managing Webex Calling services.\nhuman_text: How does Webex Calling ensure security for voice communications? assistant_text: Encryption protocols like SRTP for media and TLS for signaling ensure security in Webex Calling.\nhuman_text: What features does Webex Calling offer for team collaboration? assistant_text: Group call management, conferencing, and Webex Teams integration are features of Webex Calling for team collaboration.\nhuman_text: How is call recording handled in Webex Calling? assistant_text: Built-in call recording features in Webex Calling support compliance, training, and quality assurance.\nhuman_text: What scalability options are available in Webex Calling? assistant_text: Scalability in Webex Calling supports small businesses to large enterprises, accommodating thousands of users.\nhuman_text: How does Webex Calling support international operations? assistant_text: Global data centers ensure reliable and high-quality voice communication for international operations in Webex Calling.\nhuman_text: What orangeundancy features are built into Webex Calling? assistant_text: orangeundancy features in Webex Calling include geo-orangeundant data centers and automatic failover for continuous service.\nhuman_text: How does Webex Calling handle user authentication? assistant_text: Secure protocols and integration with identity providers for single sign-on (SSO) manage user authentication in Webex Calling.\nhuman_text: What reporting capabilities does Webex Calling provide? assistant_text: Detailed call analytics, usage patterns, and performance metrics are part of Webex Calling's reporting capabilities.\nhuman_text: What integrations does Webex Calling support with CRM systems? assistant_text: Integrations with CRM systems in Webex Calling enhance customer interactions and streamline business processes.\nhuman_text: How does Webex Calling support compliance with regulations? assistant_text: Compliance features in Webex Calling include call recording, monitoring, and secure data handling.\nhuman_text: What is the role of SRTP in Webex Calling? assistant_text: SRTP encrypts voice media streams to ensure secure communication in Webex Calling.\nhuman_text: How does Webex Calling manage user profiles? assistant_text: Webex Control Hub manages user profiles in Webex Calling, enabling configuration of settings and permissions by administrators.\nhuman_text: How does Webex Calling support video conferencing? assistant_text: Webex Calling supports video conferencing via integration with Webex Meetings.\nhuman_text: What is the role of a Local Gateway in Webex Calling? assistant_text: The Local Gateway connects to the PSTN and handles call routing between Webex Calling and on-premises PBX systems.\nhuman_text: How does Webex Calling handle number porting? assistant_text: Webex Calling allows users to port existing phone numbers from another provider.\nhuman_text: How does Webex Calling support disaster recovery? assistant_text: Geo-orangeundant data centers and automatic failover mechanisms support disaster recovery in Webex Calling.\nhuman_text: What is the Webex Calling architecture? assistant_text: Webex Calling has a cloud-based architecture with distributed data centers for high availability and resilience.\nhuman_text: How does Webex Calling support call encryption? assistant_text: SRTP and TLS are used to encrypt call signaling and media in Webex Calling.\nhuman_text: What are the benefits of Webex Calling for small businesses? assistant_text: Small businesses benefit from enterprise-grade calling features, scalability, and collaboration tool integration at a lower cost with Webex Calling.\nhuman_text: How does Webex Calling integrate with existing collaboration tools? assistant_text: Integration with Webex Teams and Microsoft Teams offers a seamless collaboration experience in Webex Calling.\nhuman_text: What analytics features are available in Webex Calling? assistant_text: Analytics features in Webex Calling include call quality monitoring, usage reports, and performance dashboards.\nhuman_text: How does Webex Calling support mobile devices? assistant_text: The Webex App enables Webex Calling users to make and receive calls on mobile devices.\nhuman_text: What is the role of the Webex App in Webex Calling? assistant_text: The Webex App offers a unified interface for messaging, video conferencing, and calling in Webex Calling.\nhuman_text: How does Webex Calling handle multi-location deployments? assistant_text: Centralized management and consistent calling features support multi-location deployments in Webex Calling.\nhuman_text: What troubleshooting tools are available in Webex Calling? assistant_text: Troubleshooting tools in Webex Calling include diagnostic reports, call logs, and real-time call quality monitoring.\nhuman_text: How does Webex Calling ensure voice quality? assistant_text: Voice quality in Webex Calling is ensuorange by network optimization, advanced codecs, and QoS policies.\nhuman_text: What integrations does Webex Calling support? assistant_text: Integrations with CRM systems, collaboration tools, and contact center solutions are supported by Webex Calling.\nhuman_text: How does Webex Calling handle call recording? assistant_text: Call recording in Webex Calling is available for compliance, training, and quality assurance.\nhuman_text: What role do data centers play in Webex Calling? assistant_text: Data centers provide orangeundancy, high availability, and disaster recovery in Webex Calling.\nhuman_text: What are the benefits of Webex Calling for remote teams? assistant_text: Enterprise-grade calling features, mobility, and collaboration tool integration benefit remote teams using Webex Calling.\nhuman_text: How does Webex Calling handle call forwarding? assistant_text: Flexible call forwarding options in Webex Calling allow users to orangeirect calls to other numbers or devices.\nhuman_text: What is Webex Calling? assistant_text: Webex Calling is a cloud-based phone system offering enterprise-grade calling features.\nhuman_text: What types of phones are supported by Webex Calling? assistant_text: Webex Calling supports Cisco MPP Series IP Phones, Webex Devices, and various third-party devices.\nhuman_text: How does Webex Calling integrate with other Webex services? assistant_text: Webex Calling integrates with Webex Meetings, Webex Teams, and Webex Contact Center.\nhuman_text: What are the deployment options for Webex Calling? assistant_text: Webex Calling offers cloud-only and hybrid deployment options.\nhuman_text: How is call quality maintained in Webex Calling? assistant_text: Advanced codecs, network optimization, and QoS policies maintain call quality in Webex Calling.\nhuman_text: What is the purpose of the Webex Control Hub? assistant_text: The Webex Control Hub centralizes management for provisioning, configuring, and managing Webex Calling services.\nhuman_text: How does Webex Calling support remote work? assistant_text: Webex Calling supports remote work by offering enterprise-grade calling features and connectivity from any location with internet access.\nhuman_text: What security measures are implemented in Webex Calling? assistant_text: Encryption, secure voice, and industry-standard compliance are key security measures in Webex Calling.\nhuman_text: How does Webex Calling handle emergency calls? assistant_text: Emergency calls in Webex Calling are handled by comparing the dial string with defined emergency numbers.\nhuman_text: What are the benefits of Webex Calling for enterprises? assistant_text: Lower maintenance costs, scalability, remote work support, and collaboration tool integration are benefits for enterprises using Webex Calling.\nhuman_text: How does Webex Calling manage call routing? assistant_text: Dial plans and route groups manage call routing in Webex Calling.\nhuman_text: What customer support is available for Webex Calling? assistant_text: Webex Calling customer support includes technical assistance, training, and deployment resources from Cisco.\nhuman_text: How does Webex Calling ensure high availability? assistant_text: Geo-orangeundant data centers and a orangeundant global backbone network ensure high availability in Webex Calling.\nhuman_text: What are the international calling capabilities of Webex Calling? assistant_text: International calling is supported by Webex Calling's global data center network for high-quality voice communication.\nhuman_text: What is the role of SIP in Webex Calling? assistant_text: SIP manages signaling and multimedia communication sessions in Webex Calling.\nhuman_text: How does Webex Calling handle compliance with local regulations? assistant_text: Compliance with local regulations is ensuorange by routing calls through regional data centers and supporting lawful intercept.\nhuman_text: What integration options are available for Webex Calling? assistant_text: Webex Calling integrates with Webex Meetings, Webex Teams, and third-party tools for enhanced productivity.\nhuman_text: How does Webex Calling support contact centers? assistant_text: Advanced contact center features like call routing, IVR, and analytics are provided through Webex Contact Center integration.\nhuman_text: What is the function of SRTP in Webex Calling? assistant_text: SRTP encrypts media streams to ensure secure communication in Webex Calling.\nhuman_text: How does Webex Calling handle video calls? assistant_text: Video calls are supported between video-capable MPP phones, Webex Devices, and the Webex App in Webex Calling.\nhuman_text: What are the benefits of Webex Calling for remote workers? assistant_text: Webex Calling offers remote workers enterprise-grade calling features and connectivity from any location with internet access.\nhuman_text: What is the role of the Webex Control Hub in managing Webex Calling? assistant_text: The Webex Control Hub centralizes management for provisioning, configuring, and managing Webex Calling services.\nhuman_text: How does Webex Calling integrate with existing on-premises PBX systems? assistant_text: Webex Calling integrates with on-premises PBX systems via Local Gateways for hybrid deployment.\nhuman_text: What is the significance of SRTP in Webex Calling? assistant_text: SRTP encrypts media streams in Webex Calling to ensure secure communication.\nhuman_text: How does Webex Calling support compliance with local regulations? assistant_text: Webex Calling complies with local regulations by using regional data centers and supporting lawful intercept.\nhuman_text: What features are available for call management in Webex Calling? assistant_text: Webex Calling offers call forwarding, call transfer, call hold, and voicemail features.\nhuman_text: What options are available for integrating Webex Calling with other collaboration tools? assistant_text: Webex Calling integrates with Webex Meetings, Webex Teams, and third-party tools for enhanced productivity.\nhuman_text: How does Webex Calling handle call routing? assistant_text: Dial plans and route groups manage call routing in Webex Calling.\nhuman_text: What security features are built into Webex Calling? assistant_text: Webex Calling features encryption, secure voice, and industry-standard compliance for communication security.\nhuman_text: How does Webex Calling support mobile users? assistant_text: The Webex App enables mobile users to make and receive calls on their devices with Webex Calling.\nhuman_text: How does Webex Calling integrate with Cisco devices? assistant_text: Cisco MPP phones and Webex Room devices integrate with Webex Calling for unified communication.\nhuman_text: What are the deployment models available for Webex Calling? assistant_text: Webex Calling supports cloud-only and hybrid deployment models.\nhuman_text: How does Webex Calling handle international calling? assistant_text: International calling is supported by Webex Calling's global data center network for high-quality voice communication.\nhuman_text: What features does Webex Calling offer for contact centers? assistant_text: Advanced contact center features like call routing, IVR, and analytics are offeorange through Webex Contact Center integration.\nhuman_text: How does Webex Calling support scalability? assistant_text: The cloud-based architecture of Webex Calling supports scalability for businesses of all sizes.\nhuman_text: What type of customer support is available for Webex Calling? assistant_text: Webex Calling customer support includes technical assistance, training, and deployment resources from Cisco.\nhuman_text: How does Webex Calling handle voice quality? assistant_text: High voice quality in Webex Calling is ensuorange by advanced codecs, network optimization, and QoS policies.\nhuman_text: What are the benefits of using Webex Calling over traditional PBX systems? assistant_text: Benefits of Webex Calling include lower maintenance costs, scalability, remote work support, and collaboration tool integration.\nhuman_text: What signaling and media protocols does Webex Calling use? assistant_text: Webex Calling uses SIP for signaling and SRTP for media.\nhuman_text: What is the role of the Webex Control Hub in Webex Calling? assistant_text: The Webex Control Hub provides connection parameters and digest corangeentials for SIP authentication during Local Gateway registration.\nhuman_text: What group features does Webex Calling provide? assistant_text: Webex Calling provides group features like unlimited subscriptions of auto-attendants, hunt groups, and call queues.\nhuman_text: What are the regional platforms for Webex Calling? assistant_text: Webex Calling operates regional platforms in the US, Canada, UK, Europe, APJC Japan, and APJC Australia.\nhuman_text: What role do load balancers play in Webex Calling datacenters? assistant_text: Load balancers are used to build a scalable, orangeundant datacenter architecture.\nhuman_text: What are the capabilities of the Webex App in Webex Calling? assistant_text: The Webex App supports mid-call features, rich presence, and control of the user's Cisco MPP phone.\nhuman_text: What is the role of the Webex Control Hub in Local Gateway registration? assistant_text: The Webex Control Hub provides connection parameters and digest corangeentials for SIP authentication during Local Gateway registration.\nhuman_text: What deployment options are available for Webex Calling? assistant_text: Webex Calling can be deployed as a cloud-only solution or as part of a hybrid cloud.\nhuman_text: What are the data center locations for Webex Calling in the US? assistant_text: Webex Calling data centers in the US are located in Dallas, Chicago, and New York.\nhuman_text: What capabilities does the Webex App offer when integrated with Webex Calling? assistant_text: The Webex App offers messaging, screen sharing, audio and video conferencing, and integrated calling with mid-call features or control of a user\u2019s desk phone.\nhuman_text: What are the considerations for video calls in Webex Calling? assistant_text: Video calls can be made within a single Webex Calling org between video-capable devices or Webex App, while PSTN only supports voice calls.\nhuman_text: What are the main functions hosted in each Webex Calling datacenter? assistant_text: Webex Calling datacenters host call routing functions, provide provisioning interface access, and host access and peering SBCs.\nhuman_text: How does Webex Calling ensure firewall traversal for calls? assistant_text: Webex Calling ensures firewall traversal by using TLS connections initiated by phones and Local Gateways, and sending traffic back through the same connection.\nhuman_text: How are trunks used in Webex Calling? assistant_text: Trunks connect Webex Calling with Local Gateways or Dedicated Instances.\nhuman_text: What is the Private Network Connect (PNC) solution? assistant_text: The Private Network Connect (PNC) solution extends private networks to the cloud for high quality of service and low latency.\nhuman_text: What type of subscription is Webex Calling based on? assistant_text: Webex Calling uses a subscription-based licensing model managed with the Cisco Collaboration Flex Plan.\nhuman_text: Where are Webex Calling data centers located? assistant_text: Webex Calling data centers are located in the US, Canada, Europe, UK, Australia, and Japan.\nhuman_text: How does Webex Calling handle emergency calls? assistant_text: Emergency calls are handled by comparing the dial string with emergency numbers defined in the national numbering plan.\nhuman_text: How are unknown numbers handled in Webex Calling? assistant_text: Unknown numbers are handled based on the 'Unknown Number Handling' and 'Calls to On-Premises Extension' settings.\nhuman_text: What is the purpose of dial plans in Webex Calling? assistant_text: Dial plans enable call routing to premises-based call control instances based on dial patterns.\nhuman_text: What are the benefits of using route groups in Webex Calling? assistant_text: Route groups provide orangeundancy and increased capacity by grouping multiple trunks together.\nhuman_text: What happens if ICE negotiation fails in Webex Calling? assistant_text: If ICE negotiation fails, media is anchoorange on the Webex Calling Access SBC, resulting in media flowing through the customer\u2019s Internet edge to the SBC and back to the destination endpoint.\nhuman_text: What are route groups in Webex Calling? assistant_text: Route groups provide orangeundancy or increased capacity by grouping multiple trunks together.\nhuman_text: What is requiorange for Webex Calling endpoints to connect to the datacenters? assistant_text: Webex Calling endpoints use the public Internet to connect to datacenters and establish over-the-top TLS connections.\nhuman_text: What features does the Dedicated Instance option provide in Webex Calling? assistant_text: The Dedicated Instance option provides a Cisco Unified Communications Manager based stack of applications in a private cloud dedicated to a single customer.\nhuman_text: How does Webex Calling handle PSTN access? assistant_text: Webex Calling handles PSTN access through Cisco Calling Plans, Cloud Connected PSTN, and Premises-based PSTN.\nhuman_text: What are the benefits of the Webex Calling global backbone? assistant_text: The global backbone optimizes media round-trip times and ensures high availability with a multi-gigabit, fully orangeundant network.\nhuman_text: What is the purpose of a Local Gateway in Webex Calling? assistant_text: The Local Gateway connects to the PSTN and registers with Webex Calling to handle all calls between the PSTN and Webex Calling.\nhuman_text: What is the significance of media path optimization in Webex Calling? assistant_text: Media path optimization establishes a direct media path between entities to orangeuce bandwidth usage and improve call quality.\nhuman_text: What is Webex Edge Connect? assistant_text: Webex Edge Connect peers Webex meetings and Webex Calling traffic with an Equinix Cloud Exchange (ECX) location to improve user experience with guaranteed bandwidth and QoS.\nhuman_text: What is the Webex Calling solution overview? assistant_text: Webex Calling provides enterprise-grade PBX features, functionality, and performance.\nhuman_text: What connectivity options are available for Webex Calling? assistant_text: Connectivity options for Webex Calling include Over-the-top (OTT) Internet, Webex Edge Connect, and Private Network Connect.\nhuman_text: What type of patterns can be included in a Webex Calling dial plan? assistant_text: Dial plans can include numeric patterns and domain patterns for routing SIP URIs.\nhuman_text: What is the role of Local Gateways in Webex Calling? assistant_text: Local Gateways provide PSTN access and connect Webex Calling to existing on-premises call control services.\nhuman_text: How does Webex Calling handle calls between different customers? assistant_text: Calls between different Webex Calling customers are routed through the PSTN.\nhuman_text: What types of phones are supported by Webex Calling? assistant_text: Webex Calling supports all models of Cisco Multiplatform Phones (MPP).\nhuman_text: What is Webex Edge Connect? assistant_text: Webex Edge Connect peers Webex meetings and Webex Calling traffic with an Equinix Cloud Exchange location, improving user experience with guaranteed bandwidth and QoS.\nhuman_text: How can video calls be made in Webex Calling? assistant_text: Video calls in Webex Calling can be made between video capable MPP phones, Webex Devices, and Webex App.\nhuman_text: What is the Dedicated Instance option in Webex Calling? assistant_text: The Dedicated Instance option provides a Cisco Unified Communications Manager based stack of applications in a private cloud dedicated to a single customer.\nhuman_text: How many participants can Webex Meetings support when added to Webex Calling? assistant_text: Webex Meetings can support up to 1000 meeting participants.\n</code></pre> <p>Save the file as example.txt as we will be using it in the next step</p> <p>To finalize, we again convert the above dataset (example.txt) into Llama2 format. Lets look into those steps</p>"},{"location":"Task8a/#convert-dataset-into-llama2-format-and-upload-on-hugging-face","title":"Convert dataset into Llama2 format and upload on Hugging Face","text":"<ul> <li>Open Google Colab and create a new notebook. Click on \"File\" &gt; \"New notebook\" .Go to the \"Secrets\" section in the sidebar and ensure the Huuging Face toggle is enabled. Please refer to the following section to create Google Colab account.</li> </ul> <ul> <li>Make sure you are connected to a runtime. For this task, you can use the CPU as the runtime environment.</li> </ul> <ul> <li>Click on Folder and create a new folder called \"data\"</li> </ul> <ul> <li>Click on [...], select Upload</li> </ul> <ul> <li>Choose your example.txt file and click Open</li> </ul> <p>Note\u00a0 Ensure that your files are saved elsewhere. This runtime's files will be deleted when it is terminated.</p> <p>Summary: So far, we have our raw dataset as example.txt, enabled Hugging Face in our Colab notebook, and uploaded the data into our folder. we will be convertig the dataset (example.txt) into Llama2 format and uploading on Hugging Face so it can be used for our fine tuning in the upcoming steps</p> <p> We will start by installing specific Python packages. </p> <pre><code>!pip install datasets huggingface_hub google-colab\n</code></pre> <p></p> <ul> <li> <p>The ! at the beginning is used in Jupyter notebooks or Google Colab to run shell commands. Using pip install we will install Python packages  </p> </li> <li> <p>datasets: This package is part of the Hugging Face ecosystem and provides tools for working with large datasets. It allows users to easily download, preprocess, and manage datasets, especially those used in machine learning and natural language processing (NLP).</p> </li> <li> <p>huggingface_hub: This package provides tools to interact with the Hugging Face Hub. </p> </li> <li> <p>google-colab: This package includes utilities specifically designed for Google Colab, a  Jupyter notebook environment that runs in the cloud.</p> </li> </ul> <p> Step 1: Import the requiorange modules </p> <pre><code># Import requiorange modules\nfrom datasets import Dataset\nfrom huggingface_hub import login\nimport os\nfrom google.colab import userdata\n</code></pre> <ul> <li> <p>from datasets import Dataset: imports the Dataset class from the datasets library. The Dataset class is used to create and manipulate datasets. This library is part of the Hugging Face ecosystem and is especially useful for handling datasets for machine learning and NLP tasks.</p> </li> <li> <p>from huggingface_hub import login: This imports the login function from the huggingface_hub library. The login function is used to authenticate with the Hugging Face Hub, allowing the user to upload and manage models and datasets on the platform.</p> </li> <li> <p>import os: This imports the os module, which provides a way of using operating system-dependent functionality like reading or writing to the file system, environment variables, and more. </p> </li> <li> <p>from google.colab import userdata: imports the userdata module from the google.colab library. The google.colab library contains utilities specifically designed for use with Google Colab. </p> </li> </ul> <p>Step 2:  Retrieve Hugging Face token from Colab secrets </p> <pre><code># Retrieve Hugging Face token from Colab secrets\nos.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n# Login to Hugging Face\nlogin(token=os.environ[\"HF_TOKEN\"])\n</code></pre> <p></p> <ul> <li> <p>This part of the code retrieves a previously stoorange Hugging Face token from Colab secrets. This token is essential for authenticating with the Hugging Face platform. Storing tokens in Colab secrets is a secure way to handle sensitive information without hardcoding it in your script.</p> </li> <li> <p>Login to Hugging Face: This line logs into Hugging Face using the retrieved token. Logging in allows our code to interact with the Hugging Face Hub, and allow us to upload datasets and models.</p> </li> </ul> <p> Step 3: Define a fuction that will help us convert our example.txt into Llama2 format </p> <pre><code># Define the generator function\ndef data_generator(file_path):\n    with open(file_path, 'r') as file:\n        for line in file:\n            if \"assistant_text: \" in line:\n                parts = line.split(\"assistant_text: \")\n                human_text = parts[0].replace(\"human_text: \", \"\").strip()\n                assistant_text = parts[1].strip()\n                reformatted_segment = f'&lt;s&gt;[INST] {human_text} [/INST] {assistant_text} &lt;/s&gt;'\n                yield {\"reformatted_segment\": reformatted_segment}\n</code></pre> <ul> <li> <p>def data_generator(file_path): defines a function named data_generator that takes a single argument, file_path.</p> </li> <li> <p>with open(file_path, 'r') as file:   opens the file specified by file_path in read mode ('r'). </p> </li> <li> <p>for line in file: iterates over each line in the file. </p> </li> <li> <p>if \"assistant_text: \" in line: checks if the string \"assistant_text: \" is present in the current line (example.txt) file </p> </li> <li> <p>parts = line.split(\"assistant_text: \"): splits the current line into two parts using \"assistant_text: \" as the delimiter.</p> </li> <li> <p>human_text = parts[0].replace(\"human_text: \", \"\").strip(): takes the first part of the split line (parts[0]), replaces \"human_text: \" with an empty string, and then removes any leading or trailing whitespace using the strip() method.</p> </li> <li> <p>assistant_text = parts[1].strip(): takes the second part of the split line (parts[1]) and removes any leading or trailing whitespace using the strip() method. </p> </li> <li> <p>reformatted_segment =  Creates a formatted string. The human_text and assistant_text variables are inserted into the string at the specified locations, to replicate Llama2 format.</p> </li> <li> <p>yield {\"reformatted_segment\": reformatted_segment}: the yield statement  return a dictionary containing the reformatted_segment. The yield statement makes this function a generator, allowing it to produce a sequence of values over time, rather than returning them all at once.</p> </li> </ul> <p> Step 4: Define the path for the file that we want to convert </p> <pre><code># Path to your data file\nfile_path = '/content/data/example.txt'\n</code></pre> <p> Note: How to get path for your file in Google COlab </p> <ul> <li>Right click on your file (example.txt) and select Copy Path</li> </ul> <p></p> <p> Step 5: Calling data_generator function </p> <pre><code># Create the dataset from the generator\nds = Dataset.from_generator(data_generator, gen_kwargs={\"file_path\": file_path})\n</code></pre> <ul> <li>Creating a Dataset object by passing the file (example.txt) to the data_generator function</li> </ul> <p> Step 6: Verify if our data formatted </p> <pre><code># Access the dataset\nprint(ds[2])\n</code></pre> <p></p> <p> Step 7: Verify values in our varaiable ds </p> <pre><code># Access the dataset\nprint(ds)\n</code></pre> <p></p> <p> Step 8: Consolidates all the data and create new Dataset </p> <pre><code>reformatted_segments_list = []\n# Iterate through the dataset and collect reformatted segments\nfor example in ds:\n    reformatted_segment = example[\"reformatted_segment\"]\n    reformatted_segments_list.append(reformatted_segment)\n# Now you have all reformatted segments in reformatted_segments_list\nprint(\"Total reformatted segments:\", len(reformatted_segments_list))\nprint(\"First reformatted segment example:\", reformatted_segments_list[0])\n# Create a new Dataset object with these reformatted segments\nreformatted_ds = Dataset.from_dict({\"text\": reformatted_segments_list})  # Assuming downstream processes expect 'text'\n</code></pre> <ul> <li> <p>The  above code snippet iterates over the original dataset (ds), extracts the reformatted segments, and collects them into a list (reformatted_segments_list). This process consolidates all the relevant data into a single list for further processing.</p> </li> <li> <p>After collecting all the reformatted segments, we will create a new Dataset object (reformatted_ds) from the list. This new dataset is structuorange in a way that is requiorange by downstream processes when fine tuning starts.</p> </li> </ul> <p></p> <p> Step 9: Push our new Dataset to Hugging Face Hub so it can be processed and used for fine tuning </p> <pre><code># Push the dataset to the Hub\nreformatted_ds.push_to_hub(\"WebexOne/test\")\n</code></pre> <p></p> <ul> <li> <p>The push_to_hub method is used to upload the dataset reformatted_ds to the Hugging Face Hub. This makes the dataset publicly available (or private, depending on the repository settings) for others to access and use.</p> </li> <li> <p>Repository Naming: The string \"WebexOne/test\" specifies the target repository on the Hugging Face Hub. </p> </li> </ul> <p>Let's login to Hugging Face and view our uploaded model</p> <p></p> <p>Our uploaded Dataset</p> <p></p> <p>Complete Code - FOR REFERENCE ONLY</p> <pre><code>!pip install datasets huggingface_hub google-colab\n# Import requiorange modules\nfrom datasets import Dataset\nfrom huggingface_hub import login\nimport os\nfrom google.colab import userdata\n# Retrieve Hugging Face token from Colab secrets\nos.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n# Login to Hugging Face\nlogin(token=os.environ[\"HF_TOKEN\"])\n# Define the generator function\ndef data_generator(file_path):\n    with open(file_path, 'r') as file:\n        for line in file:\n            if \"assistant_text: \" in line:\n                parts = line.split(\"assistant_text: \")\n                human_text = parts[0].replace(\"human_text: \", \"\").strip()\n                assistant_text = parts[1].strip()\n                reformatted_segment = f'&lt;s&gt;[INST] {human_text} [/INST] {assistant_text} &lt;/s&gt;'\n                yield {\"reformatted_segment\": reformatted_segment}\n# Path to your data file\nfile_path = '/content/data/example.txt'\n# Create the dataset from the generator\nds = Dataset.from_generator(data_generator, gen_kwargs={\"file_path\": file_path})\n\nreformatted_segments_list = []\n# Iterate through the dataset and collect reformatted segments\nfor example in ds:\n    reformatted_segment = example[\"reformatted_segment\"]\n    reformatted_segments_list.append(reformatted_segment)\n\n# Now you have all reformatted segments in reformatted_segments_list\nprint(\"Total reformatted segments:\", len(reformatted_segments_list))\nprint(\"First reformatted segment example:\", reformatted_segments_list[0])\n\n# Create a new Dataset object with these reformatted segments\nreformatted_ds = Dataset.from_dict({\"text\": reformatted_segments_list})  # Assuming downstream processes expect 'text'\n\n# Save the dataset locally - OPTIONAL STEP\nreformatted_ds.save_to_disk('/content/data/reformatted_dataset')\n\n# Push the dataset to the Hub\nreformatted_ds.push_to_hub(\"WebexOne/test\")\n</code></pre>"},{"location":"Task8a/#fine-tuning-llama2-7b-model","title":"Fine-tuning Llama2-7B Model","text":"<p> NOTE: If you\u2019re serious about fine-tuning models, using a script instead of a notebook is recommended. You can easily rent GPUs on Lambda Labs, Runpod, Vast.ai e.t.c </p>"},{"location":"Task8a/#background-on-fine-tuning","title":"Background on Fine-Tuning","text":"<p>Language models (LLMs) are pretrained on extensive text corpus. For example, Llama 2 was trained with 2 trillion tokens. As mentioned before pretraining is resource-intensive and often faces hardware challenges.</p> <p>After pretraining, models like Llama 2, can porangeict the next word in a sequence but don't naturally follow instructions. To make them better assistants, we use instruction tuning, which involves two primary methods:</p> <ul> <li> <p>Supervised Fine-Tuning (SFT): Models are trained on datasets of instructions and responses to minimize the difference between their answers and the correct ones.</p> </li> <li> <p>Reinforcement Learning from Human Feedback (RLHF): Models learn through interaction and feedback to optimize a reward signal based on human evaluations.</p> </li> </ul> <p>RLHF can capture nuanced human preferences but is complex to implement, requiring a well-designed reward system and consistent feedback. Not a focus for this lab</p> <p>In this lab, we will use Supervised Fine-Tuning (SFT). Fine-tuning works well because it builds on the knowledge gained during pretraining. If a model has seen similar data, fine-tuning can significantly enhance performance. For instance, fine-tuning a LLaMA model with 65 billion parameters on 1,000 high-quality samples can outperform larger models like GPT-3.</p> <p>Note: As mentioned earlier, the choice of prompt template is crucial for fine-tuning. In our dataset section, we have converted our data into the following template:</p> <p><code>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt; {{ system_prompt }} &lt;&lt;/SYS&gt;&gt; {{ user_message }} [/INST] Model answer &lt;/s&gt;</code></p> <p>Note: For this tutorial, we will use a preformatted dataset (WebexOne/test) that was uploaded earlier on Hugging Face. We will apply Supervised Fine-Tuning (SFT) to a base model.</p>"},{"location":"Task8a/#guide-to-fine-tuning-llama-2","title":"Guide to Fine-Tuning Llama 2","text":"<p>In this section, we will learn about all the steps requiorange to fine-tune the Llama 2 model with 7 billion parameters on a T4 GPU with high RAM using Google Colab.</p> <p>The Colab T4 GPU has a limited 16 GB of VRAM. That is barely enough to store Llama 2\u20137b's weights (7b \u00d7 2 bytes = 14 GB in FP16), which means full fine-tuning is not possible, and we need to use parameter-efficient fine-tuning techniques like LoRA and QLoRA.</p> <p>We will use the QLoRA technique to fine-tune the model in 4-bit precision and optimize VRAM usage. For that, we will use the Hugging Face ecosystem of LLM libraries:   transformers, accelerate, peft, trl, and bitsandbytes.</p>"},{"location":"Task8a/#base-models-for-fine-tuning","title":"Base models for Fine Tuning","text":"<ul> <li>We have the option to fine-tune the Llama2 Base model (meta-llama/Llama-2-7b-hf), which can be found in the Hugging Face repository</li> </ul> <ul> <li>Since it is a gated repository, you'll need to provide the requiorange information to access and use the model. Please scroll down, fill in the necessary details, and submit the form.</li> </ul> <ul> <li>Once submitted, you can check the status of your request by navigating to Settings and clicking on Gated Repositories.</li> </ul> <p> NOTE: It may take some time for the status to update from Pending to Accepted.</p> <p> NOTE: In this lab environment, we can use the Llama2 base model from another repository that is not gated.  More Info at:  Repository</p> <ul> <li>Lets continue</li> </ul>"},{"location":"Task8a/#logging-into-google-collab","title":"Logging into Google Collab","text":"<ul> <li>You can either use the existing notebook from above and add a new code cell to start fine-tuning, or create a new Jupyter Notebook.</li> </ul> <ul> <li>Change Runtime Environment: Click the \u201cRuntime\u201d dropdown menu at the top of the Colab interface.</li> </ul> <ul> <li> <p>Select \u201cChange runtime type\u201d: This will open a dialog box where you can configure the runtime environment.</p> </li> <li> <p>Select Hardware Accelerator: From the \u201cHardware accelerator\u201d dropdown menu, choose &gt;&gt; T4 GPU and enable toggle for High RAM</p> </li> </ul> <p></p> <ul> <li>Save Settings: Click \u201cSave\u201d to apply the changes.</li> </ul> <p>Reminder: Whenever you want to copy the code in Google Colab and run it, be sure to click on + Code to add a new code cell.</p> <p></p> <p>Reminder: Click the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\" while the cell is selected.</p> <p></p>"},{"location":"Task8a/#set-up-envoirnment","title":"Set up Envoirnment","text":"<p>Step 1: Check the status of Nvidia chipset. OPTIONAL STEP </p> <pre><code>!nvidia-smi \n</code></pre> <p>Note: Remember to execute each cell individually </p> <p></p> <p>Note:  nvidia-smi stands for NVIDIA System Management Interface. It is a command-line utility that provides information about NVIDIA GPUs installed on the system. This tool is part of the NVIDIA GPU driver package. By using !nvidia-smi, you can quickly check the status and health of your NVIDIA GPUs from within a Jupyter Notebook, making it a useful tool for machine learning and data science workflows.</p> <p>Step 2: Install the requiorange libraries. </p> <pre><code>!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7\n</code></pre> <p>Note: Remember to execute each cell individually </p> <p></p> <ul> <li> <p>-q: flag stands for \"quiet\" mode, which minimizes the output during the installation process. OPTIONAL FLAG</p> </li> <li> <p>accelerate==0.21.0: accelerate is a library from Hugging Face for easily running models on different devices (e.g., CPU, GPU). </p> </li> <li> <p>peft stands for Parameter-Efficient Fine-Tuning. It is a library that provides tools for fine-tuning large models efficiently. </p> </li> <li> <p>bitsandbytes==0.40.2: is a library for efficient model quantization </p> </li> <li> <p>transformers==4.31.0: library by Hugging Face that provides pre-trained models and tools for natural language processing (NLP) tasks.</p> </li> <li> <p>trl==0.4.7:  Transformer Reinforcement Learning. It is a library for applying reinforcement learning techniques to transformer models. </p> </li> </ul> <p>Step 3: Load the necessary modules </p> <pre><code>import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer\n</code></pre> <p>Note: Remember to execute each cell individually </p> <ul> <li> <p>datasets:  library, is part of the Hugging Face ecosystem, that provides tools to load and process datasets.</p> </li> <li> <p>transformers: Hugging Face Transformers library, which provides tools for working with transformer-based models.</p> </li> <li> <p>AutoModelForCausalLM: automatically selects the appropriate model architecture for causal language modeling (e.g., Llama or GPT based models).</p> </li> <li> <p>AutoTokenizer: A class that automatically selects the appropriate tokenizer for a given model.</p> </li> <li> <p>BitsAndBytesConfig: Configuration class for model quantization</p> </li> <li> <p>HfArgumentParser: A helper class for parsing command-line arguments, designed for Hugging Face libraries.</p> </li> <li> <p>TrainingArguments: A class that defines the training configuration, such as learning rate, batch size, number of epochs, etc.</p> </li> <li> <p>pipeline: The pipelines are a great and easy way to use models for inference. More info</p> </li> <li> <p>peft: Stands for Parameter-Efficient Fine-Tuning (PEFT), which includes methods like LoRA (Low-Rank Adaptation) and Qlora</p> </li> <li> <p>trl: Stands for Transformer Reinforcement Learning, a library that includes tools for fine-tuning and training models</p> </li> </ul> <p>Step 4: Retrieve Hugging Face token and set as an environment variable. </p> <p><pre><code>from google.colab import userdata\nos.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n</code></pre> Note: Remember to execute each cell individually </p> <pre><code>!huggingface-cli whoami\n</code></pre> <p></p> <ul> <li>Verify to confirm that the Hugging Face CLI is correctly authenticated with your account.</li> </ul>"},{"location":"Task8a/#load-and-prepare-dataset-and-model","title":"Load and prepare dataset and model","text":"<p>Step 5: Before we start processing the data we prepaorange earlier, we need to load the model, tokenizer and datasets.  </p> <pre><code># model_name = \"meta-llama/Llama-2-7b-hf\" as its a gated repo\nmodel_name = \"NousResearch/Llama-2-7b-chat-hf\"\nnew_model = \"WebexOneDemo-Llama-2-7b-chat-finetune\"\n</code></pre> <p>Note: You can name the new_model variable whatever you prefer. </p> <ul> <li>We can use the gated repo or the one mentioned earlier</li> </ul> <pre><code># The instruction dataset to use that we created earlier \ndataset_name = \"WebexOne/test\"\n\n# Load dataset (you can process it here)\ndataset = load_dataset(dataset_name, split=\"train\")\n</code></pre> <pre><code>print(dataset)\n</code></pre> <p></p> <pre><code>print(dataset['text'][2])\n</code></pre> <ul> <li> <p>shows the total number of rows in our dataset</p> </li> <li> <p>Loading the previously created dataset from the Hugging Face Hub</p> </li> </ul>"},{"location":"Task8a/#training-parameters-and-4-bit-quantization-parameters-qlora","title":"Training parameters and 4 bit Quantization Parameters (Qlora)","text":"<p>Step 6: Define hyperparameters for training a machine learning model using QLoRA (Quantized Low-Rank Adaptation) and bitsandbytes, along with the TrainingArguments for the training process. In the below we will use QLoRA with a rank of 64 and a scaling parameter of 16. We\u2019ll load the Llama 2 model directly in 4-bit using the NF4 type and train it for 10 epoch. </p> <pre><code>################################################################################\n# QLoRA parameters - That we will use\n################################################################################\n\n# LoRA attention dimension . A higher value increases the model's capacity to learn but also its computational cost. The higher the rank the more parameters you train and the bigger your adapter files will be.\nlora_r = 64\n\n# Alpha parameter for LoRA scaling. It controls the trade-off between model capacity and stability.\nlora_alpha = 16\n\n# Dropout probability for LoRA layers. The dropout probability applied to the LoRA layers to prevent overfitting.\nlora_dropout = 0.1\n\n################################################################################\n# bitsandbytes parameters\n################################################################################\n\n# Activate 4-bit precision base model. Enables loading the base model with 4-bit precision, which orangeuces memory usage.\nuse_4bit = True\n\n# Compute dtype for 4-bit base models. Specifies the data type for computations in 4-bit precision models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4) we\u2019ll load the Llama 2 model directly in 4-bit precision using the NF4 type\nbnb_4bit_quant_type = \"nf4\"\n\n# Activate or Deactivate nested quantization for 4-bit base models (double quantization)\nuse_nested_quant = False\n\n################################################################################\n# TrainingArguments parameters\n################################################################################\n\n# Output directory where the model porangeictions and checkpoints will be stoorange\noutput_dir = \"./results\"\n\n# Number of training epochs. Epochs efers to one complete pass through the entire training dataset. During an epoch, the model processes each example in the training set once and updates its weights accordingly\n# In machine learning, particularly in training neural networks, the term \"number of training epochs\" refers to the number of times the entire training dataset is passed forward and backward through the neural network. Each pass through the entire dataset is counted as one epoch.\n\nnum_train_epochs = 10\n\n# Enable fp16/bf16 training (set bf16 to True with an A100)\nfp16 = False\nbf16 = False\n\n# Batch size per GPU for training\nper_device_train_batch_size = 4\n\n# Batch size per GPU for evaluation\nper_device_eval_batch_size = 4\n\n# Number of steps to accumulate gradients before updating model weights.\ngradient_accumulation_steps = 1\n\n#  Enables saving memory during training by checkpointing gradients.\ngradient_checkpointing = True\n\n# Maximum gradient normal (gradient clipping)\nmax_grad_norm = 0.3\n\n# Initial learning rate (AdamW optimizer)\nlearning_rate = 2e-4\n\n# Weight decay to apply to all layers except bias/LayerNorm weights\nweight_decay = 0.001\n\n# Optimizer to use\noptim = \"paged_adamw_32bit\"\n\n# Learning rate schedule (constant a bit better than cosine)\nlr_scheduler_type = \"constant\"\n\n# Number of training steps (overrides num_train_epochs)\nmax_steps = -1\n\n# Ratio of steps for a linear warmup (from 0 to learning rate)\nwarmup_ratio = 0.03\n\n# Group sequences into batches with same length\n# Saves memory and speeds up training considerably\ngroup_by_length = True\n\n# Save checkpoint every X updates steps\nsave_steps = 25\n\n# Log every X updates steps\nlogging_steps = 25\n\n################################################################################\n# SFT parameters\n################################################################################\n\n# Maximum sequence length to use\nmax_seq_length = None\n\n# Pack multiple short examples in the same input sequence to increase efficiency\npacking = False\n\n# Load the entire model on the GPU 0\ndevice_map = {\"\": 0}\n</code></pre>"},{"location":"Task8a/#load-tokenizer","title":"Load tokenizer","text":"<p>Step 7: Load Tokenizer </p> <pre><code>compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=use_4bit,\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=use_nested_quant,\n)\n\n# Check GPU compatibility with bfloat16\nif compute_dtype == torch.float16 and use_4bit:\n    major, _ = torch.cuda.get_device_capability()\n    if major &gt;= 8:\n        print(\"=\" * 80)\n        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n        print(\"=\" * 80)\n\n# Load base model\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=device_map\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\n# Load LLaMA tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n\n# Set the padding token and EOS token to the same value\n# tokenizer.pad_token = \"&lt;/s&gt;\"\n# tokenizer.add_special_tokens({'eos_token': '&lt;/s&gt;'})\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\n</code></pre>"},{"location":"Task8a/#load-lora-configuration","title":"Load LoRA configuration","text":"<p>Step 8: Load Lora Config </p> <pre><code>peft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n</code></pre>"},{"location":"Task8a/#setting-peft-parameters","title":"Setting Peft Parameters","text":"<p>Step 9: Setting Peft Config </p> <pre><code># Set training parameters\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    fp16=fp16,\n    bf16=bf16,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=group_by_length,\n    lr_scheduler_type=lr_scheduler_type,\n    report_to=\"tensorboard\"\n)\n\n# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=packing,\n)\n</code></pre> <ul> <li>Supervised fine-tuning (SFT) is a key step in reinforcement learning. We will provide SFT Trainer the model, dataset, Lora configuration, tokenizer, and training parameters.</li> </ul> <p></p> <p>Step 10: We will use .train() to fine-tune the Llama 2 model on our new dataset.</p> <pre><code>trainer.train()\n</code></pre> <p></p> <p>Note: Given our minimal dataset, the training process may take up to 10 minutes. However, with larger datasets, the training duration can range from an hour to several hours, depending on the size and complexity of the data. </p> <p>Step 11: After training the model, we will save the model adopter and tokenizers.</p> <pre><code>trainer.model.save_pretrained(new_model)\ntrainer.tokenizer.save_pretrained(new_model)\n</code></pre> <p></p> <p></p> <p>Step 12: To ensure our model is functioning correctly, let's ask a question from our dataset. While a more comprehensive evaluation is necessary for production, we can perform a basic check in our lab using the text generation pipeline. For instance, we can ask, \"What capabilities does the Webex App offer when integrated with Webex Calling?\" Note that the input is formatted to match Llama 2's prompt template. </p> <ul> <li>Our dataset on HF</li> </ul> <p></p> <pre><code># Run text generation pipeline with our next model\nprompt = \"What are the considerations for video calls in Webex Calling?\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\nresult = pipe(f\"&lt;s&gt;[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])\n</code></pre> <p></p>"},{"location":"Task8a/#merge-lora-adapters-with-base-model-and-saving-our-model","title":"Merge LoRA adapters with base model and saving our model","text":"<p> Step 13:  Merge LoRA adapters </p> <ul> <li>To store our newly fine-tuned  WebexOneDemo-Llama-2-7b-chat-finetune  model, we need to merge the LoRA weights with the base model. This involves reloading the base model with FP16 precision and using the PEFT library to combine all components.</li> </ul> <pre><code>base_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)\nmodel = PeftModel.from_pretrained(base_model, new_model)\nmodel = model.merge_and_unload()\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n# tokenizer.pad_token = \"&lt;/s&gt;\"\n# tokenizer.add_special_tokens({'eos_token': '&lt;/s&gt;'})\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\n</code></pre> <p> Optional STEP: if you run out of GPU memory - Create a function to clear GPU cache on google colab </p> <pre><code># Function to clear GPU cache\ndef clear_gpu_cache():\n    torch.cuda.empty_cache()\n\nclear_gpu_cache()\n</code></pre> <p> Step 14:  Push our model and tokenizer to Hugging Face</p> <ul> <li>We can now push everything to the Hugging Face Hub to save our model.</li> </ul> <pre><code>model.push_to_hub(new_model, use_temp_dir=False)\n# tokenizer.push_to_hub(new_model, use_temp_dir=False) # Get push automatically\n</code></pre> <p>Or we can push it to the org that we created earlier called - WebexOne</p> <pre><code>org_name = \"WebexOne\" \nmodel.push_to_hub(f\"{org_name}/{new_model}\", use_temp_dir=False)\ntokenizer.push_to_hub(f\"{org_name}/{new_model}\", use_temp_dir=False)\n</code></pre> <p></p> <p></p>"},{"location":"Task8a/#load-the-pretrained-model-from-hugging-face-and-use-for-inference","title":"Load the  pretrained model from Hugging Face and use for inference","text":"<ul> <li>The Model Hub simplifies the process of selecting the appropriate model. You can now use this model for inference by loading it like any other Llama 2 model from the Hub. Let's explore how to use the model we've uploaded.</li> </ul> <p> Step 15:  login into Hugging Face hub </p> <p></p> <ul> <li>We select the WebexOne/WebexOneDemo-Llama-2-7b-chat-finetune model. Click Use this model.</li> </ul> <p></p> <p>Note: The inference api requires that the model repo have a certain amount of user activity before it can be used directly on api-inference or \"Use the model\" tab appears. If you having issues please speak with the lab proctor</p> <ul> <li>Lets click on Transformer so we can instantiate it using the pipeline() function:</li> </ul> <p></p> <p> Step 16: Copy the code for transformers </p> <pre><code>from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n# Load the model and tokenizer\nmodel_name = \"WebexOne/WebexOneDemo-Llama-2-7b-chat-finetune\"\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n</code></pre> <p></p> <p>The process involves downloading the necessary files for the model and tokenizer from the Hub to ensure the model and tokenizer work correctly.  Followed by loading them into memory so they can be used for generating text. When downloading a model, the following components are typically fetched:</p> <ul> <li> <p>Model Configuration: Defines the architecture and hyperparameters (config.json).</p> </li> <li> <p>Weight Shards: Large binary files containing the model's trained parameters (pytorch_model-00001-of-00002.bin, pytorch_model-00002-of-00002.bin).</p> </li> <li> <p>Index Files: Help manage and load weight shards (pytorch_model.bin.index.json).</p> </li> <li> <p>Generation Configuration: Specifies settings for text generation tasks (generation_config.json).</p> </li> <li> <p>Tokenizer Files: Include configuration, the tokenizer model, and mappings for converting text to tokens (tokenizer_config.json, tokenizer.model, tokenizer.json).</p> </li> <li> <p>Special Tokens: Ensures special tokens are correctly handled (added_tokens.json, special_tokens_map.json).</p> </li> </ul> <p> Step 17: Instantiate using the pipeline() function </p> <p><pre><code># Set up the text generation pipeline\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_length=200,\n    pad_token_id=tokenizer.eos_token_id  # Ensure the padding token is correctly set\n)\n</code></pre>  Step 18: Example 1: </p> <p> Note :  Lets take one question from our dataset.</p> <pre><code># Define the prompt\nprompt = \"What is the Private Network Connect (PNC) solution?\"\n\n# Run the text generation pipeline with the prompt\nresult = pipe(f\"&lt;s&gt;[INST] {prompt} [/INST]\")\n\n# Print the generated text\nprint(result[0]['generated_text'])\n</code></pre> <p> Output: </p> <p></p> <p> Step 19: Example 2: </p> <p> Note :  Lets take one question from our dataset.</p> <pre><code># Define the prompt\nprompt = \"What happens if ICE negotiation fails in Webex Calling?\"\n\n# Run the text generation pipeline with the prompt\nresult = pipe(f\"&lt;s&gt;[INST] {prompt} [/INST]\")\n\n# Print the generated text\nprint(result[0]['generated_text'])\n</code></pre> <p> Output: </p> <p></p>"},{"location":"Task8a/#fine-tuning-example-2","title":"Fine Tuning - Example 2","text":"<p>In this example, I will show you how to fine-tune using the Cisco IP DECT Phone 6800 Series Deployment Guide . I have already created the dataset from the PDF, which can be found at WebexOne/dect1</p> <p> Step 1: Import the Necessary Libraries </p> <pre><code>import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer\nfrom dotenv import load_dotenv\n</code></pre> <p> Step 2: Load your HuggingFace tokens </p> <pre><code>from google.colab import userdata\nos.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n</code></pre> <p>Note: Optional Step - If using Jupyter notebook on your machine. Create a .env folder, add your HuggingFace token. Then, import the token.  Optional STEP<pre><code>load_dotenv()\nhf_token = os.getenv(\"HF_TOKEN\")\n</code></pre> </p> <p> Step 3: Load your Datasets and models </p> <pre><code># The instruction dataset to use that we created earlier\ndataset_name = \"WebexOne/dect1\"\n# Load dataset (you can process it here)\ndataset = load_dataset(dataset_name, split=\"train\")\n# model_name = \"meta-llama/Llama-2-7b-hf\" as its a gated repo\nmodel_name = \"NousResearch/Llama-2-7b-chat-hf\"\nnew_model = \"dect-phone-Llama-2-7b-Finale\"\n</code></pre> <p>Note: You can name the new_model variable whatever you prefer. </p> <p> Step 4: Load pre-trained model with 4-bit quantization</p> <pre><code>###############################################################################\n# QLoRA parameters - That we will use\n################################################################################\n\n# LoRA attention dimension . A higher value increases the model's capacity to learn but also its computational cost. The higher the rank the more parameters you train and the bigger your adapter files will be.\nlora_r = 64\n\n# Alpha parameter for LoRA scaling. It controls the trade-off between model capacity and stability.\nlora_alpha = 16\n\n# Dropout probability for LoRA layers. The dropout probability applied to the LoRA layers to prevent overfitting.\nlora_dropout = 0.1\n\n################################################################################\n# bitsandbytes parameters\n################################################################################\n\n# Activate 4-bit precision base model. Enables loading the base model with 4-bit precision, which orangeuces memory usage.\nuse_4bit = True\n\n# Compute dtype for 4-bit base models. Specifies the data type for computations in 4-bit precision models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4) we\u2019ll load the Llama 2 model directly in 4-bit precision using the NF4 type\nbnb_4bit_quant_type = \"nf4\"\n\n# Activate or Deactivate nested quantization for 4-bit base models (double quantization)\nuse_nested_quant = False\n\n################################################################################\n# TrainingArguments parameters\n################################################################################\n\n# Output directory where the model porangeictions and checkpoints will be stoorange\noutput_dir = \"./dectresults1\"\n\n# Number of training epochs. Epochs efers to one complete pass through the entire training dataset. During an epoch, the model processes each example in the training set once and updates its weights accordingly\nnum_train_epochs = 10\n\n# Enable fp16/bf16 training (set bf16 to True with an A100)\nfp16 = False\nbf16 = False\n\n# Batch size per GPU for training\nper_device_train_batch_size = 4\n\n# Batch size per GPU for evaluation\nper_device_eval_batch_size = 4\n\n# Number of steps to accumulate gradients before updating model weights.\ngradient_accumulation_steps = 1\n\n#  Enables saving memory during training by checkpointing gradients.\ngradient_checkpointing = True\n\n# Maximum gradient normal (gradient clipping)\nmax_grad_norm = 0.3\n\n# Initial learning rate (AdamW optimizer)\nlearning_rate = 2e-4\n\n# Weight decay to apply to all layers except bias/LayerNorm weights\nweight_decay = 0.001\n\n# Optimizer to use\noptim = \"paged_adamw_32bit\"\n\n# Learning rate schedule (constant a bit better than cosine)\nlr_scheduler_type = \"constant\"\n\n# Number of training steps (overrides num_train_epochs)\nmax_steps = -1\n\n# Ratio of steps for a linear warmup (from 0 to learning rate)\nwarmup_ratio = 0.03\n\n# Group sequences into batches with same length\n# Saves memory and speeds up training considerably\ngroup_by_length = True\n\n# Save checkpoint every X updates steps\nsave_steps = 25\n\n# Log every X updates steps\nlogging_steps = 25\n\n################################################################################\n# SFT parameters\n################################################################################\n\n# Maximum sequence length to use\nmax_seq_length = None\n\n# Pack multiple short examples in the same input sequence to increase efficiency\npacking = False\n\n# Load the entire model on the GPU 0\ndevice_map = {\"\": 0}\n</code></pre> <p> Step 5: Configure PEFT and Training Parameters</p> <pre><code>peft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\n# Set training parameters\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    fp16=fp16,\n    bf16=bf16,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=group_by_length,\n    lr_scheduler_type=lr_scheduler_type,\n    report_to=\"tensorboard\"\n)\n\n# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=packing,\n)\n</code></pre> <p> Step 6: Train the Model Using the Trainer API and Save the model</p> <pre><code>trainer.train()\ntrainer.model.save_pretrained(new_model)\n</code></pre> <p> Testing the model Locally</p> <pre><code># Run text generation pipeline with our next model\nprompt = \"What is a key consideration when planning the DECT system for different regions?\"\nsys1 = \"You are an interviewer AI tasked with asking questions about a deployment guide for the Cisco IP DECT Phone 6800 Series. Your goal is to elicit detailed responses from the text as if the pdf itself were answering. Be polite and address the user's query directly. Aim to offer clear and accurate answers. If you dont find the answer in pdf just say no info available at this time please contact your Cisco TME\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\nresult = pipe(f\"&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt; {sys1} &lt;&lt;/SYS&gt;&gt; {prompt} [/INST]\")\nprint(result[0]['generated_text'])\n</code></pre> <p> Step 7: Push the Model to Hub <pre><code>model.push_to_hub(new_model, use_temp_dir=False)\ntokenizer.push_to_hub(new_model, use_temp_dir=False)\n</code></pre></p> <p> Step 8: Verify the Model: </p> <ul> <li>Log in to the Hugging Face Hub and navigate to your model's page.</li> <li>Click on \"Use this model\" and then \"Transformers\".</li> <li>Copy the provided code snippet for using the model.</li> </ul> <p></p> <p> Step 9: Configure Inferencing </p> <pre><code># Load model directly\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\ntokenizer = AutoTokenizer.from_pretrained(\"compile2011/dect-phone-Llama-2-7b-Finale\")\nmodel = AutoModelForCausalLM.from_pretrained(\"compile2011/dect-phone-Llama-2-7b-Finale\")\nfrom transformers import pipeline\npipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_length=200,\n    pad_token_id=tokenizer.eos_token_id  # Ensure the padding token is correctly set\n)\n</code></pre> <p> Step 10: Inferencing with downloaded Model to test </p> <pre><code># Run text generation pipeline with our next model\nprompt = \"What is a key consideration when planning the DECT system for different regions?\"\nsys1 = \"You are an interviewer AI tasked with asking questions about a deployment guide for the Cisco IP DECT Phone 6800 Series. Your goal is to elicit detailed responses from the text as if the pdf itself were answering. Be polite and address the user's query directly. Aim to offer clear and accurate answers. If you dont find the answer in pdf just say no info available at this time please contact your Cisco TME\"\n# pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=200)\nresult = pipe(f\"&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt; {sys1} &lt;&lt;/SYS&gt;&gt; {prompt} [/INST]\")\nprint(result[0]['generated_text'])\n</code></pre> <p>  OUTPUT  <pre><code>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt; You are an interviewer AI tasked with asking questions about a deployment guide for the Cisco IP DECT Phone 6800 Series. Your goal is to elicit detailed responses from the text as if the pdf itself were answering. Be polite and address the user's query directly. Aim to offer clear and accurate answers. If you dont find the answer in pdf just say no info available at this time please contact your Cisco TME &lt;&lt;/SYS&gt;&gt; What is a key consideration when planning the DECT system for different regions? [/INST]\nConsider the regulatory requirements for DECT frequencies in different regions. Cisco offers units set up correctly for each region, such as 1880-1900 MHz for Australia and New Zealand, 1880-1900 MHz for E.U. and APAC. \n</code></pre></p>"},{"location":"Task8a/#troubleshooting-best-practices","title":"Troubleshooting - Best Practices","text":"<ul> <li>Challenges are an inherent part of model training. Let's discuss some common issues and their resolutions.</li> </ul>"},{"location":"Task8a/#out-of-memory-oom-errors","title":"Out of Memory (OOM) Errors","text":"<ul> <li> <p>If you encounter an Out of Memory (OOM) error:</p> <ul> <li>orangeuce Batch Size: Lowering the batch size can help fit the model into memory.</li> <li>Shorten Training Samples: Decrease the context length (e.g., max_length in tokenize()).</li> </ul> </li> </ul>"},{"location":"Task8a/#slow-training","title":"Slow Training","text":"<ul> <li> <p>If training seems sluggish:</p> <ul> <li> <p>Increase Batch Size: A larger batch size can speed up training.</p> </li> <li> <p>Use Multiple GPUs: Consider using multiple GPUs, either by purchasing or renting (e.g., on platforms like Runpod). The provided code is compatible with accelerate for multi-GPU settings. Simply launch it with  accelerate launch your_file.py  instead of  python your_file.py </p> </li> </ul> </li> </ul>"},{"location":"Task8a/#poor-model-quality","title":"Poor Model Quality","text":"<p>The quality of your model reflects the quality of your dataset. To improve model quality ensure your dataset is rich and relevant.</p>"},{"location":"Task8a/#metadata-info-on-huggingface-optional","title":"Metadata - Info on HuggingFace - Optional","text":"<pre><code>---\ninference: true\nlanguage:\n- en\npipeline_tag: text-generation\ntags:\n- facebook\n- meta\n- pytorch\n- llama\n- llama-2\nlicense: llama2\nlibrary_name: transformers\n---\n</code></pre>"},{"location":"Task8a/#conclusions","title":"Conclusions","text":"<p>So, we have exploorange the process of fine-tuning our model and performing inference with it. Now, let\u2019s say you have successfully trained or fine-tuned your model and are ready to deploy it for widespread use. However, you notice that the latency is too slow, and you want to speed up the model. There are four key methods you can employ to enhance your model's performance. While these steps are not coveorange in this lab, they serve as a good starting point for further investigation:</p> <ul> <li>Quantization</li> <li>Pruning</li> <li>Model or Knowledge Distillation</li> <li>Engineering Optimizations</li> </ul>"},{"location":"Task8b/","title":"Task 8b - Configuring and Fine Tuning - Using llama3","text":""},{"location":"Task8b/#introduction","title":"Introduction","text":"<p>This diagram represents the workflow of training and using a LLM. </p> <p>Note: This diagram is referenced from Task8a</p>"},{"location":"Task8b/#pre-requisites","title":"Pre-requisites","text":"<p>Note: Referenced from Task8a</p>"},{"location":"Task8b/#usecase-1-fine-tuning-using-llama2","title":"UseCase 1 - Fine Tuning Using Llama2","text":""},{"location":"Task8b/#datasets-creation","title":"Datasets Creation","text":"<p>As we will be using and fine tuning Llama3 base model we need to convert datasets into a uniform format compatible with Llama3. More Info at</p>"},{"location":"Task8b/#example-format-for-llama3-instruct","title":"Example Format for Llama3 - Instruct","text":"Sample Format - Dont Copy - reference ONLY<pre><code>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt; You are a helpful AI assistant for  Collaboration&lt;|eot_id|&gt;\n\n                 &lt;|start_header_id|&gt;user&lt;|end_header_id|&gt; What can you help me with?&lt;|eot_id|&gt;\n\n                 &lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n</code></pre> <ul> <li>&lt;|begin_of_text|&gt;: Specifies the start of the prompt</li> <li>&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;: Specifies the role for the following message, i.e. \u201csystem\u201d You are a helpful AI assistant for Collaboration</li> <li>&lt;|eot_id|&gt;: Specifies the end of the input message</li> <li>&lt;|start_header_id|&gt;user&lt;\\end_header_id|&gt;: Specifies the role for the following message i.e. \u201cuser\u201d What can you help me with?: The user message</li> <li>&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;: Ends with the assistant header, to prompt the model to start generation.</li> </ul>"},{"location":"Task8b/#datasets-creation_1","title":"Datasets Creation","text":"<p>The next step is to prepare a dataset for fine-tuning. If you already have a clean, high-quality dataset, that's great. However, let's assume you don't have one readily available.</p> <p>In my scenario, I was able to generate synthetic dataset from the Cisco Preferred Architecture for Webex Calling.</p>"},{"location":"Task8b/#creating-a-dataset-from-a-pdf-summary","title":"Creating a Dataset from a PDF - Summary","text":"<p>To delve into the intricacies of dataset creation, let's explore a scenario where we aim to train an AI to replicate our preferred architecture. In this lab, we will transform a PDF document into a dataset. Specifically, we will use a PDF about Webex Calling as our source material.</p> <p>Steps Involved</p> <p>Converting the PDF to Text</p> <ul> <li>Begin by extracting the text content from the PDF document.</li> </ul> <p>Paragraph Analysis and Segmentation:</p> <ul> <li>Once the PDF is in text form, analyze and segment it into individual paragraphs. Combine short paragraphs and split longer ones to ensure each segment is coherent and self-contained, while still contributing to the overall narrative.</li> </ul> <p>Generating Interview Questions:</p> <ul> <li>For each paragraph, create an artificial interview scenario where a language model (LLM) acts as the interviewer.</li> <li>Develop questions that naturally elicit responses based on the content of the paragraph.</li> <li>The objective is to simulate an insightful dialogue, making it seem as though the PDF is responding to questions about its content and experiences.</li> </ul> <p>By following these steps, we will convert the static information in the PDF into a dynamic and interactive dataset, facilitating a deeper understanding and more engaging learning experience.</p> <p>Here's an example of the resulting file. Please note that for this lab demonstration, only a few data points were converted from the PDF.</p> <p>Note: We will use the following file to create and eventually train downstream tasks for our LLM, specifically the Llama3 model.</p>"},{"location":"Task8b/#sample-file","title":"Sample File","text":"example_llama3.json<pre><code>[\n    {\n        \"question\":\"What is the solution provided by Webex Calling?\",\n        \"context\":\"Webex Calling is part of an integrated, intelligent, and modular team collaboration suite. It provides enterprise-grade PBX features, functionality, and performance previously only possible with an on-premises PBX network.\",\n        \"answer\":\"Webex Calling provides enterprise-grade PBX features, functionality, and performance.\"\n    },\n    {\n        \"question\":\"What options are available for PSTN access in Webex Calling?\",\n        \"context\":\"Webex Calling can access the PSTN in three ways: Cisco Calling Plans, Cloud Connected PSTN, and Premises-based PSTN.\",\n        \"answer\":\"The options are Cisco Calling Plans, Cloud Connected PSTN, and Premises-based PSTN.\"\n    },\n    {\n        \"question\":\"What type of devices does Webex Calling support?\",\n        \"context\":\"Webex Calling supports a wide range of Cisco MPP Series IP Phones (6800, 7800, and 8800 Series), Webex Devices, and a variety of third-party devices.\",\n        \"answer\":\"Webex Calling supports Cisco MPP Series IP Phones, Webex Devices, and a variety of third-party devices.\"\n    },\n    {\n        \"question\":\"How are Webex Calling data centers distributed?\",\n        \"context\":\"Webex Calling data centers are globally distributed and geo-redundant. The data centers are located in six regions: US, Canada, Europe, UK, Australia, and Japan.\",\n        \"answer\":\"Webex Calling data centers are globally distributed and geo-redundant, located in six regions: US, Canada, Europe, UK, Australia, and Japan.\"\n    },\n    {\n        \"question\":\"What is the function of the Local Gateway in Webex Calling?\",\n        \"context\":\"A Local Gateway connects to the PSTN either directly by terminating a PSTN trunk or by connecting to an existing PSTN gateway via a SIP trunk. It also registers with Webex Calling and handles all calls between the PSTN and Webex Calling.\",\n        \"answer\":\"The Local Gateway connects to the PSTN and registers with Webex Calling to handle all calls between the PSTN and Webex Calling.\"\n    },\n    {\n        \"question\":\"What are the key benefits of Webex Calling for large enterprises?\",\n        \"context\":\"Webex Calling provides large enterprises with scalability, advanced call management features, and integration with other collaboration tools to streamline communication.\",\n        \"answer\":\"Webex Calling offers scalability, advanced call management, and integration with collaboration tools for large enterprises.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle call encryption?\",\n        \"context\":\"Webex Calling uses SRTP for media encryption and TLS for signaling encryption to ensure secure communications.\",\n        \"answer\":\"SRTP and TLS are used in Webex Calling to encrypt media and signaling for secure communications.\"\n    },\n    {\n        \"question\":\"What features are included in the Webex Calling analytics suite?\",\n        \"context\":\"Webex Calling offers analytics on call quality, usage patterns, and performance metrics to help optimize communication systems.\",\n        \"answer\":\"Call quality, usage patterns, and performance metrics are part of the Webex Calling analytics suite.\"\n    },\n    {\n        \"question\":\"How does Webex Calling integrate with third-party devices?\",\n        \"context\":\"Webex Calling supports integration with third-party SIP phones, enabling flexibility in device choices.\",\n        \"answer\":\"Integration with third-party SIP phones provides flexibility in device choices for Webex Calling users.\"\n    },\n    {\n        \"question\":\"What disaster recovery mechanisms are available in Webex Calling?\",\n        \"context\":\"Webex Calling ensures disaster recovery through geo-redundant data centers and automatic failover mechanisms.\",\n        \"answer\":\"Geo-redundant data centers and automatic failover mechanisms support disaster recovery in Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling manage international call routing?\",\n        \"context\":\"International call routing in Webex Calling is managed through a global network of data centers to ensure high-quality communication.\",\n        \"answer\":\"A global network of data centers manages international call routing in Webex Calling.\"\n    },\n    {\n        \"question\":\"What role does the Webex Control Hub play in Webex Calling?\",\n        \"context\":\"The Webex Control Hub is used for provisioning, configuring, and managing Webex Calling services from a centralized interface.\",\n        \"answer\":\"Provisioning, configuring, and managing Webex Calling services are handled through the Webex Control Hub.\"\n    },\n    {\n        \"question\":\"What are the main security protocols used in Webex Calling?\",\n        \"context\":\"Webex Calling uses SRTP for media encryption and TLS for signaling encryption to protect communications.\",\n        \"answer\":\"SRTP and TLS are the main security protocols used in Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support mobile users?\",\n        \"context\":\"Webex Calling supports mobile users through the Webex App, which allows calls to be made and received on smartphones and tablets.\",\n        \"answer\":\"The Webex App enables mobile users to make and receive calls on smartphones and tablets in Webex Calling.\"\n    },\n    {\n        \"question\":\"What are the benefits of Webex Calling for remote teams?\",\n        \"context\":\"Webex Calling provides remote teams with enterprise-grade calling features, mobility, and integration with collaboration tools.\",\n        \"answer\":\"Remote teams benefit from enterprise-grade calling features, mobility, and collaboration tool integration in Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling ensure compliance with regulatory requirements?\",\n        \"context\":\"Webex Calling includes features such as call recording, monitoring, and secure data handling to ensure compliance with regulatory requirements.\",\n        \"answer\":\"Compliance with regulatory requirements in Webex Calling is ensured through call recording, monitoring, and secure data handling.\"\n    },\n    {\n        \"question\":\"What redundancy features are built into Webex Calling?\",\n        \"context\":\"Webex Calling includes redundancy features like geo-redundant data centers and automatic failover to ensure continuous service.\",\n        \"answer\":\"Geo-redundant data centers and automatic failover ensure continuous service in Webex Calling.\"\n    },\n    {\n        \"question\":\"What user management capabilities are available in Webex Calling?\",\n        \"context\":\"Webex Calling provides user management capabilities through the Webex Control Hub, allowing administrators to configure user settings and permissions.\",\n        \"answer\":\"User settings and permissions are managed through the Webex Control Hub in Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle call routing?\",\n        \"context\":\"Call routing in Webex Calling is managed through dial plans and routing rules that can be customized to meet business needs.\",\n        \"answer\":\"Dial plans and customizable routing rules manage call routing in Webex Calling.\"\n    },\n    {\n        \"question\":\"What kind of customer support does Cisco provide for Webex Calling?\",\n        \"context\":\"Cisco provides comprehensive customer support for Webex Calling, including technical assistance, training, and resources for deployment and management.\",\n        \"answer\":\"Technical assistance, training, and deployment resources are part of Cisco's support for Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support hybrid deployments?\",\n        \"context\":\"Webex Calling supports hybrid deployments by integrating with both cloud and on-premises PBX systems, allowing for seamless communication.\",\n        \"answer\":\"Integration with cloud and on-premises PBX systems supports hybrid deployments in Webex Calling.\"\n    },\n    {\n        \"question\":\"What are the call management features in Webex Calling?\",\n        \"context\":\"Webex Calling provides call management features such as call forwarding, call transfer, call hold, and voicemail.\",\n        \"answer\":\"Call management features in Webex Calling include call forwarding, call transfer, call hold, and voicemail.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support video calls?\",\n        \"context\":\"Webex Calling supports video calls between video-capable devices, allowing users to make and receive video calls seamlessly.\",\n        \"answer\":\"Video calls are supported between video-capable devices in Webex Calling.\"\n    },\n    {\n        \"question\":\"What compliance features are available in Webex Calling?\",\n        \"context\":\"Webex Calling includes compliance features such as call recording, logging, and monitoring to meet regulatory requirements.\",\n        \"answer\":\"Compliance features in Webex Calling include call recording, logging, and monitoring.\"\n    },\n    {\n        \"question\":\"What is the function of SRTP in Webex Calling?\",\n        \"context\":\"Secure Real-Time Transport Protocol (SRTP) is used to encrypt media streams in Webex Calling, ensuring secure communication.\",\n        \"answer\":\"SRTP encrypts media streams in Webex Calling to ensure secure communication.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support call analytics?\",\n        \"context\":\"Webex Calling offers detailed call analytics, including metrics on call quality, usage patterns, and performance to help optimize communication systems.\",\n        \"answer\":\"Webex Calling provides detailed call analytics on call quality, usage patterns, and performance.\"\n    },\n    {\n        \"question\":\"What kind of redundancy features are available in Webex Calling?\",\n        \"context\":\"Webex Calling includes geo-redundant data centers and automatic failover mechanisms to ensure continuous service and high availability.\",\n        \"answer\":\"Redundancy features in Webex Calling include geo-redundant data centers and automatic failover.\"\n    },\n    {\n        \"question\":\"How does Webex Calling ensure secure voice communications?\",\n        \"context\":\"Webex Calling uses encryption protocols such as SRTP for media and TLS for signaling to protect voice communications.\",\n        \"answer\":\"Encryption protocols like SRTP for media and TLS for signaling ensure secure voice communications in Webex Calling.\"\n    },\n    {\n        \"question\":\"What integrations does Webex Calling offer with contact center solutions?\",\n        \"context\":\"Webex Calling integrates with Webex Contact Center, providing advanced features like call routing, IVR, and analytics to enhance customer service operations.\",\n        \"answer\":\"Integration with Webex Contact Center offers advanced features like call routing, IVR, and analytics.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle call monitoring and recording?\",\n        \"context\":\"Webex Calling includes features for call monitoring and recording, which can be used for compliance, training, and quality assurance purposes.\",\n        \"answer\":\"Call monitoring and recording features in Webex Calling support compliance, training, and quality assurance.\"\n    },\n    {\n        \"question\":\"What options are available for user authentication in Webex Calling?\",\n        \"context\":\"User authentication in Webex Calling is managed through secure protocols and can integrate with identity providers for single sign-on (SSO).\",\n        \"answer\":\"Webex Calling supports user authentication through secure protocols and integration with identity providers for SSO.\"\n    },\n    {\n        \"question\":\"What is the role of the Webex App in Webex Calling?\",\n        \"context\":\"The Webex App provides a unified interface for messaging, video conferencing, and calling, allowing users to manage all communication needs from a single platform.\",\n        \"answer\":\"The Webex App unifies messaging, video conferencing, and calling for a seamless communication experience.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support international business operations?\",\n        \"context\":\"Webex Calling supports international operations with global data centers, ensuring reliable and high-quality voice communication around the world.\",\n        \"answer\":\"Global data centers support reliable and high-quality voice communication for international operations in Webex Calling.\"\n    },\n    {\n        \"question\":\"What management capabilities does Webex Calling provide?\",\n        \"context\":\"Webex Calling offers comprehensive management tools through the Webex Control Hub, allowing for centralized provisioning, configuration, and monitoring of services.\",\n        \"answer\":\"The Webex Control Hub provides centralized provisioning, configuration, and monitoring for Webex Calling services.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle voice and video integration?\",\n        \"context\":\"Webex Calling integrates with Webex Meetings and Webex Teams to provide seamless voice and video communication, enhancing collaboration.\",\n        \"answer\":\"Integration with Webex Meetings and Webex Teams allows for seamless voice and video communication in Webex Calling.\"\n    },\n    {\n        \"question\":\"What are the benefits of Webex Calling for large enterprises?\",\n        \"context\":\"Webex Calling offers large enterprises scalability, advanced call management features, and integration with other collaboration tools to streamline communication.\",\n        \"answer\":\"Scalability, advanced call management, and integration with collaboration tools are benefits for large enterprises using Webex Calling.\"\n    },\n    {\n        \"question\":\"What disaster recovery options are available with Webex Calling?\",\n        \"context\":\"Webex Calling ensures disaster recovery through geo-redundant data centers and automatic failover to maintain continuous service.\",\n        \"answer\":\"Geo-redundant data centers and automatic failover provide disaster recovery options in Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling manage call quality?\",\n        \"context\":\"Webex Calling manages call quality with network optimization, advanced codecs, and quality of service (QoS) policies to ensure clear voice communication.\",\n        \"answer\":\"Call quality in Webex Calling is managed through network optimization, advanced codecs, and QoS policies.\"\n    },\n    {\n        \"question\":\"What user profile management features are available in Webex Calling?\",\n        \"context\":\"User profiles in Webex Calling are managed through the Webex Control Hub, allowing administrators to configure settings and permissions.\",\n        \"answer\":\"User profile management features in Webex Calling include settings and permissions configuration through the Webex Control Hub.\"\n    },\n    {\n        \"question\":\"How does Webex Calling integrate with CRM systems?\",\n        \"context\":\"Webex Calling supports integration with CRM systems, enhancing customer interactions and improving business processes.\",\n        \"answer\":\"Integration with CRM systems enhances customer interactions and business processes in Webex Calling.\"\n    },\n    {\n        \"question\":\"What compliance features does Webex Calling offer?\",\n        \"context\":\"Webex Calling includes compliance features such as call recording, monitoring, and secure data handling to meet regulatory requirements.\",\n        \"answer\":\"Compliance features in Webex Calling include call recording, monitoring, and secure data handling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support remote teams?\",\n        \"context\":\"Webex Calling supports remote teams by providing enterprise-grade calling features, mobility, and integration with collaboration tools.\",\n        \"answer\":\"Remote teams benefit from enterprise-grade calling features, mobility, and collaboration tool integration in Webex Calling.\"\n    },\n    {\n        \"question\":\"What are the main security features of Webex Calling?\",\n        \"context\":\"Webex Calling includes security features such as encryption, secure voice, and compliance with industry standards to protect communications.\",\n        \"answer\":\"Security features in Webex Calling include encryption, secure voice, and industry-standard compliance.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle emergency call routing?\",\n        \"context\":\"Emergency call routing in Webex Calling is managed through predefined routing rules that ensure calls are directed to the appropriate emergency services.\",\n        \"answer\":\"Predefined routing rules manage emergency call routing in Webex Calling.\"\n    },\n    {\n        \"question\":\"What kind of support does Cisco provide for Webex Calling?\",\n        \"context\":\"Cisco provides comprehensive support for Webex Calling, including technical assistance, training, and resources for deployment and management.\",\n        \"answer\":\"Technical assistance, training, and deployment resources are part of Cisco's support for Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support hybrid work environments?\",\n        \"context\":\"Webex Calling supports hybrid work environments by integrating with both cloud and on-premises PBX systems, allowing for seamless communication.\",\n        \"answer\":\"Webex Calling supports hybrid work environments by integrating with cloud and on-premises PBX systems.\"\n    },\n    {\n        \"question\":\"What management tools are available in Webex Calling?\",\n        \"context\":\"Webex Calling provides management tools such as the Webex Control Hub for provisioning, configuring, and managing services.\",\n        \"answer\":\"Management tools in Webex Calling include the Webex Control Hub for provisioning, configuring, and managing services.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle call quality issues?\",\n        \"context\":\"Webex Calling includes tools for monitoring call quality and diagnosing issues, ensuring high-quality voice communication.\",\n        \"answer\":\"Tools for monitoring and diagnosing issues ensure high-quality voice communication in Webex Calling.\"\n    },\n    {\n        \"question\":\"What kind of analytics does Webex Calling offer?\",\n        \"context\":\"Webex Calling offers analytics on call quality, usage patterns, and performance metrics to help optimize communication.\",\n        \"answer\":\"Analytics on call quality, usage patterns, and performance metrics are available in Webex Calling.\"\n    },\n    {\n        \"question\":\"What devices are compatible with Webex Calling?\",\n        \"context\":\"Webex Calling is compatible with a range of devices including Cisco IP Phones, Webex Room Devices, and third-party SIP phones.\",\n        \"answer\":\"Compatible devices for Webex Calling include Cisco IP Phones, Webex Room Devices, and third-party SIP phones.\"\n    },\n    {\n        \"question\":\"How does Webex Calling integrate with Webex Meetings?\",\n        \"context\":\"Webex Calling integrates with Webex Meetings to provide a seamless experience for scheduling and joining video meetings.\",\n        \"answer\":\"Integration with Webex Meetings provides a seamless experience for scheduling and joining video meetings in Webex Calling.\"\n    },\n    {\n        \"question\":\"What role does Webex Control Hub play in Webex Calling?\",\n        \"context\":\"Webex Control Hub is used for provisioning, configuring, and managing Webex Calling services, providing a centralized management interface.\",\n        \"answer\":\"Webex Control Hub provides a centralized interface for provisioning, configuring, and managing Webex Calling services.\"\n    },\n    {\n        \"question\":\"How does Webex Calling ensure security for voice communications?\",\n        \"context\":\"Webex Calling ensures security through encryption protocols like SRTP for media and TLS for signaling, protecting voice communications.\",\n        \"answer\":\"Encryption protocols like SRTP for media and TLS for signaling ensure security in Webex Calling.\"\n    },\n    {\n        \"question\":\"What features does Webex Calling offer for team collaboration?\",\n        \"context\":\"Webex Calling offers features such as group call management, conferencing, and integration with Webex Teams for enhanced collaboration.\",\n        \"answer\":\"Group call management, conferencing, and Webex Teams integration are features of Webex Calling for team collaboration.\"\n    },\n    {\n        \"question\":\"How is call recording handled in Webex Calling?\",\n        \"context\":\"Call recording in Webex Calling is managed through built-in features that allow recording for compliance, training, and quality assurance.\",\n        \"answer\":\"Built-in call recording features in Webex Calling support compliance, training, and quality assurance.\"\n    },\n    {\n        \"question\":\"What scalability options are available in Webex Calling?\",\n        \"context\":\"Webex Calling is designed to scale from small businesses to large enterprises, supporting thousands of users across multiple locations.\",\n        \"answer\":\"Scalability in Webex Calling supports small businesses to large enterprises, accommodating thousands of users.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support international operations?\",\n        \"context\":\"Webex Calling supports international operations with global data centers, ensuring reliable and high-quality voice communication worldwide.\",\n        \"answer\":\"Global data centers ensure reliable and high-quality voice communication for international operations in Webex Calling.\"\n    },\n    {\n        \"question\":\"What redundancy features are built into Webex Calling?\",\n        \"context\":\"Webex Calling includes redundancy features like geo-redundant data centers and automatic failover to ensure continuous service.\",\n        \"answer\":\"Redundancy features in Webex Calling include geo-redundant data centers and automatic failover for continuous service.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle user authentication?\",\n        \"context\":\"User authentication in Webex Calling is managed through secure protocols and integration with identity providers for single sign-on (SSO).\",\n        \"answer\":\"Secure protocols and integration with identity providers for single sign-on (SSO) manage user authentication in Webex Calling.\"\n    },\n    {\n        \"question\":\"What reporting capabilities does Webex Calling provide?\",\n        \"context\":\"Webex Calling provides reporting capabilities that include detailed call analytics, usage patterns, and performance metrics.\",\n        \"answer\":\"Detailed call analytics, usage patterns, and performance metrics are part of Webex Calling's reporting capabilities.\"\n    },\n    {\n        \"question\":\"What integrations does Webex Calling support with CRM systems?\",\n        \"context\":\"Webex Calling supports integrations with CRM systems to enhance customer interactions and streamline business processes.\",\n        \"answer\":\"Integrations with CRM systems in Webex Calling enhance customer interactions and streamline business processes.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support compliance with regulations?\",\n        \"context\":\"Webex Calling supports compliance with regulations through features like call recording, monitoring, and secure data handling.\",\n        \"answer\":\"Compliance features in Webex Calling include call recording, monitoring, and secure data handling.\"\n    },\n    {\n        \"question\":\"What is the role of SRTP in Webex Calling?\",\n        \"context\":\"Secure Real-Time Transport Protocol (SRTP) is used in Webex Calling to encrypt voice media streams, ensuring secure communication.\",\n        \"answer\":\"SRTP encrypts voice media streams to ensure secure communication in Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling manage user profiles?\",\n        \"context\":\"User profiles in Webex Calling are managed through the Webex Control Hub, allowing administrators to configure settings and permissions.\",\n        \"answer\":\"Webex Control Hub manages user profiles in Webex Calling, enabling configuration of settings and permissions by administrators.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support video conferencing?\",\n        \"context\":\"Webex Calling supports video conferencing through integration with Webex Meetings, allowing users to join video meetings from their phones or Webex devices.\",\n        \"answer\":\"Webex Calling supports video conferencing via integration with Webex Meetings.\"\n    },\n    {\n        \"question\":\"What is the role of a Local Gateway in Webex Calling?\",\n        \"context\":\"A Local Gateway connects to the PSTN and handles call routing between Webex Calling and on-premises PBX systems.\",\n        \"answer\":\"The Local Gateway connects to the PSTN and handles call routing between Webex Calling and on-premises PBX systems.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle number porting?\",\n        \"context\":\"Webex Calling supports number porting, allowing users to transfer existing phone numbers from another provider to Webex Calling.\",\n        \"answer\":\"Webex Calling allows users to port existing phone numbers from another provider.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support disaster recovery?\",\n        \"context\":\"Webex Calling ensures disaster recovery through geo-redundant data centers and automatic failover mechanisms.\",\n        \"answer\":\"Geo-redundant data centers and automatic failover mechanisms support disaster recovery in Webex Calling.\"\n    },\n    {\n        \"question\":\"What is the Webex Calling architecture?\",\n        \"context\":\"Webex Calling is built on a cloud-based architecture with distributed data centers to ensure high availability and resilience.\",\n        \"answer\":\"Webex Calling has a cloud-based architecture with distributed data centers for high availability and resilience.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support call encryption?\",\n        \"context\":\"Webex Calling uses Secure Real-Time Transport Protocol (SRTP) and Transport Layer Security (TLS) to encrypt call signaling and media.\",\n        \"answer\":\"SRTP and TLS are used to encrypt call signaling and media in Webex Calling.\"\n    },\n    {\n        \"question\":\"What are the benefits of Webex Calling for small businesses?\",\n        \"context\":\"Webex Calling offers small businesses enterprise-grade calling features, scalability, and integration with collaboration tools at a lower cost.\",\n        \"answer\":\"Small businesses benefit from enterprise-grade calling features, scalability, and collaboration tool integration at a lower cost with Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling integrate with existing collaboration tools?\",\n        \"context\":\"Webex Calling integrates with tools like Webex Teams and Microsoft Teams, providing a seamless collaboration experience.\",\n        \"answer\":\"Integration with Webex Teams and Microsoft Teams offers a seamless collaboration experience in Webex Calling.\"\n    },\n    {\n        \"question\":\"What analytics features are available in Webex Calling?\",\n        \"context\":\"Webex Calling provides analytics features such as call quality monitoring, usage reports, and performance dashboards.\",\n        \"answer\":\"Analytics features in Webex Calling include call quality monitoring, usage reports, and performance dashboards.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support mobile devices?\",\n        \"context\":\"Webex Calling supports mobile devices through the Webex App, allowing users to make and receive calls on their smartphones.\",\n        \"answer\":\"The Webex App enables Webex Calling users to make and receive calls on mobile devices.\"\n    },\n    {\n        \"question\":\"What is the role of the Webex App in Webex Calling?\",\n        \"context\":\"The Webex App provides a unified interface for messaging, video conferencing, and calling within Webex Calling.\",\n        \"answer\":\"The Webex App offers a unified interface for messaging, video conferencing, and calling in Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle multi-location deployments?\",\n        \"context\":\"Webex Calling supports multi-location deployments by allowing centralized management and consistent calling features across all locations.\",\n        \"answer\":\"Centralized management and consistent calling features support multi-location deployments in Webex Calling.\"\n    },\n    {\n        \"question\":\"What troubleshooting tools are available in Webex Calling?\",\n        \"context\":\"Webex Calling provides troubleshooting tools such as diagnostic reports, call logs, and real-time call quality monitoring.\",\n        \"answer\":\"Troubleshooting tools in Webex Calling include diagnostic reports, call logs, and real-time call quality monitoring.\"\n    },\n    {\n        \"question\":\"How does Webex Calling ensure voice quality?\",\n        \"context\":\"Webex Calling ensures voice quality through network optimization, advanced codecs, and quality of service (QoS) policies.\",\n        \"answer\":\"Voice quality in Webex Calling is ensured by network optimization, advanced codecs, and QoS policies.\"\n    },\n    {\n        \"question\":\"What integrations does Webex Calling support?\",\n        \"context\":\"Webex Calling supports integrations with CRM systems, collaboration tools, and contact center solutions.\",\n        \"answer\":\"Integrations with CRM systems, collaboration tools, and contact center solutions are supported by Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle call recording?\",\n        \"context\":\"Webex Calling includes call recording features for compliance, training, and quality assurance purposes.\",\n        \"answer\":\"Call recording in Webex Calling is available for compliance, training, and quality assurance.\"\n    },\n    {\n        \"question\":\"What role do data centers play in Webex Calling?\",\n        \"context\":\"Data centers in Webex Calling provide redundancy, high availability, and disaster recovery capabilities.\",\n        \"answer\":\"Data centers provide redundancy, high availability, and disaster recovery in Webex Calling.\"\n    },\n    {\n        \"question\":\"What are the benefits of Webex Calling for remote teams?\",\n        \"context\":\"Webex Calling offers remote teams enterprise-grade calling features, mobility, and integration with collaboration tools.\",\n        \"answer\":\"Enterprise-grade calling features, mobility, and collaboration tool integration benefit remote teams using Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle call forwarding?\",\n        \"context\":\"Webex Calling provides flexible call forwarding options, allowing users to redirect calls to other numbers or devices.\",\n        \"answer\":\"Flexible call forwarding options in Webex Calling allow users to redirect calls to other numbers or devices.\"\n    },\n    {\n        \"question\":\"What is Webex Calling?\",\n        \"context\":\"Webex Calling is a cloud-based phone system designed to provide enterprise-grade calling features.\",\n        \"answer\":\"Webex Calling is a cloud-based phone system offering enterprise-grade calling features.\"\n    },\n    {\n        \"question\":\"What types of phones are supported by Webex Calling?\",\n        \"context\":\"Webex Calling supports Cisco MPP Series IP Phones, Webex Devices, and a variety of third-party devices.\",\n        \"answer\":\"Webex Calling supports Cisco MPP Series IP Phones, Webex Devices, and various third-party devices.\"\n    },\n    {\n        \"question\":\"How does Webex Calling integrate with other Webex services?\",\n        \"context\":\"Webex Calling integrates seamlessly with Webex Meetings, Webex Teams, and Webex Contact Center.\",\n        \"answer\":\"Webex Calling integrates with Webex Meetings, Webex Teams, and Webex Contact Center.\"\n    },\n    {\n        \"question\":\"What are the deployment options for Webex Calling?\",\n        \"context\":\"Webex Calling can be deployed as a cloud-only solution or in a hybrid model with existing on-premises PBX systems.\",\n        \"answer\":\"Webex Calling offers cloud-only and hybrid deployment options.\"\n    },\n    {\n        \"question\":\"How is call quality maintained in Webex Calling?\",\n        \"context\":\"Call quality in Webex Calling is maintained through the use of advanced codecs, network optimization, and quality of service (QoS) policies.\",\n        \"answer\":\"Advanced codecs, network optimization, and QoS policies maintain call quality in Webex Calling.\"\n    },\n    {\n        \"question\":\"What is the purpose of the Webex Control Hub?\",\n        \"context\":\"The Webex Control Hub provides a centralized management interface for provisioning, configuring, and managing Webex Calling services.\",\n        \"answer\":\"The Webex Control Hub centralizes management for provisioning, configuring, and managing Webex Calling services.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support remote work?\",\n        \"context\":\"Webex Calling provides remote workers with enterprise-grade calling features and connectivity from any location with internet access.\",\n        \"answer\":\"Webex Calling supports remote work by offering enterprise-grade calling features and connectivity from any location with internet access.\"\n    },\n    {\n        \"question\":\"What security measures are implemented in Webex Calling?\",\n        \"context\":\"Webex Calling includes security measures such as encryption, secure voice, and compliance with industry standards.\",\n        \"answer\":\"Encryption, secure voice, and industry-standard compliance are key security measures in Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle emergency calls?\",\n        \"context\":\"Webex Calling compares the dial string with emergency numbers defined in the national numbering plan for the calling user.\",\n        \"answer\":\"Emergency calls in Webex Calling are handled by comparing the dial string with defined emergency numbers.\"\n    },\n    {\n        \"question\":\"What are the benefits of Webex Calling for enterprises?\",\n        \"context\":\"Webex Calling provides enterprises with benefits such as lower maintenance costs, scalability, remote work support, and integration with collaboration tools.\",\n        \"answer\":\"Lower maintenance costs, scalability, remote work support, and collaboration tool integration are benefits for enterprises using Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling manage call routing?\",\n        \"context\":\"Call routing in Webex Calling is managed through dial plans and route groups for efficient and flexible call management.\",\n        \"answer\":\"Dial plans and route groups manage call routing in Webex Calling.\"\n    },\n    {\n        \"question\":\"What customer support is available for Webex Calling?\",\n        \"context\":\"Cisco provides comprehensive customer support for Webex Calling, including technical assistance, training, and deployment resources.\",\n        \"answer\":\"Webex Calling customer support includes technical assistance, training, and deployment resources from Cisco.\"\n    },\n    {\n        \"question\":\"How does Webex Calling ensure high availability?\",\n        \"context\":\"High availability is ensured through geo-redundant data centers and a fully redundant global backbone network.\",\n        \"answer\":\"Geo-redundant data centers and a redundant global backbone network ensure high availability in Webex Calling.\"\n    },\n    {\n        \"question\":\"What are the international calling capabilities of Webex Calling?\",\n        \"context\":\"Webex Calling supports international calling through its global network of data centers, ensuring high-quality voice communication.\",\n        \"answer\":\"International calling is supported by Webex Calling's global data center network for high-quality voice communication.\"\n    },\n    {\n        \"question\":\"What is the role of SIP in Webex Calling?\",\n        \"context\":\"Session Initiation Protocol (SIP) is used for signaling and managing multimedia communication sessions in Webex Calling.\",\n        \"answer\":\"SIP manages signaling and multimedia communication sessions in Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle compliance with local regulations?\",\n        \"context\":\"Webex Calling supports compliance by routing calls through regional data centers and supporting lawful intercept.\",\n        \"answer\":\"Compliance with local regulations is ensured by routing calls through regional data centers and supporting lawful intercept.\"\n    },\n    {\n        \"question\":\"What integration options are available for Webex Calling?\",\n        \"context\":\"Webex Calling integrates seamlessly with Webex Meetings, Webex Teams, and third-party collaboration tools to enhance productivity.\",\n        \"answer\":\"Webex Calling integrates with Webex Meetings, Webex Teams, and third-party tools for enhanced productivity.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support contact centers?\",\n        \"context\":\"Webex Calling integrates with Webex Contact Center to provide advanced features such as call routing, IVR, and analytics.\",\n        \"answer\":\"Advanced contact center features like call routing, IVR, and analytics are provided through Webex Contact Center integration.\"\n    },\n    {\n        \"question\":\"What is the function of SRTP in Webex Calling?\",\n        \"context\":\"Secure Real-Time Transport Protocol (SRTP) is used to encrypt media streams, ensuring secure communication in Webex Calling.\",\n        \"answer\":\"SRTP encrypts media streams to ensure secure communication in Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle video calls?\",\n        \"context\":\"Webex Calling supports video calls between video-capable MPP phones, Webex Devices, and the Webex App.\",\n        \"answer\":\"Video calls are supported between video-capable MPP phones, Webex Devices, and the Webex App in Webex Calling.\"\n    },\n    {\n        \"question\":\"What are the benefits of Webex Calling for remote workers?\",\n        \"context\":\"Webex Calling provides remote workers with enterprise-grade calling features and the ability to stay connected from anywhere with an internet connection.\",\n        \"answer\":\"Webex Calling offers remote workers enterprise-grade calling features and connectivity from any location with internet access.\"\n    },\n    {\n        \"question\":\"What is the role of the Webex Control Hub in managing Webex Calling?\",\n        \"context\":\"The Webex Control Hub provides a centralized management interface for provisioning, configuring, and managing Webex Calling services.\",\n        \"answer\":\"The Webex Control Hub centralizes management for provisioning, configuring, and managing Webex Calling services.\"\n    },\n    {\n        \"question\":\"How does Webex Calling integrate with existing on-premises PBX systems?\",\n        \"context\":\"Webex Calling can integrate with existing on-premises PBX systems through Local Gateways, allowing for a hybrid deployment model.\",\n        \"answer\":\"Webex Calling integrates with on-premises PBX systems via Local Gateways for hybrid deployment.\"\n    },\n    {\n        \"question\":\"What is the significance of SRTP in Webex Calling?\",\n        \"context\":\"Secure Real-Time Transport Protocol (SRTP) is used in Webex Calling to encrypt media streams and ensure secure communication.\",\n        \"answer\":\"SRTP encrypts media streams in Webex Calling to ensure secure communication.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support compliance with local regulations?\",\n        \"context\":\"Webex Calling supports compliance with local regulations by routing calls through regional data centers and supporting lawful intercept.\",\n        \"answer\":\"Webex Calling complies with local regulations by using regional data centers and supporting lawful intercept.\"\n    },\n    {\n        \"question\":\"What features are available for call management in Webex Calling?\",\n        \"context\":\"Webex Calling provides features such as call forwarding, call transfer, call hold, and voicemail for efficient call management.\",\n        \"answer\":\"Webex Calling offers call forwarding, call transfer, call hold, and voicemail features.\"\n    },\n    {\n        \"question\":\"What options are available for integrating Webex Calling with other collaboration tools?\",\n        \"context\":\"Webex Calling integrates seamlessly with Webex Meetings, Webex Teams, and third-party collaboration tools to enhance productivity.\",\n        \"answer\":\"Webex Calling integrates with Webex Meetings, Webex Teams, and third-party tools for enhanced productivity.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle call routing?\",\n        \"context\":\"Call routing in Webex Calling is managed through dial plans and route groups, allowing for efficient and flexible call management.\",\n        \"answer\":\"Dial plans and route groups manage call routing in Webex Calling.\"\n    },\n    {\n        \"question\":\"What security features are built into Webex Calling?\",\n        \"context\":\"Webex Calling includes security features such as encryption, secure voice, and compliance with industry standards to protect communications.\",\n        \"answer\":\"Webex Calling features encryption, secure voice, and industry-standard compliance for communication security.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support mobile users?\",\n        \"context\":\"Webex Calling supports mobile users through the Webex App, allowing them to make and receive calls from their mobile devices.\",\n        \"answer\":\"The Webex App enables mobile users to make and receive calls on their devices with Webex Calling.\"\n    },\n    {\n        \"question\":\"How does Webex Calling integrate with Cisco devices?\",\n        \"context\":\"Webex Calling integrates with Cisco devices such as MPP phones and Webex Room devices for a unified communication experience.\",\n        \"answer\":\"Cisco MPP phones and Webex Room devices integrate with Webex Calling for unified communication.\"\n    },\n    {\n        \"question\":\"What are the deployment models available for Webex Calling?\",\n        \"context\":\"Webex Calling can be deployed as a cloud-only solution or in a hybrid model with existing on-premises PBX systems.\",\n        \"answer\":\"Webex Calling supports cloud-only and hybrid deployment models.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle international calling?\",\n        \"context\":\"Webex Calling supports international calling through its global network of data centers, ensuring high-quality voice communication.\",\n        \"answer\":\"International calling is supported by Webex Calling's global data center network for high-quality voice communication.\"\n    },\n    {\n        \"question\":\"What features does Webex Calling offer for contact centers?\",\n        \"context\":\"Webex Calling integrates with Webex Contact Center to provide advanced contact center features such as call routing, IVR, and analytics.\",\n        \"answer\":\"Advanced contact center features like call routing, IVR, and analytics are offered through Webex Contact Center integration.\"\n    },\n    {\n        \"question\":\"How does Webex Calling support scalability?\",\n        \"context\":\"Webex Calling is designed to scale with the needs of businesses, supporting small to large enterprises with its cloud-based architecture.\",\n        \"answer\":\"The cloud-based architecture of Webex Calling supports scalability for businesses of all sizes.\"\n    },\n    {\n        \"question\":\"What type of customer support is available for Webex Calling?\",\n        \"context\":\"Cisco provides comprehensive customer support for Webex Calling, including technical assistance, training, and resources for deployment.\",\n        \"answer\":\"Webex Calling customer support includes technical assistance, training, and deployment resources from Cisco.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle voice quality?\",\n        \"context\":\"Webex Calling ensures high voice quality through the use of advanced codecs, network optimization, and quality of service (QoS) policies.\",\n        \"answer\":\"High voice quality in Webex Calling is ensured by advanced codecs, network optimization, and QoS policies.\"\n    },\n    {\n        \"question\":\"What are the benefits of using Webex Calling over traditional PBX systems?\",\n        \"context\":\"Webex Calling offers benefits such as lower maintenance costs, scalability, remote work support, and integration with other collaboration tools.\",\n        \"answer\":\"Benefits of Webex Calling include lower maintenance costs, scalability, remote work support, and collaboration tool integration.\"\n    },\n    {\n        \"question\":\"What signaling and media protocols does Webex Calling use?\",\n        \"context\":\"Webex Calling uses SIP for signaling and SRTP for media. Dynamic NAT can be used for IP Phone and Local Gateway IP addresses.\",\n        \"answer\":\"Webex Calling uses SIP for signaling and SRTP for media.\"\n    },\n    {\n        \"question\":\"What is the role of the Webex Control Hub in Webex Calling?\",\n        \"context\":\"The Webex Control Hub, as part of the provisioning process of a trunk, provides connection parameters and digest credentials for SIP authentication.\",\n        \"answer\":\"The Webex Control Hub provides connection parameters and digest credentials for SIP authentication during Local Gateway registration.\"\n    },\n    {\n        \"question\":\"What group features does Webex Calling provide?\",\n        \"context\":\"In addition to enterprise-grade PBX features, Webex Calling also provides group features, including unlimited subscriptions of auto-attendants, hunt groups, and call queues.\",\n        \"answer\":\"Webex Calling provides group features like unlimited subscriptions of auto-attendants, hunt groups, and call queues.\"\n    },\n    {\n        \"question\":\"What are the regional platforms for Webex Calling?\",\n        \"context\":\"Webex Calling operates six regional platforms: US, Canada, UK, Europe, APJC Japan, and APJC Australia.\",\n        \"answer\":\"Webex Calling operates regional platforms in the US, Canada, UK, Europe, APJC Japan, and APJC Australia.\"\n    },\n    {\n        \"question\":\"What role do load balancers play in Webex Calling datacenters?\",\n        \"context\":\"Load balancers and other network functions are required to build a scalable, redundant datacenter architecture in each Webex Calling datacenter.\",\n        \"answer\":\"Load balancers are used to build a scalable, redundant datacenter architecture.\"\n    },\n    {\n        \"question\":\"What are the capabilities of the Webex App in Webex Calling?\",\n        \"context\":\"The Webex App supports commonly used mid-call features, rich presence with MPP and a single line for each user. The Webex App also allows control of the user\\u2019s Cisco MPP phone.\",\n        \"answer\":\"The Webex App supports mid-call features, rich presence, and control of the user's Cisco MPP phone.\"\n    },\n    {\n        \"question\":\"What is the role of the Webex Control Hub in Local Gateway registration?\",\n        \"context\":\"The Webex Control Hub, as part of the provisioning process of a trunk, provides connection parameters and digest credentials for SIP authentication.\",\n        \"answer\":\"The Webex Control Hub provides connection parameters and digest credentials for SIP authentication during Local Gateway registration.\"\n    },\n    {\n        \"question\":\"What deployment options are available for Webex Calling?\",\n        \"context\":\"Webex Calling is deployed as a cloud-only solution, or if you require a mixed network of both cloud and on-premises PBXs, it is deployed as part of a hybrid cloud.\",\n        \"answer\":\"Webex Calling can be deployed as a cloud-only solution or as part of a hybrid cloud.\"\n    },\n    {\n        \"question\":\"What are the data center locations for Webex Calling in the US?\",\n        \"context\":\"Webex Calling operates from redundant data centers in Dallas, Chicago, and New York within the US.\",\n        \"answer\":\"Webex Calling data centers in the US are located in Dallas, Chicago, and New York.\"\n    },\n    {\n        \"question\":\"What capabilities does the Webex App offer when integrated with Webex Calling?\",\n        \"context\":\"The Webex App offers messaging, screen sharing, audio and video conferencing, and integrated calling with mid-call features or control of a user\\u2019s desk phone.\",\n        \"answer\":\"The Webex App offers messaging, screen sharing, audio and video conferencing, and integrated calling with mid-call features or control of a user\\u2019s desk phone.\"\n    },\n    {\n        \"question\":\"What are the considerations for video calls in Webex Calling?\",\n        \"context\":\"Video calls are possible within a single Webex Calling org between video-capable devices or Webex App by dialing a work number or extension. PSTN only carries voice.\",\n        \"answer\":\"Video calls can be made within a single Webex Calling org between video-capable devices or Webex App, while PSTN only supports voice calls.\"\n    },\n    {\n        \"question\":\"What are the main functions hosted in each Webex Calling datacenter?\",\n        \"context\":\"Each Webex Calling datacenter hosts call routing functions, provides provisioning interface access, and hosts access and peering Session Border Controllers (SBCs).\",\n        \"answer\":\"Webex Calling datacenters host call routing functions, provide provisioning interface access, and host access and peering SBCs.\"\n    },\n    {\n        \"question\":\"How does Webex Calling ensure firewall traversal for calls?\",\n        \"context\":\"Phones and Local Gateways initiate a TLS connection to Webex Calling and are authenticated by Webex Calling, which then uses the same connection to send traffic back, providing firewall traversal.\",\n        \"answer\":\"Webex Calling ensures firewall traversal by using TLS connections initiated by phones and Local Gateways, and sending traffic back through the same connection.\"\n    },\n    {\n        \"question\":\"How are trunks used in Webex Calling?\",\n        \"context\":\"Trunks connect Webex Calling with Local Gateways or to Dedicated Instance, if included in the solution. Each trunk represents a connection to one Local Gateway instance configured on a CUBE or Cisco voice gateway.\",\n        \"answer\":\"Trunks connect Webex Calling with Local Gateways or Dedicated Instances.\"\n    },\n    {\n        \"question\":\"What is the Private Network Connect (PNC) solution?\",\n        \"context\":\"The Private Network Connect (PNC) solution allows Webex Calling customers to extend their private network to the cloud, ensuring high quality of service and low latency for voice calls.\",\n        \"answer\":\"The Private Network Connect (PNC) solution extends private networks to the cloud for high quality of service and low latency.\"\n    },\n    {\n        \"question\":\"What type of subscription is Webex Calling based on?\",\n        \"context\":\"Webex Calling is part of an integrated, intelligent, and modular team collaboration suite. Licensing is subscription-based and managed with the Cisco Collaboration Flex Plan.\",\n        \"answer\":\"Webex Calling uses a subscription-based licensing model managed with the Cisco Collaboration Flex Plan.\"\n    },\n    {\n        \"question\":\"Where are Webex Calling data centers located?\",\n        \"context\":\"Webex Calling is available globally and is delivered from redundant data centers in six regions: US, Canada, Europe, UK, Australia, and Japan.\",\n        \"answer\":\"Webex Calling data centers are located in the US, Canada, Europe, UK, Australia, and Japan.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle emergency calls?\",\n        \"context\":\"For calls originating from Webex Calling users, the dial string is first compared with the emergency numbers defined in the national numbering plan for the calling user.\",\n        \"answer\":\"Emergency calls are handled by comparing the dial string with emergency numbers defined in the national numbering plan.\"\n    },\n    {\n        \"question\":\"How are unknown numbers handled in Webex Calling?\",\n        \"context\":\"The routing behavior for unknown numbers is controlled by two settings: the enterprise-wide 'Unknown Number Handling' setting and the 'Calls to On-Premises Extension' setting at the location level.\",\n        \"answer\":\"Unknown numbers are handled based on the 'Unknown Number Handling' and 'Calls to On-Premises Extension' settings.\"\n    },\n    {\n        \"question\":\"What is the purpose of dial plans in Webex Calling?\",\n        \"context\":\"Dial plans add the ability to route calls to premises-based call control instances or between multiple premises-based call control instances based on matches against dial patterns within a dial plan.\",\n        \"answer\":\"Dial plans enable call routing to premises-based call control instances based on dial patterns.\"\n    },\n    {\n        \"question\":\"What are the benefits of using route groups in Webex Calling?\",\n        \"context\":\"Using route groups allows for redundancy and increased capacity. Multiple trunks can be grouped together in a route group to provide these benefits.\",\n        \"answer\":\"Route groups provide redundancy and increased capacity by grouping multiple trunks together.\"\n    },\n    {\n        \"question\":\"What happens if ICE negotiation fails in Webex Calling?\",\n        \"context\":\"If ICE negotiation fails, media is anchored on the Webex Calling Access SBC, causing media to flow from the originating phone via the customer\\u2019s Internet edge to the SBC and then back to the destination endpoint.\",\n        \"answer\":\"If ICE negotiation fails, media is anchored on the Webex Calling Access SBC, resulting in media flowing through the customer\\u2019s Internet edge to the SBC and back to the destination endpoint.\"\n    },\n    {\n        \"question\":\"What are route groups in Webex Calling?\",\n        \"context\":\"Route groups are used to group multiple trunks together to provide redundancy or increased capacity.\",\n        \"answer\":\"Route groups provide redundancy or increased capacity by grouping multiple trunks together.\"\n    },\n    {\n        \"question\":\"What is required for Webex Calling endpoints to connect to the datacenters?\",\n        \"context\":\"Webex Calling endpoints on the customer\\u2019s network use the public Internet as the access network to connect to the Webex Calling datacenters and establish over-the-top TLS connections.\",\n        \"answer\":\"Webex Calling endpoints use the public Internet to connect to datacenters and establish over-the-top TLS connections.\"\n    },\n    {\n        \"question\":\"What features does the Dedicated Instance option provide in Webex Calling?\",\n        \"context\":\"The Dedicated Instance option is an entitlement within Webex Calling that provides a Cisco Unified Communications Manager based stack of applications, in a private cloud, dedicated to a single customer.\",\n        \"answer\":\"The Dedicated Instance option provides a Cisco Unified Communications Manager based stack of applications in a private cloud dedicated to a single customer.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle PSTN access?\",\n        \"context\":\"Webex Calling can access the PSTN via Cisco Calling Plans, Cloud Connected PSTN, and Premises-based PSTN.\",\n        \"answer\":\"Webex Calling handles PSTN access through Cisco Calling Plans, Cloud Connected PSTN, and Premises-based PSTN.\"\n    },\n    {\n        \"question\":\"What are the benefits of the Webex Calling global backbone?\",\n        \"context\":\"The global backbone interconnects the datacenters with a multi-gigabit and fully redundant network, optimizing media round-trip times and ensuring high availability.\",\n        \"answer\":\"The global backbone optimizes media round-trip times and ensures high availability with a multi-gigabit, fully redundant network.\"\n    },\n    {\n        \"question\":\"What is the purpose of a Local Gateway in Webex Calling?\",\n        \"context\":\"A Local Gateway connects to the PSTN either directly by terminating a PSTN trunk or by connecting to an existing PSTN gateway via a SIP trunk. It also registers with Webex Calling and handles all calls between the PSTN and Webex Calling.\",\n        \"answer\":\"The Local Gateway connects to the PSTN and registers with Webex Calling to handle all calls between the PSTN and Webex Calling.\"\n    },\n    {\n        \"question\":\"What is the significance of media path optimization in Webex Calling?\",\n        \"context\":\"Media path optimization using ICE tries to establish a direct media path between the involved entities to reduce bandwidth usage and improve call quality.\",\n        \"answer\":\"Media path optimization establishes a direct media path between entities to reduce bandwidth usage and improve call quality.\"\n    },\n    {\n        \"question\":\"What is Webex Edge Connect?\",\n        \"context\":\"Webex Edge Connect is a solution that peers your Webex meetings and Webex Calling traffic with an Equinix Cloud Exchange (ECX) location. This peering improves user experience by providing guaranteed bandwidth and quality of service (QoS).\",\n        \"answer\":\"Webex Edge Connect peers Webex meetings and Webex Calling traffic with an Equinix Cloud Exchange (ECX) location to improve user experience with guaranteed bandwidth and QoS.\"\n    },\n    {\n        \"question\":\"What is the Webex Calling solution overview?\",\n        \"context\":\"Webex Calling is part of an integrated, intelligent, and modular team collaboration suite. It provides enterprise-grade PBX features, functionality, and performance previously only possible with an on-premises PBX network.\",\n        \"answer\":\"Webex Calling provides enterprise-grade PBX features, functionality, and performance.\"\n    },\n    {\n        \"question\":\"What connectivity options are available for Webex Calling?\",\n        \"context\":\"Customers and partners have access connectivity options beyond Over-the-top (OTT) Internet that can optimize the connection to Webex Calling and these include Webex Edge Connect or Private Network Connect.\",\n        \"answer\":\"Connectivity options for Webex Calling include Over-the-top (OTT) Internet, Webex Edge Connect, and Private Network Connect.\"\n    },\n    {\n        \"question\":\"What type of patterns can be included in a Webex Calling dial plan?\",\n        \"context\":\"Dial plans can include numeric patterns (E.164 numbers, enterprise numbers, extensions) and domain patterns for routing alphanumeric SIP URIs.\",\n        \"answer\":\"Dial plans can include numeric patterns and domain patterns for routing SIP URIs.\"\n    },\n    {\n        \"question\":\"What is the role of Local Gateways in Webex Calling?\",\n        \"context\":\"Local Gateways provide PSTN access for Webex Calling and can also connect Webex Calling to existing on-premises call control services.\",\n        \"answer\":\"Local Gateways provide PSTN access and connect Webex Calling to existing on-premises call control services.\"\n    },\n    {\n        \"question\":\"How does Webex Calling handle calls between different customers?\",\n        \"context\":\"Calls between two Webex Calling customers must be routed through the PSTN to meet legal requirements, such as lawful intercept.\",\n        \"answer\":\"Calls between different Webex Calling customers are routed through the PSTN.\"\n    },\n    {\n        \"question\":\"What types of phones are supported by Webex Calling?\",\n        \"context\":\"Webex Calling supports all models of Cisco Multiplatform Phones (MPP).\",\n        \"answer\":\"Webex Calling supports all models of Cisco Multiplatform Phones (MPP).\"\n    },\n    {\n        \"question\":\"What is Webex Edge Connect?\",\n        \"context\":\"Webex Edge Connect is a solution that peers your Webex meetings and Webex Calling traffic with an Equinix Cloud Exchange (ECX) location. This peering improves the calling and in-meeting user experience by providing guaranteed bandwidth and quality of service (QoS).\",\n        \"answer\":\"Webex Edge Connect peers Webex meetings and Webex Calling traffic with an Equinix Cloud Exchange location, improving user experience with guaranteed bandwidth and QoS.\"\n    },\n    {\n        \"question\":\"How can video calls be made in Webex Calling?\",\n        \"context\":\"Webex Calling supports video calls between video capable MPP phones, Webex Devices, and Webex App (desktop and mobile). Users can use speed dial with a SIP address to call into Webex meetings.\",\n        \"answer\":\"Video calls in Webex Calling can be made between video capable MPP phones, Webex Devices, and Webex App.\"\n    },\n    {\n        \"question\":\"What is the Dedicated Instance option in Webex Calling?\",\n        \"context\":\"The Dedicated Instance option is an entitlement within Webex Calling that provides a Cisco Unified Communications Manager based stack of applications, in a private cloud, dedicated to a single customer.\",\n        \"answer\":\"The Dedicated Instance option provides a Cisco Unified Communications Manager based stack of applications in a private cloud dedicated to a single customer.\"\n    },\n    {\n        \"question\":\"How many participants can Webex Meetings support when added to Webex Calling?\",\n        \"context\":\"Webex Meetings supports advanced meeting experiences including meeting room recording, meeting room locking, remote dial-in access over PSTN, and supporting up to 1000 meeting participants.\",\n        \"answer\":\"Webex Meetings can support up to 1000 meeting participants.\"\n    }\n]\n</code></pre> <p>Download example_llama3 file</p> <p>Save the file as example_llama3.json as we will be using it in the next step to push dataset on Hugging Face Hub</p> <p>To finalize, we again convert the above dataset (example_llama3.json) into Llama3 format. Lets look into those steps</p>"},{"location":"Task8b/#convert-dataset-into-llama3-format-and-upload-on-hugging-face","title":"Convert dataset into Llama3 format and upload on Hugging Face","text":"<ul> <li>Open Google Colab and create a new notebook. Click on \"File\" &gt; \"New notebook\" .Go to the \"Secrets\" section in the sidebar and ensure the Hugging Face toggle is enabled. Please refer to the following section to create Google Colab account.</li> </ul> <ul> <li>Make sure you are connected to a runtime. For this task, you can use the CPU as the runtime environment.</li> </ul> <ul> <li>Click on Folder and create a new folder called \"data\"</li> </ul> <ul> <li>Click on [...], select Upload</li> </ul> <ul> <li>Choose your example_llama3.json file and click Open</li> </ul> <p>Note\u00a0 Ensure that your files are saved elsewhere. This runtime's files will be deleted when its is terminated.</p> <p>Summary: So far, we have our raw dataset as example_llama3.json, enabled Hugging Face in our Colab notebook, and uploaded the data into our folder. we will be convertig the dataset (example_llama3.json) into Llama3 format and uploading on Hugging Face so it can be used for our fine tuning in the upcoming steps</p> <p> We will start by installing specific Python packages. </p> <pre><code>!pip install datasets huggingface_hub google-colab\n</code></pre> <p></p> <p>Note\u00a0 You don't need to install the packages if you are using the same notebook as in Task 8a when the datasets were created for Llama2.</p> <ul> <li> <p>The ! at the beginning is used in Jupyter notebooks or Google Colab to run shell commands. Using pip install we will install Python packages  </p> </li> <li> <p>datasets: This package is part of the Hugging Face ecosystem and provides tools for working with large datasets. It allows users to easily download, preprocess, and manage datasets, especially those used in machine learning and natural language processing (NLP).</p> </li> <li> <p>huggingface_hub: This package provides tools to interact with the Hugging Face Hub. </p> </li> <li> <p>google-colab: This package includes utilities specifically designed for Google Colab, a  Jupyter notebook environment that runs in the cloud.</p> </li> </ul> <p> Step 1: Import the required modules </p> <pre><code># Import required modules\nfrom datasets import Dataset\nfrom huggingface_hub import login\nimport os\nfrom google.colab import userdata\nimport json\nimport pandas as pd\n</code></pre> <ul> <li> <p>from datasets import Dataset: imports the Dataset class from the datasets library. The Dataset class is used to create and manipulate datasets. This library is part of the Hugging Face ecosystem and is especially useful for handling datasets for machine learning and NLP tasks.</p> </li> <li> <p>from huggingface_hub import login: This imports the login function from the huggingface_hub library. The login function is used to authenticate with the Hugging Face Hub, allowing the user to upload and manage models and datasets on the platform.</p> </li> <li> <p>import os: This imports the os module, which provides a way of using operating system-dependent functionality like reading or writing to the file system, environment variables, and more. </p> </li> <li> <p>from google.colab import userdata: imports the userdata module from the google.colab library. The google.colab library contains utilities specifically designed for use with Google Colab. </p> </li> <li> <p>import Json: will be used to Parsed JSON data</p> </li> <li> <p>import pandas as pd: used for data manipulation and analysis </p> </li> </ul> <p>Step 2:  Retrieve Hugging Face token from Colab secrets </p> <pre><code># Retrieve Hugging Face token from Colab secrets\nos.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n# Login to Hugging Face\nlogin(token=os.environ[\"HF_TOKEN\"])\n</code></pre> <p></p> <ul> <li> <p>This part of the code retrieves a previously stored Hugging Face token from Colab secrets. This token is essential for authenticating with the Hugging Face platform. Storing tokens in Colab secrets is a secure way to handle sensitive information without hardcoding it in your script.</p> </li> <li> <p>Login to Hugging Face: This line logs into Hugging Face using the retrieved token. Logging in allows our code to interact with the Hugging Face Hub, and allow us to upload datasets and models.</p> </li> </ul> <pre><code>!huggingface-cli whoami\n</code></pre> <p>Note: Confirm you are connected to your HuggingFace account </p> <p> Step 3: Standardizing and load data from example_llama3.json </p> <p><pre><code># Load JSON data from a file\nwith open('/content/data/example_llama3.json', 'r') as f:\n# with open('new_data_records.json', 'r') as f:\n    data = json.load(f)\n\n# Transform the data to match the desired format\ntransformed_data = []\nfor item in data:\n    transformed_data.append({\n        \"question\": item[\"question\"],\n        \"context\": item[\"context\"],\n        \"answer\": item[\"answer\"]\n    })\n</code></pre>  Note: How to get path for your file in GoogleColab </p> <ul> <li>Right click on your file (example_llama3.json) and select Copy Path</li> </ul> <p></p> <p> Step 3a: List and confirm data from  transformed_data. </p> <p><pre><code>print(transformed_data[0])\n</code></pre>  Output: </p> <p> Step 4: Saves the transformed data to a new JSON file, ensuring it is stored in a structured and readable format for future use.</p> <pre><code># Save the transformed data to a new JSON file\nwith open('/content/data/transformed_data.json', 'w') as f:\n    json.dump(transformed_data, f, indent=2)\n</code></pre> <p> Step 5: Converts the transformed JSON data into a pandas DataFrame and then into a Dataset object.  </p> <pre><code># Create a Dataset from the transformed data\ndf = pd.DataFrame(transformed_data)\ndataset = Dataset.from_pandas(df)\n</code></pre> <p> Step 6: Push our new Dataset to Hugging Face Hub so it can be processed and used for fine tuning </p> <p><pre><code># Push the dataset to Hugging Face Hub\ndataset.push_to_hub(\"WebexOne/llama3Data\")\n</code></pre> Complete Code - FOR REFERENCE ONLY</p> <pre><code>from datasets import Dataset\nfrom huggingface_hub import login\nimport os\nfrom google.colab import userdata\nimport json\nimport pandas as pd\n\n# Retrieve Hugging Face token from Colab secrets\nos.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n# Login to Hugging Face\nlogin(token=os.environ[\"HF_TOKEN\"])\n\n# Load JSON data from a file\nwith open('/content/data/example_llama3.json', 'r') as f:\n# with open('new_data_records.json', 'r') as f:\n    data = json.load(f)\n\n# Transform the data to match the desired format\ntransformed_data = []\nfor item in data:\n    transformed_data.append({\n        \"question\": item[\"question\"],\n        \"context\": item[\"context\"],\n        \"answer\": item[\"answer\"]\n    })\n# Save the transformed data to a new JSON file\nwith open('/content/data/transformed_data.json', 'w') as f:\n    json.dump(transformed_data, f, indent=2)\n\n# Create a Dataset from the transformed data\ndf = pd.DataFrame(transformed_data)\ndataset = Dataset.from_pandas(df)\n\n# Push the dataset to Hugging Face Hub\ndataset.push_to_hub(\"WebexOne/llama3Data\")\n</code></pre>"},{"location":"Task8b/#fine-tuning-llama3-model","title":"Fine-tuning Llama3 Model","text":"<p> NOTE: If you\u2019re serious about fine-tuning models, using a script instead of a notebook is recommended. You can easily rent GPUs on Lambda Labs, Runpod, Vast.ai e.t.c </p>"},{"location":"Task8b/#background-on-fine-tuning","title":"Background on Fine-Tuning","text":"<p>Meta has released a new series of large language models (LLMs) called Llama 3, a collection of pre-trained and instruction-tuned text-to-text models. </p> <p>Llama 3 is an auto-regressive language model that uses an optimized transformer architecture. Both pre-trained and instruction-tuned models come with 8B and 70B parameters with a context length of 8K tokens.</p> <p>As mentioned earlier Language models (LLMs) are pretrained on extensive text corpus. The 8B model has a knowledge cutoff of March 2023, while the 70B model has a cutoff of December 2023. The models use Grouped-Query Attention (GQA), which reduces memory bandwidth and improves efficiency.</p> <p>In this lab, we will FineTune Llama3-8b parameter model with our dataset that was created earlier.</p> <p>Note: As mentioned earlier, the choice of prompt template is crucial for fine-tuning. The following prompt template will be used to fine tune Llama3-8b</p> Sample Format - Dont Copy - reference ONLY<pre><code>&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt; You are a helpful AI assistant for  Collaboration&lt;|eot_id|&gt;\n\n                 &lt;|start_header_id|&gt;user&lt;|end_header_id|&gt; What can you help me with?&lt;|eot_id|&gt;\n\n                 &lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n</code></pre> <p>Note: For this tutorial, we will use a preformatted dataset (WebexOne/llama3Data) that was uploaded earlier on Hugging Face. We will apply Supervised Fine-Tuning (SFT) to a base model.</p>"},{"location":"Task8b/#guide-to-fine-tuning-llama-3","title":"Guide to Fine-Tuning Llama 3","text":"<p>In this section, we will learn about all the steps required to fine-tune the Llama 3 model with 8billion parameters on a T4 GPU with high RAM using Google Colab.</p> <p>The Colab T4 GPU has a limited 16 GB of VRAM. </p>"},{"location":"Task8b/#base-models-for-fine-tuning","title":"Base models for Fine Tuning","text":"<ul> <li>We have the option to fine-tune the Llama3 8b model (meta-llama/Meta-Llama-3-8B-Instruct), which can be found in the Hugging Face repository</li> </ul> <ul> <li>Since it is a gated repository, you'll need to provide the required information to access and use the model. Please scroll down, fill in the necessary details, and submit the form.</li> </ul> <ul> <li>Once submitted, you can check the status of your request by navigating to Settings and clicking on Gated Repositories.</li> </ul> <p> NOTE: It may take some time for the status to update from Pending to Accepted.</p> <ul> <li>Lets continue</li> </ul>"},{"location":"Task8b/#logging-into-google-collab","title":"Logging into Google Collab","text":"<ul> <li>You can either use the existing notebook from above and add a new code cell to start fine-tuning, or create a new Colab Notebook.</li> </ul> <ul> <li>Change Runtime Environment: Click the \u201cRuntime\u201d dropdown menu at the top of the Colab interface.</li> </ul> <ul> <li> <p>Select \u201cChange runtime type\u201d: This will open a dialog box where you can configure the runtime environment.</p> </li> <li> <p>Select Hardware Accelerator: From the \u201cHardware accelerator\u201d dropdown menu, choose &gt;&gt; T4 GPU and enable toggle for High RAM</p> </li> </ul> <p></p> <ul> <li>Save Settings: Click \u201cSave\u201d to apply the changes.</li> </ul> <p>Reminder: Whenever you want to copy the code in Google Colab and run it, be sure to click on + Code to add a new code cell.</p> <p></p> <p>Reminder: Click the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\" while the cell is selected.</p> <p></p>"},{"location":"Task8b/#set-up-envoirnment","title":"Set up Envoirnment","text":"<p>Step 1: Check the status of Nvidia chipset. OPTIONAL STEP </p> <pre><code>!nvidia-smi \n</code></pre> <p>Note: Remember to execute each cell individually </p> <p></p> <p>Note:  nvidia-smi stands for NVIDIA System Management Interface. It is a command-line utility that provides information about NVIDIA GPUs installed on the system. This tool is part of the NVIDIA GPU driver package. By using !nvidia-smi, you can quickly check the status and health of your NVIDIA GPUs from within a Jupyter Notebook, making it a useful tool for machine learning and data science workflows.</p> <p>Step 2: Install the required libraries. </p> <pre><code>!pip install transformers\n!pip install datasets\n!pip install accelerate\n!pip install bitsandbytes\n!pip install peft\n!pip install trl\n!pip install --upgrade jinja2\n!pip install tensorboard\n!pip install scikit-learn\n</code></pre> <p>Note: Remember to execute each cell individually </p> <p></p> <ul> <li> <p>datasets: accessing and using various datasets for NLP </p> </li> <li> <p>bitsandbytes: is a library for efficient model quantization </p> </li> <li> <p>transformers library by Hugging Face that provides pre-trained models and tools for natural language processing (NLP) tasks.</p> </li> <li> <p>trl:  Transformer Reinforcement Learning. It is a library for applying reinforcement learning techniques to transformer models. </p> </li> <li> <p>peft: package for fine tuning LLM's</p> </li> </ul> <p>Step 3: Load the necessary modules </p> <pre><code>from textwrap import dedent\nfrom typing import Dict, List\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom datasets import Dataset, load_dataset\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    TaskType,\n    get_peft_model,\n    prepare_model_for_kbit_training,\n)\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    pipeline,\n)\nfrom dotenv import load_dotenv\nimport os\n</code></pre> <p>Note: Remember to execute each cell individually </p> <ul> <li> <p>datasets:  library, is part of the Hugging Face ecosystem, that provides tools to load and process datasets.</p> </li> <li> <p>transformers: Hugging Face Transformers library, which provides tools for working with transformer-based models.</p> </li> <li> <p>AutoModelForCausalLM: automatically selects the appropriate model architecture for causal language modeling (e.g., Llama or GPT based models).</p> </li> <li> <p>AutoTokenizer: A class that automatically selects the appropriate tokenizer for a given model.</p> </li> <li> <p>BitsAndBytesConfig: Configuration class for model quantization</p> </li> <li> <p>pipeline: The pipelines are a great and easy way to use models for inference. More info</p> </li> <li> <p>peft: Stands for Parameter-Efficient Fine-Tuning (PEFT), which includes methods like LoRA (Low-Rank Adaptation) and Qlora</p> </li> <li> <p>trl: Stands for Transformer Reinforcement Learning, a library that includes tools for fine-tuning and training models</p> </li> </ul> <p>Step 4: Retrieve Hugging Face token and set as an environment variable. </p> <p><pre><code>from google.colab import userdata\nos.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n</code></pre> Note: Remember to execute each cell individually </p> <pre><code>!huggingface-cli whoami\n</code></pre> <p></p> <ul> <li>Verify to confirm that the Hugging Face CLI is correctly authenticated with your account.</li> </ul>"},{"location":"Task8b/#load-model","title":"Load model","text":"<p>Step 5: Before we start processing the data let's load our base model.  </p> <pre><code>PAD_TOKEN = \"&lt;|pad|&gt;\"\nMODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\nNEW_MODEL = \"WebexOne-lllama-3\"\n</code></pre> <ul> <li> <p>PAD_TOKEN: is set to help model not to repeat text.</p> </li> <li> <p>MODEL_NAME: specifies the name of a pre-trained model from Hugging Face that we will be using</p> </li> <li> <p>NEW_MODEL: gives a custom name for our fine-tuned version of the model.</p> </li> </ul>"},{"location":"Task8b/#load-quantization","title":"Load Quantization","text":"<p>Step 6: Loading a Quantized Language Model  </p> <pre><code>quantization_config = BitsAndBytesConfig(\n    load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\ntokenizer.add_special_tokens({\"pad_token\": PAD_TOKEN}) #help modles not to repeat text\ntokenizer.padding_side = \"right\"  #help modles not to repeat text\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    quantization_config=quantization_config,\n    device_map=\"auto\",\n)\nmodel.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8) #help models not to repeat text\n</code></pre> <ul> <li> <p>Creating a configuration for the model with 4-bit precision and bfloat16 compute type. Specified the quantization type as nf4</p> </li> <li> <p>Downloading the original tokenizer from the Meta repository and adding special tokens. Used the fast tokenizer implementation for faster processing</p> </li> <li> <p>Loading the quantized model and automatically mapping it to available devices.</p> </li> <li> <p>Resizing the model's token embeddings to match the tokenizer's vocabulary and setting the padding side to 'right' to prevent the model from generating text automatically.</p> </li> <li> <p>Adding a padding token to help prevent text repetition.</p> </li> </ul> <p></p> <p>Step 7: Retrieves the configuration associated with our loaded model - OPTIONAL STEP</p> <pre><code>model.config\n</code></pre> <p></p> <ul> <li>You will be able to see the config here for Quantization</li> </ul>"},{"location":"Task8b/#load-dataset","title":"Load Dataset","text":"<p>Step 7: Loading Dataset  </p> <pre><code>dataset = load_dataset(\"WebexOne/llama3Data\")\ndataset\n</code></pre> <p></p> <p>Step 8: Extracting and converting Dataset into a pandas DataFrame  </p> <pre><code>rows = []\nfor item in dataset[\"train\"]:\n    rows.append(\n        {\n            \"question\": item[\"question\"],\n            \"context\": item[\"context\"],\n            \"answer\": item[\"answer\"],\n        }\n    )\ndf = pd.DataFrame(rows)\n</code></pre> <ul> <li> <p>Initialize an empty list called rows.  Iterate over each item in the training split of the dataset and extracted the \"question\", \"context\", and \"answer\" fields from each item.</p> </li> <li> <p>Converted our list (rows) into a pandas DataFrame (df variable).</p> </li> </ul> <p><pre><code>df\n</code></pre> </p> <p>Step 9: Lets create a function which will format each row into a list of dictionaries (messages), followed by a conversation-like structure that is suitable for training Llama3. Each message includes a role (system, user, assistant) and corresponding content.  </p> <pre><code>def format_example(row: dict):\n    prompt = dedent(\n        f\"\"\"\n        {row[\"question\"]}\n\n        Information:\n        ```\n        {row[\"context\"]}\n        ```\n        \"\"\"\n    )\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"Use only the information to answer the question. If you dont know the answer just say it.\",\n        },\n        {\"role\": \"user\", \"content\": prompt},\n        {\"role\": \"assistant\", \"content\": row[\"answer\"]},\n    ]\n    print(messages)\n    return tokenizer.apply_chat_template(messages, tokenize=False)\n</code></pre> <p>Note: tokenizer.apply_chat_template(messages, tokenize=False): Applies the chat template to the messages list using the tokenizer. The tokenize=False argument indicates that the text should not be tokenized at this stage. This step prepares the text in a format that can be used by Llama3 for training and inference. </p> <p>Step 10: Apply the Function to our DataFrame </p> <pre><code>df[\"text\"] = df.apply(format_example, axis=1)\n</code></pre> <p>Note: axis = 1 , apply the function to each row </p> <p></p> <pre><code>df.text[0]\n</code></pre> OUTPUT - For Reference ONLY<pre><code>'&lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\\n\\nUse only the information to answer the question. If you dont know the answer just say it.&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWhat is the solution provided by Webex Calling?\\n\\nInformation:\\n```\\nWebex Calling is part of an integrated, intelligent, and modular team collaboration suite. It provides enterprise-grade PBX features, functionality, and performance previously only possible with an on-premises PBX network.\\n```&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\nWebex Calling provides enterprise-grade PBX features, functionality, and performance.&lt;|eot_id|&gt;'\n</code></pre> <p>Step 11: Counting Tokens for Each Text in a DataFrame </p> <ul> <li>Lets define a function to calculate the number of tokens in each  entry within our DataFrame. Note: Optional Step </li> </ul> <pre><code>def count_tokens(row: Dict) -&gt; int:\n    return len(\n        tokenizer(\n            row[\"text\"],\n            add_special_tokens=True,\n            return_attention_mask=False,\n        )[\"input_ids\"]\n    )\n</code></pre> <ul> <li>Lets convert text into tokens and then counts how many tokens each piece of text contains. The result is stored in a new column named token_count in the DataFrame, providing an easy reference for the length of each text in terms of tokens. </li> </ul> <pre><code>df[\"token_count\"] = df.apply(count_tokens, axis=1)\n</code></pre> <p></p>"},{"location":"Task8b/#splitting-a-dataset-into-training-validation-and-test-sets","title":"Splitting a Dataset into Training, Validation, and Test Sets","text":"<p>Step 12: We will split our dataset into three distinct subsets: a training set, a validation set, and a test set. This is a common practice in machine learning to ensure that the model is trained, validated, and tested on separate data, which helps to evaluate its performance more reliably.</p> <p>Note: For our fine-tuning, we will only use the training dataset. However, I'll demonstrate how to split and create separate datasets.</p> <pre><code>train, temp = train_test_split(df, test_size=0.2)\nval, test = train_test_split(temp, test_size=0.2)\n</code></pre> <ul> <li> <p>We performed a two-step data splitting process to divide a dataset into training, validation, and test :</p> <ul> <li> <p>First Split: The original dataset  is split into a training set (80%) and a temporary set (temp, 20%).</p> </li> <li> <p>Second Split: The temporary set is further split into a validation set (val, 16%) and a test set (test, 4%).</p> </li> </ul> </li> </ul> <p>The final result is:</p> <ul> <li>train: 80% of the data for training the model.</li> <li>val: 16% of the data for validating the model during training.</li> <li>test: 4% of the data for testing the model's performance.</li> </ul> <p>This method ensures that the model is trained, validated, and tested on different subsets of the data, which helps in preventing overfitting and provides a more accurate assessment of the model's generalization capability.</p> <p>Step 13: Calculating Dataset Proportions and Sizes </p> <p><pre><code>len(train) / len(df), len(val) / len(df), len(test) / len(df)\n\nlen(train), len(val), len(test)\n</code></pre>  Output </p> <p>(128, 26, 7)</p> <ul> <li>We calculate both the proportions and the absolute sizes of the training, validation, and test datasets relative to the original dataset   This helps in confirming that the dataset was split correctly and understanding how the data is distributed among the training, validation, and test sets.</li> </ul> <p>Step 14: Sampling and Exporting Subsets to JSON Files </p> <pre><code>train.sample(n=128).to_json(\"train.json\", orient=\"records\", lines=True)\nval.sample(n=26).to_json(\"val.json\", orient=\"records\", lines=True)\n</code></pre> <ul> <li> <p>Performs 2 functions:</p> <ul> <li>Random Sampling: It randomly selects 128 samples from the training dataset (train) (absoulte size calculated above) and 26 samples from the validation dataset (val).</li> <li>Export to JSON: The sampled data is then exported to JSON files (train.json and val.json) in a format where each row is a separate JSON object. orient=\"records\": allows the JSON output so that each object is written on a new line.</li> </ul> </li> <li> <p>This approach is very useful for creating smaller, representative datasets for testing or sharing, ensuring that the data remains in a structured and easily readable format.</p> </li> </ul> <p>Step 15: Loading a Dataset from JSON Files </p> <ul> <li>Load dataset from JSON files using the Hugging Face datasets library:</li> </ul> <pre><code>dataset = load_dataset(\n    \"json\",\n    data_files={\"train\": \"train.json\", \"validation\": \"val.json\"}\n)\n</code></pre> <p></p> <ul> <li>To view JSON data</li> </ul> <pre><code>dataset['train'][0][\"text\"]\n</code></pre> <p>Step 16: Testing Before Fine-Tuning our model</p> <ul> <li>Setting Up the Text Generation Pipeline</li> </ul> <pre><code>pipe = pipeline(\n    task=\"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=128,\n    return_full_text=False,\n)\n</code></pre> <ul> <li>We'll create a test prompt by removing the original answer from the prompt. By setting add_generation_prompt=True, the following be added at the end of prompt &lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;</li> </ul> <pre><code>def create_test_prompt(data_row):\n    prompt = dedent(\n        f\"\"\"\n        {data_row[\"question\"]}\n\n        Information:\n        ```\n        {data_row[\"context\"]}\n        ```\n        \"\"\"\n    )\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"Use only the information to answer the question. If you dont know the answer just say it.\",\n        },\n        {\"role\": \"user\", \"content\": prompt},\n    ]\n    return tokenizer.apply_chat_template(\n        messages, tokenize=False, add_generation_prompt=True\n    )\n</code></pre> <ul> <li>We will test the Model with a Sample Row from our training dataset  </li> </ul> <p><pre><code>row = dataset[\"train\"][0]\nprompt = create_test_prompt(row)\nprint(prompt)\n</code></pre> </p> <ul> <li>Generating and Comparing Output</li> </ul> <p><pre><code>%%time\noutputs = pipe(prompt)\nresponse = f\"\"\"\nanswer: {row[\"answer\"]}\nprediction: {outputs[0][\"generated_text\"]}\n\"\"\"\nprint(response)\n</code></pre> </p>"},{"location":"Task8b/#configuring-and-preparing-a-model-for-low-rank-adaptation-lora-with-quantization","title":"Configuring and Preparing a Model for Low-Rank Adaptation (LoRA) with Quantization","text":"<p>Step 17: Testing Before Fine-Tuning our model</p> <ul> <li> <p>K-bit quantization reduces the precision of the model's weights to k-bits (e.g., 4-bit or 8-bit)</p> </li> <li> <p>The LoRA configuration is applied to the model, adding low-rank matrices to the specified layers, enabling efficient fine-tuning with minimal additional parameters.</p> </li> <li> <p>We will target all the linear layers to train models like query, key , value pretty much every linear layer in the model mlp = multilayer preception.  Its like creating a small model on top of orignal model, we will only finetune teh weights of the small model.</p> </li> </ul> <pre><code>lora_config = LoraConfig(\n    r=32,\n    lora_alpha=16,\n    target_modules=[\n        \"self_attn.q_proj\",\n        \"self_attn.k_proj\",\n        \"self_attn.v_proj\",\n        \"self_attn.o_proj\",\n        \"mlp.gate_proj\",\n        \"mlp.up_proj\",\n        \"mlp.down_proj\",\n    ],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=TaskType.CAUSAL_LM,\n)\nmodel = prepare_model_for_kbit_training(model) #  as we using Kbit for quantization\nmodel = get_peft_model(model, lora_config)\nOUTPUT_DIR = \"./l3Webex1\"\n</code></pre> <ul> <li>To view total parameters of the model  <pre><code>model.print_trainable_parameters()\n</code></pre></li> </ul> <p>Step 18: Configuring and Initializing a Supervised Fine-Tuning (SFT)</p> <ul> <li>We will setup configuration for supervised fine-tuning (SFT) of a language model and then initializes a trainer to perform the fine-tuning process. As discussed, SFT is a method used to fine-tune pre-trained language models on specific datasets with labeled data, enabling the model to perform better on specific tasks.</li> </ul> <p><pre><code>sft_config = SFTConfig(\n    output_dir=OUTPUT_DIR,\n    dataset_text_field=\"text\",\n    max_seq_length=512,\n    num_train_epochs=1,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=4,\n    optim=\"paged_adamw_8bit\", #8 bit optimmizer\n    eval_strategy=\"steps\",\n    save_steps=0.2,\n    eval_steps=0.2,\n    logging_steps=10,\n    learning_rate=2e-4,\n    fp16=True,  # or bf16=True,\n    save_strategy=\"steps\",\n    warmup_ratio=0.1,\n    save_total_limit=2,\n    lr_scheduler_type=\"constant\",\n    report_to=\"tensorboard\",\n    save_safetensors=True,\n    dataset_kwargs={\n        \"add_special_tokens\": False,  # We template with special tokens\n        \"append_concat_token\": False,  # No need to add additional separator token\n    }\n)\n\ntrainer = SFTTrainer(\n    model=model,\n    args=sft_config,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"validation\"],\n    tokenizer=tokenizer,\n)\n</code></pre> </p> <p>Note: eval_dataset=dataset[\"validation\"]: The validation dataset is specified for info only As in the future this dataset can be used to evaluate the model's performance during training. </p> <p>Step 19: Executing the Training Process </p> <ul> <li>trainer.train() initiates the training process. This method triggers the training loop, where the model is fine-tuned on the training dataset (train_dataset) according to the configuration (sft_config) passed to the SFTTrainer in step18  </li> </ul> <pre><code>trainer.train()\n</code></pre> <p></p> <p>Step 20: Saving the Fine-Tuned Model </p> <pre><code>trainer.save_model(NEW_MODEL)\n</code></pre> <p>Step 21: Loading and Preparing a Fine-Tuned Model </p> <p> Note: This step may not work on Google Colab due to its resource limitations. It involves resizing token embeddings and merging a PEFT (Parameter-Efficient Fine-Tuning) model with the base model before pushing it to Hugging Face. If you're using your own servers (not Google Colab), feel free to proceed. Otherwise, this is for your information only, and you might encounter an error similar to the one shown below. </p> <p></p> <ul> <li> <p>We will merge PEFT model with the base model and unloads unnecessary components. </p> </li> <li> <p>Reloads and configures the tokenizer for consistent padding and token handling.</p> </li> </ul> <p><pre><code>import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import PeftModel\n\n# Function to clear GPU cache\ndef clear_gpu_cache():\n    torch.cuda.empty_cache()\n\n# Load model with low memory usage\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    device_map=\"cpu\",\n)\nclear_gpu_cache()\n\n# Resize token embeddings\nmodel.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)\nclear_gpu_cache()\n\n# Load PeftModel and merge\nmodel = PeftModel.from_pretrained(model, NEW_MODEL)\nmodel = model.merge_and_unload()\nclear_gpu_cache()\n\n# Reload tokenizer to save it\ntokenizer = AutoTokenizer.from_pretrained(NEW_MODEL, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"\n\n# Clear GPU cache one last time\nclear_gpu_cache()\n</code></pre> * Similar to the model, this command uploads the tokenizer to the same Hugging Face Hub repository that was defined at the begining of this section </p> <pre><code>model.push_to_hub(NEW_MODEL, use_temp_dir=False)\ntokenizer.push_to_hub(NEW_MODEL, use_temp_dir=False)\n</code></pre> <p></p>"},{"location":"Task8b/#use-the-uploaded-model-and-test-for-inferencing","title":"Use the uploaded model and test for inferencing","text":"<p> Note: Since we were unable to upload our fine-tuned model to the Hugging Face Hub, I have already trained and fine-tuned the model using the same datasets we discussed in the lab. You can download the model and use it for inference. </p> <ul> <li> <p>Log in to the Hugging Face Hub and navigate to your model's page (from above)</p> </li> <li> <p>Click on \"Use this model\" and then \"Transformers\".</p> </li> <li> <p>Copy the provided code snippet for using the model.</p> </li> </ul> <p>Step 22: Load model directly </p> <pre><code>from transformers import AutoTokenizer, AutoModelForCausalLM\ntokenizer = AutoTokenizer.from_pretrained(\"compile2011/WebexOne-lllama-3\")\nmodel = AutoModelForCausalLM.from_pretrained(\"compile2011/WebexOne-lllama-3\")\n</code></pre> <p></p> <pre><code>from transformers import pipeline\n\npipe = pipeline(\n    task=\"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=128,\n    return_full_text=False,\n)\n</code></pre> <pre><code>from textwrap import dedent\ndef create_test_prompt(question, context):\n    prompt = dedent(\n        f\"\"\"\n        {question}\n\n        Information:\n        ```\n        {context}\n        ```\n        \"\"\"\n    )\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": \"Use only the information to answer the question. If you dont know the answer just say it.\",\n        },\n        {\"role\": \"user\", \"content\": prompt},\n    ]\n    return tokenizer.apply_chat_template(\n        messages, tokenize=False, add_generation_prompt=True\n    )\n</code></pre> <pre><code>context = \"How does Webex Calling support call analytics?\"\nquestion = \"\"\nprompt = create_test_prompt(question,context)\nprint(prompt)\n</code></pre> <p></p> <p><pre><code>%%time\noutputs = pipe(prompt)\nresponse = f\"\"\"\nprediction: {outputs[0][\"generated_text\"]}\n\"\"\"\nprint(response)\n</code></pre> </p> <p>Note:You can compare the answers with those in the dataset file that was uploaded to Hugging Face.</p>"},{"location":"Task8b/#troubleshooting-best-practices","title":"Troubleshooting - Best Practices","text":"<ul> <li>Challenges are an inherent part of model training. Let's discuss some common issues and their resolutions.</li> </ul>"},{"location":"Task8b/#out-of-memory-oom-errors","title":"Out of Memory (OOM) Errors","text":"<ul> <li> <p>If you encounter an Out of Memory (OOM) error:</p> <ul> <li>Reduce Batch Size: Lowering the batch size can help fit the model into memory.</li> <li>Shorten Training Samples: Decrease the context length (e.g., max_length in tokenize()).</li> </ul> </li> </ul>"},{"location":"Task8b/#slow-training","title":"Slow Training","text":"<ul> <li> <p>If training seems sluggish:</p> <ul> <li> <p>Increase Batch Size: A larger batch size can speed up training.</p> </li> <li> <p>Use Multiple GPUs: Consider using multiple GPUs, either by purchasing or renting (e.g., on platforms like Runpod). The provided code is compatible with accelerate for multi-GPU settings. Simply launch it with  accelerate launch your_file.py  instead of  python your_file.py </p> </li> </ul> </li> </ul>"},{"location":"Task8b/#poor-model-quality","title":"Poor Model Quality","text":"<p>The quality of your model reflects the quality of your dataset. To improve model quality ensure your dataset is rich and relevant.</p>"},{"location":"Task8b/#conclusions","title":"Conclusions","text":"<p>So, we have explored the process of fine-tuning our model and performing inference with it. Now, let\u2019s say you have successfully trained or fine-tuned your model and are ready to deploy it for widespread use. However, you notice that the latency is too slow, and you want to speed up the model. There are four key methods you can employ to enhance your model's performance. While these steps are not covered in this lab, they serve as a good starting point for further investigation:</p> <ul> <li>Quantization</li> <li>Pruning</li> <li>Model or Knowledge Distillation</li> <li>Engineering Optimizations</li> </ul>"},{"location":"Task8c/","title":"Task 8c - Configuring and Fine Tuning - Using ChatGPT","text":""},{"location":"Task8c/#introduction","title":"Introduction","text":"<p>Just to summarise fine-tuning is the process of adjusting the parameters of a pre-trained large language model to a specific task or domain. Although pre-trained language models like GPT possess vast language knowledge, they lack specialization in specific areas e.g specific info about Webex. Fine-tuning addresses this limitation by allowing the model to learn from domain-specific data to make it more accurate and effective for targeted applications.</p> <p>Having already customized LLaMA 2 and LLaMA 3, let's now dive into fine-tuning another AI model GPT4. As we have seen, fine-tuning allows you to adapt a model for specific tasks, enhancing its accuracy and reliability. It can also make your prompts more efficient, saving both time and costs. </p> <p>In our demo, we\u2019re going to try something different: fine-tuning a language model using synthetic datasets created by a more advanced AI (GPT4).</p> <p>Note: it's important to note that fine-tuning this type of model involves some costs. More info for pricing available here</p>"},{"location":"Task8c/#pre-requisites","title":"Pre-requisites","text":"<ul> <li>Fine-tuning is currently available for the following models: </li> </ul> <p>Note: Fine-tuning for GPT-4 (gpt-4-0613 and gpt-4o-*) is in an experimental access program\u2014eligible users can request access in the fine-tuning UI when creating a new fine-tuning job.</p> <ul> <li> <p>While there is no strict minimum, the quality and quantity of the data greatly affect the fine-tuning process. To fine-tune a GPT model, you are requiorange to provide a dataset with atleast 10 examples </p> </li> <li> <p>Before you start a fine-tuning job, it's crucial to check your dataset's formatting. OpenAI has provided a simple Python script that helps you spot potential errors, review token counts, and estimate the cost of fine-tuning. You can find the code here.</p> </li> </ul>"},{"location":"Task8c/#datasets-creation","title":"Datasets Creation","text":"<p>As we will be using and fine tuning GPT4  model we need to convert datasets into a uniform format. More Info at</p>"},{"location":"Task8c/#example-format","title":"Example Format","text":"Sample Format - reference ONLY<pre><code>{\"messages\": [{\"role\": \"system\", \"content\": \"WebexOne is a chatbot that provides the most relevant and up-to-date information.\"}, \n{\"role\": \"user\", \"content\": \"What's the cloud calling solution provided by Cisco\"}, \n{\"role\": \"assistant\", \"content\": \"Webex Calling, as if everyone doesn't know that already.\"}]}\n</code></pre> <ul> <li>JSON setup with three different inputs <ul> <li>System Prompt</li> <li>User/Input Prompt</li> <li>Response from Model or Output Prompt</li> </ul> </li> </ul>"},{"location":"Task8c/#datasets-creation_1","title":"Datasets Creation","text":"<p>The next step is to prepare a dataset for fine-tuning. </p> <p>In my scenario, I was able to generate synthetic dataset from the Cisco IP DECT Phone 6800 Series Deployment Guide.</p>"},{"location":"Task8c/#sample-dataset","title":"Sample Dataset","text":"<ul> <li>Below is the sample Dataset we will train our model on:</li> </ul> <p>Note: My User_Prompt and Assistant_Prompt are defined below.</p> GPT.txt<pre><code>User_Prompt: What is the first step in the quick setup and installation process for the Cisco IP DECT 6800 Series? Assistant_Prompt: The first step is to review the entire document to ensure success before starting the deployment. This initial section provides a quick step-by-step guide, but the details and context are found in the remainder of the document.\nUser_Prompt: What should be consideorange when planning the location of base stations for the DECT system? Assistant_Prompt: When planning the location of base stations for the DECT system, consider that each base station covers 50 meters (164 feet) indoors. They should be installed within this range for good coverage. The location might be impacted by objects or barriers that create radio obstruction and interference. Using the handsets' free site survey tool can help identify these potential barriers.\nUser_Prompt: What equipment is requiorange for the DECT system installation? Assistant_Prompt: The equipment requiorange includes Cisco IP DECT DBS-110 Single-Cell Base Station, Cisco IP DECT DBS-210 Multi-Cell Base Station, and Cisco IP DECT RPT-110 Repeater. Additionally, handsets such as Cisco IP DECT Phone 6823, 6825, and 6825 Ruggedized Handset are needed.\nUser_Prompt: How do you upgrade the devices for the Cisco IP DECT 6800 Series? Assistant_Prompt: Unpack and register the base stations to the call system, upgrade them to the desiorange firmware version if necessary, and select and set the desiorange configuration parameters. Unpack the handsets, remove the battery's plastic shield, and charge the battery before using the handsets.\nUser_Prompt: What are the steps to install the base station? Assistant_Prompt: Place the base stations around the site in high locations without securing them, use the site survey tool on handsets to check the location for good coverage, make a few test calls from the handsets, and then mount the base stations with the included foot stands or wall/ceiling mount kits.\nUser_Prompt: What should be done if the Ethernet switch does not provide Power over Ethernet for the base stations? Assistant_Prompt: If the Ethernet switch does not provide Power over Ethernet, a power outlet is requiorange for each base station.\nUser_Prompt: What is the recommended firmware practice for the base stations and handsets? Assistant_Prompt: Cisco's best practice recommendation is to use the most recent firmware load available on Cisco.com. Each base station may take up to one hour to upgrade.\nUser_Prompt: What is the procedure for using the site survey tool on the handsets? Assistant_Prompt: Press Menu and *47*. The IP Search screen appears. Press the Select softkey when the MAC address of the base station appears. You can manually switch between base stations and repeaters during the site survey test.\nUser_Prompt: What precautions should be taken during the handset firmware upgrade? Assistant_Prompt: The handset must be placed on the cradle until the upgrade is completed. Don\u2019t remove the handset during the upgrade to avoid permanent damage.\nUser_Prompt: What are the available handsets for the Cisco IP DECT 6800 Series? Assistant_Prompt: The available handsets are Cisco IP DECT Phone 6823 Handset, Cisco IP DECT Phone 6825 Handset, and Cisco IP DECT Phone 6825 Ruggedized Handset.\nUser_Prompt: How should the handsets be prepaorange for registration and use? Assistant_Prompt: Unpack the handsets, remove the battery's plastic shield, reinstall the battery, and place the handsets on their cradle to charge fully before using. You can register each handset with the base station before charging and then upgrade the firmware while they charge on the cradle.\nUser_Prompt: What should be done if there is more than one base station to install? Assistant_Prompt: Run the site survey to check the coverage of each base station. Make a few test calls from the handsets and then mount the base stations accordingly.\nUser_Prompt: What is one advantage of Cisco\u2019s DECT solution over Wi-Fi? Assistant_Prompt: One advantage of Cisco\u2019s DECT solution over Wi-Fi is that the DECT solution components, such as the phones and base stations, have the same architecture and are designed to work exclusively with each other.\nUser_Prompt: Can third-party DECT base stations support Cisco handsets? Assistant_Prompt: No, third-party DECT base stations, repeaters, and handsets are not supported with the Cisco DECT Phone solution. The product design ensures that the DECT base station and the handset run on compatible frequencies.\nUser_Prompt: What frequency band does the Cisco IP DECT Phone 6800 Series use to avoid interference? Assistant_Prompt: The Cisco IP DECT Phone 6800 Series works close to the 1.9 GHz frequency band to avoid interference with Bluetooth, Wi-Fi, and microwave frequencies.\nUser_Prompt: What is the recommended synchronization method for dual cell and multicell deployments? Assistant_Prompt: For dual cell and multicell deployments, LAN synchronization is recommended.\nUser_Prompt: What is the coverage radius for the DBS-110, DBS-210 base stations, and RPT-110 repeater indoors? Assistant_Prompt: The coverage radius indoors is 20-50 meters (60-164 feet) depending on the nature and quantity of any radio signal impeding items or material in the installation site.\nUser_Prompt: What is the primary use case for a single cell DECT system? Assistant_Prompt: The single cell system is mostly used in small businesses and home offices. The DBS-110 is cost-effective for a single cell system not expected to grow, while the DBS-210 is ideal for future expansion.\nUser_Prompt: What are the key factors to consider in capacity planning for DECT systems? Assistant_Prompt: Key factors include the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\nUser_Prompt: What are the indoor and outdoor coverage radii for DECT base stations and repeaters? Assistant_Prompt: Indoors, the coverage radius is 20-50 meters (60-164 feet), and outdoors, it is 300 meters (984 feet).\nUser_Prompt: How does the signal area produced by a DECT base station behave? Assistant_Prompt: The signal area produced by the base station is omnidirectional and resembles a sphere. Mounting the base station very close to the ground or in a corner can orangeuce the optimal signal strength.\nUser_Prompt: What is the best practice for mounting base stations in a large hall? Assistant_Prompt: For a large hall, the base station should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\nUser_Prompt: What does the Cisco IP DECT 6800 Series include? Assistant_Prompt: The Cisco IP DECT 6800 Series includes the Cisco IP DECT Phone DBS-110 Single-Cell Base Station, Cisco IP DECT Phone DBS-210 Multi-Cell Base Station, Cisco IP DECT Phone RPT-110 Repeater, Cisco IP DECT Phone 6823 Handset, Cisco IP DECT Phone 6825 Handset, and Cisco IP DECT Phone 6825 Ruggedized Handset.\nUser_Prompt: What are the regulatory areas coveorange with Cisco DECT solutions? Assistant_Prompt: The regulatory areas coveorange are 1880-1900 MHz (Australia and New Zealand), 1880-1900 MHz (E.U. and APAC), and 1920-1930 MHz (U.S. and Canada).\nUser_Prompt: What technology is the Cisco IP DECT Phone 6800 Series built on? Assistant_Prompt: The Cisco IP DECT Phone 6800 Series is built on Digital Enhanced Cordless Telecommunications (DECT) technology.\nUser_Prompt: What protocol does the Cisco IP DECT Phone 6800 Series use for Voice over IP (VoIP)? Assistant_Prompt: The series uses the Session Initiation Protocol (SIP) to provide a Voice over IP (VoIP) solution over Ethernet.\nUser_Prompt: What is the frequency band used by DECT to avoid interference? Assistant_Prompt: DECT works close to the 1.9 GHz frequency band to avoid interference with Bluetooth, Wi-Fi, and microwave frequencies.\nUser_Prompt: What must be consideorange when deploying a DECT system in a service area with many rooms and obstacles? Assistant_Prompt: You may need a multicell deployment if the service area has many rooms and obstacles for good DECT signaling.\nUser_Prompt: What is the best mounting area for a base station to ensure optimal signal strength? Assistant_Prompt: The best mounting area is a location high up on the wall, on the wall, or ceiling away from any corners.\nUser_Prompt: What factors are typically included in network requirements for system planning? Assistant_Prompt: Factors include the area to be coveorange, the type or architecture of the building, the estimated traffic in each coverage area, signaling obstacles, and any new Ethernet cables or power outlets requiorange.\nUser_Prompt: What are the recommended conditions for base station density in high density areas with less interference? Assistant_Prompt: A Cisco IP DECT Base Station provides coverage of 20-50 meters (60\u2013164 feet) radius indoors, and 300 meters (984 feet) radius outdoors.\nUser_Prompt: What is the primary use of the DECT site survey tool? Assistant_Prompt: The DECT site survey tool is used to determine the best base station locations for maximum coverage.\nUser_Prompt: How many base stations and repeaters can a single cell DECT system support? Assistant_Prompt: A single cell DECT system with DBS-110 can support 6 repeaters, and with DBS-210, it can support 3 repeaters.\nUser_Prompt: What is the difference between the DBS-110 and DBS-210 base stations? Assistant_Prompt: The DBS-110 is cost-effective and ideal for single cell systems not expected to grow, while the DBS-210 is suitable for future expansion and can support more base stations.\nUser_Prompt: What is the maximum number of base stations in a multicell deployment? Assistant_Prompt: A multicell deployment can have 3 to 254 base stations.\nUser_Prompt: What synchronization method is recommended for multicell systems? Assistant_Prompt: LAN synchronization is recommended for multicell systems.\nUser_Prompt: What is the recommended distance between base stations to minimize interference in high density areas? Assistant_Prompt: Base stations should be installed at least 2 meters (6.5 feet) away from each other.\nUser_Prompt: How does the wideband codec affect channel capacity? Assistant_Prompt: The wideband codec occupies 2 channels, so if you expect more simultaneous calls, you may add more base stations to increase the channel capacity.\nUser_Prompt: What should be done if there are dead spots during the site survey? Assistant_Prompt: Move the base station towards the dead spot and repeat the site survey until you get the coverage you need, or add a second base station in multicell mode.\nUser_Prompt: What are the steps for installing the base station in a dual cell system? Assistant_Prompt: Ensure an overlap of at least 20% for seamless handover, place the base stations to maximize coverage, and consider RF attenuation in the deployment site.\nUser_Prompt: What are the key components to consider in deployment scenarios for capacity planning? Assistant_Prompt: Consider the intended number of handsets, traffic load, coverage area, and any potential interference or signal barriers.\nUser_Prompt: How can you optimize the location for installing a base station? Assistant_Prompt: Place the base station in the center with a line of sight to the coverage area, run the site survey tool, move around to locate dead spots, and adjust the base station as needed.\nUser_Prompt: What are the key elements described in the Cisco IP DECT 6800 Series Deployment Guide? Assistant_Prompt: The guide describes the elements in planning and designing a Cisco IP DECT 6800 Series Phone system, provides a simplified design procedure, and includes the network planning and deployment processes used in North America and Europe.\nUser_Prompt: What should be done if there is an interference with DECT signaling from wireless frequencies? Assistant_Prompt: DECT is resilient to interference from wireless frequencies commonly used for cell phones, Wi-Fi radios, and Bluetooth headsets. The DECT protocol adapts the channel to minimize the impact of interference.\nUser_Prompt: What are the recommended steps to optimize base station installation location? Assistant_Prompt: Place the base station in the center with a line of sight to the coverage area, run the site survey tool, move around the entire coverage area to locate any dead spots, and adjust the base station as needed.\nUser_Prompt: What is a key consideration when planning the DECT system for different regions? Assistant_Prompt: Consider the regulatory requirements for DECT frequencies in different regions. Cisco offers units set up correctly for each region, such as 1880-1900 MHz for Australia and New Zealand, 1880-1900 MHz for E.U. and APAC, and 1920-1930 MHz for U.S. and Canada.\nUser_Prompt: What are some of the radio considerations to take into account for DECT installations? Assistant_Prompt: Consider building penetration, interference sources, radio/cell range, and attenuation when planning DECT installations to ensure optimal signal strength and coverage.\nUser_Prompt: What is the importance of running the site survey tool during installation? Assistant_Prompt: Running the site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\nUser_Prompt: What are some best practices for DECT deployment? Assistant_Prompt: Best practices include planning the location of base stations to avoid signal blocking obstacles, using the site survey tool to check coverage, and ensuring that base stations are mounted in high locations with a clear line of sight.\nUser_Prompt: What are the primary steps in the upgrade process for DECT devices? Assistant_Prompt: Unpack and register the base stations to the call system, upgrade them to the desiorange firmware version if necessary, and select and set the desiorange configuration parameters.\nUser_Prompt: What factors should be consideorange when ordering equipment for DECT installation? Assistant_Prompt: Consider the number of base stations, repeaters, and handsets requiorange, as well as any additional mounting kits or power adapters needed for the installation site.\nUser_Prompt: What is the recommended approach for troubleshooting DECT installations? Assistant_Prompt: Rerun the site survey tool to identify any signal issues, check the placement of base stations, and ensure that all devices are upgraded to the latest firmware version.\nUser_Prompt: What should be done if there is a need to upgrade from old firmware? Assistant_Prompt: Follow the upgrade instructions provided in the Cisco IP DECT 6800 Series Administration Guide to ensure that all devices are running the latest firmware version supported by the call control system.\nUser_Prompt: What is the role of provisioning servers in DECT installations? Assistant_Prompt: Provisioning servers are used to configure and manage the DECT devices, ensuring that they are set up correctly and receive the necessary firmware updates and configuration parameters.\nUser_Prompt: What should be done if there are radio signal blockers between base stations in a multicell deployment? Assistant_Prompt: Ensure that there is a clear line of sight between the base stations or add additional base stations to work around the signal blockers.\nUser_Prompt: What are some network considerations for DECT deployment? Assistant_Prompt: Consider the network capacity, coverage requirements, and quality of service to ensure that the DECT system meets the needs of the users and provides reliable communication.\nUser_Prompt: What are the conditions for using default settings in DECT deployment scenarios? Assistant_Prompt: Default settings can be used when there is a single physical location with no overlapping base stations, or when multiple switches are used in single or multiple physical locations with no overlapping base stations.\nUser_Prompt: What should be done if the base stations do not overlap in a single physical location? Assistant_Prompt: Ensure that the base stations are properly synchronized and that there is adequate coverage in all areas where the handsets are used.\nUser_Prompt: What are the benefits of using LAN synchronization in DECT deployments? Assistant_Prompt: LAN synchronization ensures that the base stations are properly synchronized, providing seamless handover for handsets moving between base stations and orangeucing the risk of dropped calls.\nUser_Prompt: What are the recommended audio codecs for DECT systems? Assistant_Prompt: The recommended audio codecs are G722 for wideband and G726 for narrowband. The DECT protocol supports only two codecs, so choose one wideband and one narrowband codec.\nUser_Prompt: What is the importance of matching base stations to the density requirements? Assistant_Prompt: Matching base stations to the density requirements ensures that the DECT system can support the number of users and concurrent calls, providing reliable communication and avoiding capacity issues.\nUser_Prompt: What should be consideorange when planning the capacity for DECT installations? Assistant_Prompt: Consider the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\nUser_Prompt: What is one advantage of Cisco\u2019s DECT solution over Wi-Fi? Assistant_Prompt: One advantage of Cisco\u2019s DECT solution over Wi-Fi is that the DECT solution components, the phones and the base stations have the same architecture and are designed to work exclusively with each other.\nUser_Prompt: Can third-party DECT base stations support Cisco handsets? Assistant_Prompt: No, third-party DECT base stations, repeaters, and handsets are not supported with the Cisco DECT Phone solution. The product design ensures that the DECT base station and the handset run on compatible frequencies.\nUser_Prompt: What is the frequency band used by DECT to avoid interference? Assistant_Prompt: DECT works close to the 1.9 GHz frequency band to avoid interference with Bluetooth, Wi-Fi, and microwave frequencies.\nUser_Prompt: What is the recommended synchronization method for dual cell and multicell deployments? Assistant_Prompt: For dual cell and multicell deployments, LAN synchronization is recommended.\nUser_Prompt: What is the coverage radius for the DBS-110, DBS-210 base stations, and RPT-110 repeater indoors? Assistant_Prompt: The coverage radius indoors is 20-50 meters (60-164 feet) depending on the nature and quantity of any radio signal impeding items or material in the installation site.\nUser_Prompt: What is the primary use case for a single cell DECT system? Assistant_Prompt: The single cell system is mostly used in small businesses and home offices. The DBS-110 is cost-effective for a single cell system not expected to grow, while the DBS-210 is ideal for future expansion.\nUser_Prompt: What are the key factors to consider in capacity planning for DECT systems? Assistant_Prompt: Key factors include the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\nUser_Prompt: What are the indoor and outdoor coverage radii for DECT base stations and repeaters? Assistant_Prompt: Indoors, the coverage radius is 20-50 meters (60-164 feet), and outdoors, it is 300 meters (984 feet).\nUser_Prompt: How does the signal area produced by a DECT base station behave? Assistant_Prompt: The signal area produced by the base station is omnidirectional and resembles a sphere. Mounting the base station very close to the ground or in a corner can orangeuce the optimal signal strength.\nUser_Prompt: What is the best practice for mounting base stations in a large hall? Assistant_Prompt: For a large hall, the base station should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\nUser_Prompt: What is the purpose of using the site survey tool? Assistant_Prompt: The site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that might require additional coverage.\nUser_Prompt: What should be done if there are dead spots during the site survey? Assistant_Prompt: Move the base station towards the dead spot and repeat the site survey until you get the coverage you need, or add a second base station in multicell mode.\nUser_Prompt: What is the primary use of the DECT site survey tool? Assistant_Prompt: The DECT site survey tool is used to determine the best base station locations for maximum coverage.\nUser_Prompt: How many base stations and repeaters can a single cell DECT system support? Assistant_Prompt: A single cell DECT system with DBS-110 can support 6 repeaters, and with DBS-210, it can support 3 repeaters.\nUser_Prompt: What is the difference between the DBS-110 and DBS-210 base stations? Assistant_Prompt: The DBS-110 is cost-effective and ideal for single cell systems not expected to grow, while the DBS-210 is suitable for future expansion and can support more base stations.\nUser_Prompt: What is the maximum number of base stations in a multicell deployment? Assistant_Prompt: A multicell deployment can have 3 to 254 base stations.\nUser_Prompt: What synchronization method is recommended for multicell systems? Assistant_Prompt: LAN synchronization is recommended for multicell systems.\nUser_Prompt: What is the recommended distance between base stations to minimize interference in high density areas? Assistant_Prompt: Base stations should be installed at least 2 meters (6.5 feet) away from each other.\nUser_Prompt: How does the wideband codec affect channel capacity? Assistant_Prompt: The wideband codec occupies 2 channels, so if you expect more simultaneous calls, you may add more base stations to increase the channel capacity.\nUser_Prompt: What should be done if there are radio signal blockers between base stations in a multicell deployment? Assistant_Prompt: Ensure that there is a clear line of sight between the base stations or add additional base stations to work around the signal blockers.\nUser_Prompt: What is the recommended practice for base station density in high-density areas? Assistant_Prompt: In high-density areas, install base stations at least 2 meters (6.5 feet) away from each other. In the EU spectrum (20 MHz), the density should be 7 or fewer base stations in 100 square meters. In the Americas spectrum (10 MHz), the density should be 4 or fewer base stations in 100 square meters.\nUser_Prompt: What is the best practice for firmware upgrades for DECT devices? Assistant_Prompt: Cisco's best practice recommendation is to use the most recent firmware load available on Cisco.com. Each base station may take up to one hour to upgrade.\nUser_Prompt: What are the components of the Cisco IP DECT 6800 Series? Assistant_Prompt: The series includes the Cisco IP DECT Phone DBS-110 Single-Cell Base Station, Cisco IP DECT Phone DBS-210 Multi-Cell Base Station, Cisco IP DECT Phone RPT-110 Repeater, Cisco IP DECT Phone 6823 Handset, Cisco IP DECT Phone 6825 Handset, and Cisco IP DECT Phone 6825 Ruggedized Handset.\nUser_Prompt: What regulatory areas are coveorange with Cisco DECT solutions? Assistant_Prompt: The coveorange areas are 1880-1900 MHz (Australia and New Zealand), 1880-1900 MHz (E.U. and APAC), and 1920-1930 MHz (U.S. and Canada). For Mexico, Cisco offers the NA (North America) version with NOM compliance.\nUser_Prompt: What is the purpose of the DECT site survey tool? Assistant_Prompt: The site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\nUser_Prompt: How should base stations be mounted in a large hall? Assistant_Prompt: In a large hall, base stations should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\nUser_Prompt: What is the recommended method for synchronizing base stations in a multicell system? Assistant_Prompt: For a multicell system, LAN synchronization is recommended to ensure seamless handover for handsets moving between base stations.\nUser_Prompt: What are the audio codec considerations for DECT systems? Assistant_Prompt: The Cisco IP DECT 6823 and 6825 handsets support G722 for wideband and G726 for narrowband. The base stations support G.711 a-law &amp; \u00b5-law, G.722.2, G.726, and G.729a/ab. Choose one wideband and one narrowband codec, as the DECT protocol supports only two codecs.\nUser_Prompt: What is the coverage radius of the DBS-110 and DBS-210 base stations indoors? Assistant_Prompt: The coverage radius indoors is 20-50 meters (60-164 feet), depending on the nature and quantity of any radio signal impeding items or material in the installation site.\nUser_Prompt: How many repeaters can be connected to a single cell DECT system? Assistant_Prompt: A single cell DECT system with DBS-110 can support up to 6 repeaters, while DBS-210 can support up to 3 repeaters.\nUser_Prompt: What is the primary use case for a single cell DECT system? Assistant_Prompt: Single cell systems are mostly used in small businesses and home offices. The DBS-110 is cost-effective for systems not expected to grow, while the DBS-210 is suitable for future expansion.\nUser_Prompt: What should be consideorange when planning the capacity for DECT installations? Assistant_Prompt: Consider the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\nUser_Prompt: What is the importance of matching base stations to the density requirements? Assistant_Prompt: Matching base stations to the density requirements ensures that the DECT system can support the number of users and concurrent calls, providing reliable communication and avoiding capacity issues.\nUser_Prompt: What are the key elements described in the Cisco IP DECT 6800 Series Deployment Guide? Assistant_Prompt: The guide describes the elements in planning and designing a Cisco IP DECT 6800 Series Phone system, provides a simplified design procedure, and includes the network planning and deployment processes used in North America and Europe.\nUser_Prompt: What should be done if there is an interference with DECT signaling from wireless frequencies? Assistant_Prompt: DECT is resilient to interference from wireless frequencies commonly used for cell phones, Wi-Fi radios, and Bluetooth headsets. The DECT protocol adapts the channel to minimize the impact of interference.\nUser_Prompt: What are the recommended steps to optimize base station installation location? Assistant_Prompt: Place the base station in the center with a line of sight to the coverage area, run the site survey tool, move around the entire coverage area to locate any dead spots, and adjust the base station as needed.\nUser_Prompt: What is a key consideration when planning the DECT system for different regions? Assistant_Prompt: Consider the regulatory requirements for DECT frequencies in different regions. Cisco offers units set up correctly for each region, such as 1880-1900 MHz for Australia and New Zealand, 1880-1900 MHz for E.U. and APAC, and 1920-1930 MHz for U.S. and Canada.\nUser_Prompt: What are some of the radio considerations to take into account for DECT installations? Assistant_Prompt: Consider building penetration, interference sources, radio/cell range, and attenuation when planning DECT installations to ensure optimal signal strength and coverage.\nUser_Prompt: What is the importance of running the site survey tool during installation? Assistant_Prompt: Running the site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\nUser_Prompt: What is the recommended practice for base station density in high-density areas? Assistant_Prompt: In high-density areas, install base stations at least 2 meters (6.5 feet) away from each other. In the EU spectrum (20 MHz), the density should be 7 or fewer base stations in 100 square meters. In the Americas spectrum (10 MHz), the density should be 4 or fewer base stations in 100 square meters.\nUser_Prompt: What is the best practice for firmware upgrades for DECT devices? Assistant_Prompt: Cisco's best practice recommendation is to use the most recent firmware load available on Cisco.com. Each base station may take up to one hour to upgrade.\nUser_Prompt: What are the components of the Cisco IP DECT 6800 Series? Assistant_Prompt: The series includes the Cisco IP DECT Phone DBS-110 Single-Cell Base Station, Cisco IP DECT Phone DBS-210 Multi-Cell Base Station, Cisco IP DECT Phone RPT-110 Repeater, Cisco IP DECT Phone 6823 Handset, Cisco IP DECT Phone 6825 Handset, and Cisco IP DECT Phone 6825 Ruggedized Handset.\nUser_Prompt: What regulatory areas are coveorange with Cisco DECT solutions? Assistant_Prompt: The coveorange areas are 1880-1900 MHz (Australia and New Zealand), 1880-1900 MHz (E.U. and APAC), and 1920-1930 MHz (U.S. and Canada). For Mexico, Cisco offers the NA (North America) version with NOM compliance.\nUser_Prompt: What is the purpose of the DECT site survey tool? Assistant_Prompt: The site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\nUser_Prompt: How should base stations be mounted in a large hall? Assistant_Prompt: In a large hall, base stations should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\nUser_Prompt: What is the recommended method for synchronizing base stations in a multicell system? Assistant_Prompt: For a multicell system, LAN synchronization is recommended to ensure seamless handover for handsets moving between base stations.\nUser_Prompt: What are the audio codec considerations for DECT systems? Assistant_Prompt: The Cisco IP DECT 6823 and 6825 handsets support G722 for wideband and G726 for narrowband. The base stations support G.711 a-law &amp; \u00b5-law, G.722.2, G.726, and G.729a/ab. Choose one wideband and one narrowband codec, as the DECT protocol supports only two codecs.\nUser_Prompt: What is the coverage radius of the DBS-110 and DBS-210 base stations indoors? Assistant_Prompt: The coverage radius indoors is 20-50 meters (60-164 feet), depending on the nature and quantity of any radio signal impeding items or material in the installation site.\nUser_Prompt: How many repeaters can be connected to a single cell DECT system? Assistant_Prompt: A single cell DECT system with DBS-110 can support up to 6 repeaters, while DBS-210 can support up to 3 repeaters.\nUser_Prompt: What is the primary use case for a single cell DECT system? Assistant_Prompt: Single cell systems are mostly used in small businesses and home offices. The DBS-110 is cost-effective for systems not expected to grow, while the DBS-210 is suitable for future expansion.\nUser_Prompt: What should be consideorange when planning the capacity for DECT installations? Assistant_Prompt: Consider the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\nUser_Prompt: What is the importance of matching base stations to the density requirements? Assistant_Prompt: Matching base stations to the density requirements ensures that the DECT system can support the number of users and concurrent calls, providing reliable communication and avoiding capacity issues.\nUser_Prompt: What are the key elements described in the Cisco IP DECT 6800 Series Deployment Guide? Assistant_Prompt: The guide describes the elements in planning and designing a Cisco IP DECT 6800 Series Phone system, provides a simplified design procedure, and includes the network planning and deployment processes used in North America and Europe.\nUser_Prompt: What should be done if there is an interference with DECT signaling from wireless frequencies? Assistant_Prompt: DECT is resilient to interference from wireless frequencies commonly used for cell phones, Wi-Fi radios, and Bluetooth headsets. The DECT protocol adapts the channel to minimize the impact of interference.\nUser_Prompt: What are the recommended steps to optimize base station installation location? Assistant_Prompt: Place the base station in the center with a line of sight to the coverage area, run the site survey tool, move around the entire coverage area to locate any dead spots, and adjust the base station as needed.\nUser_Prompt: What is a key consideration when planning the DECT system for different regions? Assistant_Prompt: Consider the regulatory requirements for DECT frequencies in different regions. Cisco offers units set up correctly for each region, such as 1880-1900 MHz for Australia and New Zealand, 1880-1900 MHz for E.U. and APAC, and 1920-1930 MHz for U.S. and Canada.\nUser_Prompt: What are some of the radio considerations to take into account for DECT installations? Assistant_Prompt: Consider building penetration, interference sources, radio/cell range, and attenuation when planning DECT installations to ensure optimal signal strength and coverage.\nUser_Prompt: What is the importance of running the site survey tool during installation? Assistant_Prompt: Running the site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\nUser_Prompt: What is the purpose of using the DECT site survey tool? Assistant_Prompt: The DECT site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\nUser_Prompt: What is the recommended distance between base stations in high density areas to minimize interference? Assistant_Prompt: In high density areas, base stations should be installed at least 2 meters (6.5 feet) away from each other to minimize interference.\nUser_Prompt: What should be consideorange when planning the capacity for DECT installations? Assistant_Prompt: Consider the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\nUser_Prompt: What are the audio codec considerations for DECT systems? Assistant_Prompt: The Cisco IP DECT 6823 and 6825 handsets support G722 for wideband and G726 for narrowband. The base stations support G.711 a-law &amp; \u00b5-law, G.722.2, G.726, and G.729a/ab. Choose one wideband and one narrowband codec, as the DECT protocol supports only two codecs.\nUser_Prompt: How does the signal area produced by a DECT base station behave? Assistant_Prompt: The signal area produced by the base station is omnidirectional and resembles a sphere. Mounting the base station very close to the ground or in a corner can orangeuce the optimal signal strength.\nUser_Prompt: What should be done if there are dead spots during the site survey? Assistant_Prompt: Move the base station towards the dead spot and repeat the site survey until you get the coverage you need, or add a second base station in multicell mode.\nUser_Prompt: What is the coverage radius of the DBS-110 and DBS-210 base stations indoors? Assistant_Prompt: The coverage radius indoors is 20-50 meters (60-164 feet), depending on the nature and quantity of any radio signal impeding items or material in the installation site.\nUser_Prompt: How many repeaters can be connected to a single cell DECT system? Assistant_Prompt: A single cell DECT system with DBS-110 can support up to 6 repeaters, while DBS-210 can support up to 3 repeaters.\nUser_Prompt: What is the primary use case for a single cell DECT system? Assistant_Prompt: Single cell systems are mostly used in small businesses and home offices. The DBS-110 is cost-effective for systems not expected to grow, while the DBS-210 is suitable for future expansion.\nUser_Prompt: What are the recommended conditions for base station density in high density areas with less interference? Assistant_Prompt: A Cisco IP DECT Base Station provides coverage of 20-50 meters (60\u2013164 feet) radius indoors, and 300 meters (984 feet) radius outdoors.\nUser_Prompt: What is the recommended synchronization method for dual cell and multicell deployments? Assistant_Prompt: For dual cell and multicell deployments, LAN synchronization is recommended.\nUser_Prompt: What factors should be consideorange when ordering equipment for DECT installation? Assistant_Prompt: Consider the number of base stations, repeaters, and handsets requiorange, as well as any additional mounting kits or power adapters needed for the installation site.\nUser_Prompt: What should be done if the Ethernet switch does not provide Power over Ethernet for the base stations? Assistant_Prompt: If the Ethernet switch does not provide Power over Ethernet, a power outlet is requiorange for each base station.\nUser_Prompt: What is the best practice for mounting base stations in a large hall? Assistant_Prompt: For a large hall, the base station should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\nUser_Prompt: What should be done if there is an interference with DECT signaling from wireless frequencies? Assistant_Prompt: DECT is resilient to interference from wireless frequencies commonly used for cell phones, Wi-Fi radios, and Bluetooth headsets. The DECT protocol adapts the channel to minimize the impact of interference.\nUser_Prompt: What is the role of provisioning servers in DECT installations? Assistant_Prompt: Provisioning servers are used to configure and manage the DECT devices, ensuring that they are set up correctly and receive the necessary firmware updates and configuration parameters.\nUser_Prompt: What should be done if there are radio signal blockers between base stations in a multicell deployment? Assistant_Prompt: Ensure that there is a clear line of sight between the base stations or add additional base stations to work around the signal blockers.\nUser_Prompt: What is the importance of matching base stations to the density requirements? Assistant_Prompt: Matching base stations to the density requirements ensures that the DECT system can support the number of users and concurrent calls, providing reliable communication and avoiding capacity issues.\nUser_Prompt: What is the primary use of the DECT site survey tool? Assistant_Prompt: The DECT site survey tool is used to determine the best base station locations for maximum coverage.\nUser_Prompt: What should be consideorange when planning the DECT system for different regions? Assistant_Prompt: Consider the regulatory requirements for DECT frequencies in different regions. Cisco offers units set up correctly for each region, such as 1880-1900 MHz for Australia and New Zealand, 1880-1900 MHz for E.U. and APAC, and 1920-1930 MHz for U.S. and Canada.\nUser_Prompt: What should be consideorange when planning the capacity for DECT installations? Assistant_Prompt: Consider the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\nUser_Prompt: What are the audio codec considerations for DECT systems? Assistant_Prompt: The Cisco IP DECT 6823 and 6825 handsets support G722 for wideband and G726 for narrowband. The base stations support G.711 a-law &amp; \u00b5-law, G.722.2, G.726, and G.729a/ab. Choose one wideband and one narrowband codec, as the DECT protocol supports only two codecs.\nUser_Prompt: How does the signal area produced by a DECT base station behave? Assistant_Prompt: The signal area produced by the base station is omnidirectional and resembles a sphere. Mounting the base station very close to the ground or in a corner can orangeuce the optimal signal strength.\nUser_Prompt: What should be done if there are dead spots during the site survey? Assistant_Prompt: Move the base station towards the dead spot and repeat the site survey until you get the coverage you need, or add a second base station in multicell mode.\nUser_Prompt: What is the coverage radius of the DBS-110 and DBS-210 base stations indoors? Assistant_Prompt: The coverage radius indoors is 20-50 meters (60-164 feet), depending on the nature and quantity of any radio signal impeding items or material in the installation site.\nUser_Prompt: How many repeaters can be connected to a single cell DECT system? Assistant_Prompt: A single cell DECT system with DBS-110 can support up to 6 repeaters, while DBS-210 can support up to 3 repeaters.\nUser_Prompt: What is the primary use case for a single cell DECT system? Assistant_Prompt: Single cell systems are mostly used in small businesses and home offices. The DBS-110 is cost-effective for systems not expected to grow, while the DBS-210 is suitable for future expansion.\nUser_Prompt: What are the recommended conditions for base station density in high density areas with less interference? Assistant_Prompt: A Cisco IP DECT Base Station provides coverage of 20-50 meters (60\u2013164 feet) radius indoors, and 300 meters (984 feet) radius outdoors.\nUser_Prompt: What is the recommended synchronization method for dual cell and multicell deployments? Assistant_Prompt: For dual cell and multicell deployments, LAN synchronization is recommended.\nUser_Prompt: What factors should be consideorange when ordering equipment for DECT installation? Assistant_Prompt: Consider the number of base stations, repeaters, and handsets requiorange, as well as any additional mounting kits or power adapters needed for the installation site.\nUser_Prompt: What should be done if the Ethernet switch does not provide Power over Ethernet for the base stations? Assistant_Prompt: If the Ethernet switch does not provide Power over Ethernet, a power outlet is requiorange for each base station.\nUser_Prompt: What is the best practice for mounting base stations in a large hall? Assistant_Prompt: For a large hall, the base station should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\nUser_Prompt: What should be done if there is an interference with DECT signaling from wireless frequencies? Assistant_Prompt: DECT is resilient to interference from wireless frequencies commonly used for cell phones, Wi-Fi radios, and Bluetooth headsets. The DECT protocol adapts the channel to minimize the impact of interference.\nUser_Prompt: What is the role of provisioning servers in DECT installations? Assistant_Prompt: Provisioning servers are used to configure and manage the DECT devices, ensuring that they are set up correctly and receive the necessary firmware updates and configuration parameters.\n</code></pre> <p>Copy and Save the file as GPT.txt as we will be using it for fine-tuning</p> <p> Note: As previously discussed, we'll utilize GPT-4 to format our dataset and convert it into a JSONL file, preparing it for fine-tuning the GPT model. </p>"},{"location":"Task8c/#uset-gpt4-to-create-our-synthetic-data","title":"Uset GPT4 to create our synthetic data","text":"<ul> <li>Browse to GPT and copy the below txt </li> </ul> copy on GPT<pre><code>Here is my fine tuning example: System Role Prompt:\nYou are creative and exceptional Webex helper. You write information about Webex Dect Phones only from the info provided. If you dont know the info just mention that you have no idea. \nBe creative and write in a very conversational way that keeps the audience engaged.\n\nUser Prompt:\nHow should the handsets be prepaorange for registration and use? \n\nSystem Response:\n\nAnswer: Unpack the handsets, remove the battery's plastic shield, reinstall the battery, and place the handsets on their cradle to charge fully before using. You can register each handset with the base station before charging and then upgrade the firmware while they charge on the cradle.\n\nExample Format:\n\nin this example our goal is to create a fine tuning strategy that can answer questions about Dect Phone , Below are the three training examples (conversations) we could create for a dataset:\n\n{\n  \"messages\": [\n    { \"role\": \"system\", \"content\": \"You are an assistant that occasionally misspells words\" },\n    { \"role\": \"user\", \"content\": \"Tell me a story.\" },\n    { \"role\": \"assistant\", \"content\": \"One day a student went to schoool.\" }\n  ]\n}\n</code></pre> <ul> <li>In the above example  we used GPT4 to create a format that matches info(format) provided by OpenAI. Based on the above format we can create our dataset</li> </ul> <p>Attaching the below example for your easy reference </p> GPT.jsonl<pre><code>{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the first step in the quick setup and installation process for the Cisco IP DECT 6800 Series?\"}, {\"role\": \"assistant\", \"content\": \"The first step is to review the entire document to ensure success before starting the deployment. This initial section provides a quick step-by-step guide, but the details and context are found in the remainder of the document.\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be consideorange when planning the location of base stations for the DECT system?\"}, {\"role\": \"assistant\", \"content\": \"When planning the location of base stations for the DECT system, consider that each base station covers 50 meters (164 feet) indoors. They should be installed within this range for good coverage. The location might be impacted by objects or barriers that create radio obstruction and interference. Using the handsets' free site survey tool can help identify these potential barriers.\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What equipment is requiorange for the DECT system installation?\"}, {\"role\": \"assistant\", \"content\": \"The equipment requiorange includes Cisco IP DECT DBS-110 Single-Cell Base Station, Cisco IP DECT DBS-210 Multi-Cell Base Station, and Cisco IP DECT RPT-110 Repeater. Additionally, handsets such as Cisco IP DECT Phone 6823, 6825, and 6825 Ruggedized Handset are needed.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know he info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How do you upgrade the devices for the Cisco IP DECT 6800 Series?\"}, {\"role\": \"assistant\", \"content\": \"Unpack and register the base stations to the call system, upgrade them to the desiorange firmware version if necessary, and select and set the desiorange configuration parameters. Unpack the handsets, remove the battery's plastic shield, and charge the battery before using the handsets.\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the steps to install the base station?\"}, {\"role\": \"assistant\", \"content\": \"Place the base stations around the site in high locations without securing them, use the site survey tool on handsets to check the location for good coverage, make a few test calls from the handsets, and then mount the base stations with the included foot stands or wall/ceiling mount kits.\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if the Ethernet switch does not provide Power over Ethernet for the base stations?\"}, {\"role\": \"assistant\", \"content\": \"If the Ethernet switch does not provide Power over Ethernet, a power outlet is requiorange for each base station.\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended firmware practice for the base stations and handsets?\"}, {\"role\": \"assistant\", \"content\": \"Cisco's best practice recommendation is to use the most recent firmware load available on Cisco.com. Each base station may take up to one hour to upgrade.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the procedure for using the site survey tool on the handsets?\"}, {\"role\": \"assistant\", \"content\": \"Press Menu and *47*. The IP Search screen appears. Press the Select softkey when the MAC address of the base station appears. You can manually switch between base stations and repeaters during the site survey test.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What precautions should be taken during the handset firmware upgrade?\"}, {\"role\": \"assistant\", \"content\": \"The handset must be placed on the cradle until the upgrade is completed. Don\\u2019t remove the handset during the upgrade to avoid permanent damage.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the available handsets for the Cisco IP DECT 6800 Series?\"}, {\"role\": \"assistant\", \"content\": \"The available handsets are Cisco IP DECT Phone 6823 Handset, Cisco IP DECT Phone 6825 Handset, and Cisco IP DECT Phone 6825 Ruggedized Handset.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How should the handsets be prepaorange for registration and use?\"}, {\"role\": \"assistant\", \"content\": \"Alright, let's get those handsets ready to go! First things first\\u2014unpack each handset and find the plastic shield protecting the battery. You'll need to remove that, then pop the battery back in. Next up, place the handsets on their charging cradle to juice up. While they\\u2019re charging, you can go ahead and register each handset with the base station. And here\\u2019s a pro tip: consider updating the firmware during this time. It's a perfect multitask moment\\u2014charging and upgrading! Got any more questions or need further clarification?\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there is more than one base station to install?\"}, {\"role\": \"assistant\", \"content\": \"Run the site survey to check the coverage of each base station. Make a few test calls from the handsets and then mount the base stations accordingly.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is one advantage of Cisco\\u2019s DECT solution over Wi-Fi?\"}, {\"role\": \"assistant\", \"content\": \"One advantage of Cisco\\u2019s DECT solution over Wi-Fi is that the DECT solution components, such as the phones and base stations, have the same architecture and are designed to work exclusively with each other.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"Can third-party DECT base stations support Cisco handsets?\"}, {\"role\": \"assistant\", \"content\": \"No, third-party DECT base stations, repeaters, and handsets are not supported with the Cisco DECT Phone solution. The product design ensures that the DECT base station and the handset run on compatible frequencies.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What frequency band does the Cisco IP DECT Phone 6800 Series use to avoid interference?\"}, {\"role\": \"assistant\", \"content\": \"The Cisco IP DECT Phone 6800 Series works close to the 1.9 GHz frequency band to avoid interference with Bluetooth, Wi-Fi, and microwave frequencies.\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended synchronization method for dual cell and multicell deployments?\"}, {\"role\": \"assistant\", \"content\": \"For dual cell and multicell deployments, LAN synchronization is recommended.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the coverage radius for the DBS-110, DBS-210 base stations, and RPT-110 repeater indoors?\"}, {\"role\": \"assistant\", \"content\": \"The coverage radius indoors is 20-50 meters (60-164 feet) depending on the nature and quantity of any radio signal impeding items or material in the installation site.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the primary use case for a single cell DECT system?\"}, {\"role\": \"assistant\", \"content\": \"The single cell system is mostly used in small businesses and home offices. The DBS-110 is cost-effective for a single cell system not expected to grow, while the DBS-210 is ideal for future expansion.\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the key factors to consider in capacity planning for DECT systems?\"}, {\"role\": \"assistant\", \"content\": \"Key factors include the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the indoor and outdoor coverage radii for DECT base stations and repeaters?\"}, {\"role\": \"assistant\", \"content\": \"Indoors, the coverage radius is 20-50 meters (60-164 feet), and outdoors, it is 300 meters (984 feet).\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How does the signal area produced by a DECT base station behave?\"}, {\"role\": \"assistant\", \"content\": \"The signal area produced by the base station is omnidirectional and resembles a sphere. Mounting the base station very close to the ground or in a corner can orangeuce the optimal signal strength.\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the best practice for mounting base stations in a large hall?\"}, {\"role\": \"assistant\", \"content\": \"For a large hall, the base station should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What does the Cisco IP DECT 6800 Series include?\"}, {\"role\": \"assistant\", \"content\": \"The Cisco IP DECT 6800 Series includes the Cisco IP DECT Phone DBS-110 Single-Cell Base Station, Cisco IP DECT Phone DBS-210 Multi-Cell Base Station, Cisco IP DECT Phone RPT-110 Repeater, Cisco IP DECT Phone 6823 Handset, Cisco IP DECT Phone 6825 Handset, and Cisco IP DECT Phone 6825 Ruggedized Handset.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the regulatory areas coveorange with Cisco DECT solutions?\"}, {\"role\": \"assistant\", \"content\": \"The regulatory areas coveorange are 1880-1900 MHz (Australia and New Zealand), 1880-1900 MHz (E.U. and APAC), and 1920-1930 MHz (U.S. and Canada).\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What technology is the Cisco IP DECT Phone 6800 Series built on?\"}, {\"role\": \"assistant\", \"content\": \"The Cisco IP DECT Phone 6800 Series is built on Digital Enhanced Cordless Telecommunications (DECT) technology.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What protocol does the Cisco IP DECT Phone 6800 Series use for Voice over IP (VoIP)?\"}, {\"role\": \"assistant\", \"content\": \"The series uses the Session Initiation Protocol (SIP) to provide a Voice over IP (VoIP) solution over Ethernet.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the frequency band used by DECT to avoid interference?\"}, {\"role\": \"assistant\", \"content\": \"DECT works close to the 1.9 GHz frequency band to avoid interference with Bluetooth, Wi-Fi, and microwave frequencies.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What must be consideorange when deploying a DECT system in a service area with many rooms and obstacles?\"}, {\"role\": \"assistant\", \"content\": \"You may need a multicell deployment if the service area has many rooms and obstacles for good DECT signaling.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the best mounting area for a base station to ensure optimal signal strength?\"}, {\"role\": \"assistant\", \"content\": \"The best mounting area is a location high up on the wall, on the wall, or ceiling away from any corners.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What factors are typically included in network requirements for system planning?\"}, {\"role\": \"assistant\", \"content\": \"Factors include the area to be coveorange, the type or architecture of the building, the estimated traffic in each coverage area, signaling obstacles, and any new Ethernet cables or power outlets requiorange.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the recommended conditions for base station density in high density areas with less interference?\"}, {\"role\": \"assistant\", \"content\": \"A Cisco IP DECT Base Station provides coverage of 20-50 meters (60\\u2013164 feet) radius indoors, and 300 meters (984 feet) radius outdoors.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the primary use of the DECT site survey tool?\"}, {\"role\": \"assistant\", \"content\": \"The DECT site survey tool is used to determine the best base station locations for maximum coverage.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How many base stations and repeaters can a single cell DECT system support?\"}, {\"role\": \"assistant\", \"content\": \"A single cell DECT system with DBS-110 can support 6 repeaters, and with DBS-210, it can support 3 repeaters.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the difference between the DBS-110 and DBS-210 base stations?\"}, {\"role\": \"assistant\", \"content\": \"The DBS-110 is cost-effective and ideal for single cell systems not expected to grow, while the DBS-210 is suitable for future expansion and can support more base stations.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the maximum number of base stations in a multicell deployment?\"}, {\"role\": \"assistant\", \"content\": \"A multicell deployment can have 3 to 254 base stations.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What synchronization method is recommended for multicell systems?\"}, {\"role\": \"assistant\", \"content\": \"LAN synchronization is recommended for multicell systems.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended distance between base stations to minimize interference in high density areas?\"}, {\"role\": \"assistant\", \"content\": \"Base stations should be installed at least 2 meters (6.5 feet) away from each other.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How does the wideband codec affect channel capacity?\"}, {\"role\": \"assistant\", \"content\": \"The wideband codec occupies 2 channels, so if you expect more simultaneous calls, you may add more base stations to increase the channel capacity.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there are dead spots during the site survey?\"}, {\"role\": \"assistant\", \"content\": \"Move the base station towards the dead spot and repeat the site survey until you get the coverage you need, or add a second base station in multicell mode.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the steps for installing the base station in a dual cell system?\"}, {\"role\": \"assistant\", \"content\": \"Ensure an overlap of at least 20% for seamless handover, place the base stations to maximize coverage, and consider RF attenuation in the deployment site.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the key components to consider in deployment scenarios for capacity planning?\"}, {\"role\": \"assistant\", \"content\": \"Consider the intended number of handsets, traffic load, coverage area, and any potential interference or signal barriers.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How can you optimize the location for installing a base station?\"}, {\"role\": \"assistant\", \"content\": \"Place the base station in the center with a line of sight to the coverage area, run the site survey tool, move around to locate dead spots, and adjust the base station as needed.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the key elements described in the Cisco IP DECT 6800 Series Deployment Guide?\"}, {\"role\": \"assistant\", \"content\": \"The guide describes the elements in planning and designing a Cisco IP DECT 6800 Series Phone system, provides a simplified design procedure, and includes the network planning and deployment processes used in North America and Europe.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there is an interference with DECT signaling from wireless frequencies?\"}, {\"role\": \"assistant\", \"content\": \"DECT is resilient to interference from wireless frequencies commonly used for cell phones, Wi-Fi radios, and Bluetooth headsets. The DECT protocol adapts the channel to minimize the impact of interference.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the recommended steps to optimize base station installation location?\"}, {\"role\": \"assistant\", \"content\": \"Place the base station in the center with a line of sight to the coverage area, run the site survey tool, move around the entire coverage area to locate any dead spots, and adjust the base station as needed.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is a key consideration when planning the DECT system for different regions?\"}, {\"role\": \"assistant\", \"content\": \"Consider the regulatory requirements for DECT frequencies in different regions. Cisco offers units set up correctly for each region, such as 1880-1900 MHz for Australia and New Zealand, 1880-1900 MHz for E.U. and APAC, and 1920-1930 MHz for U.S. and Canada.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are some of the radio considerations to take into account for DECT installations?\"}, {\"role\": \"assistant\", \"content\": \"Consider building penetration, interference sources, radio/cell range, and attenuation when planning DECT installations to ensure optimal signal strength and coverage.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the importance of running the site survey tool during installation?\"}, {\"role\": \"assistant\", \"content\": \"Running the site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are some best practices for DECT deployment?\"}, {\"role\": \"assistant\", \"content\": \"Best practices include planning the location of base stations to avoid signal blocking obstacles, using the site survey tool to check coverage, and ensuring that base stations are mounted in high locations with a clear line of sight.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the primary steps in the upgrade process for DECT devices?\"}, {\"role\": \"assistant\", \"content\": \"Unpack and register the base stations to the call system, upgrade them to the desiorange firmware version if necessary, and select and set the desiorange configuration parameters.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What factors should be consideorange when ordering equipment for DECT installation?\"}, {\"role\": \"assistant\", \"content\": \"Consider the number of base stations, repeaters, and handsets requiorange, as well as any additional mounting kits or power adapters needed for the installation site.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended approach for troubleshooting DECT installations?\"}, {\"role\": \"assistant\", \"content\": \"Rerun the site survey tool to identify any signal issues, check the placement of base stations, and ensure that all devices are upgraded to the latest firmware version.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there is a need to upgrade from old firmware?\"}, {\"role\": \"assistant\", \"content\": \"Follow the upgrade instructions provided in the Cisco IP DECT 6800 Series Administration Guide to ensure that all devices are running the latest firmware version supported by the call control system.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the role of provisioning servers in DECT installations?\"}, {\"role\": \"assistant\", \"content\": \"Provisioning servers are used to configure and manage the DECT devices, ensuring that they are set up correctly and receive the necessary firmware updates and configuration parameters.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there are radio signal blockers between base stations in a multicell deployment?\"}, {\"role\": \"assistant\", \"content\": \"Ensure that there is a clear line of sight between the base stations or add additional base stations to work around the signal blockers.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are some network considerations for DECT deployment?\"}, {\"role\": \"assistant\", \"content\": \"Consider the network capacity, coverage requirements, and quality of service to ensure that the DECT system meets the needs of the users and provides reliable communication.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the conditions for using default settings in DECT deployment scenarios?\"}, {\"role\": \"assistant\", \"content\": \"Default settings can be used when there is a single physical location with no overlapping base stations, or when multiple switches are used in single or multiple physical locations with no overlapping base stations.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if the base stations do not overlap in a single physical location?\"}, {\"role\": \"assistant\", \"content\": \"Ensure that the base stations are properly synchronized and that there is adequate coverage in all areas where the handsets are used.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the benefits of using LAN synchronization in DECT deployments?\"}, {\"role\": \"assistant\", \"content\": \"LAN synchronization ensures that the base stations are properly synchronized, providing seamless handover for handsets moving between base stations and orangeucing the risk of dropped calls.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the recommended audio codecs for DECT systems?\"}, {\"role\": \"assistant\", \"content\": \"The recommended audio codecs are G722 for wideband and G726 for narrowband. The DECT protocol supports only two codecs, so choose one wideband and one narrowband codec.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the importance of matching base stations to the density requirements?\"}, {\"role\": \"assistant\", \"content\": \"Matching base stations to the density requirements ensures that the DECT system can support the number of users and concurrent calls, providing reliable communication and avoiding capacity issues.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be consideorange when planning the capacity for DECT installations?\"}, {\"role\": \"assistant\", \"content\": \"Consider the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is one advantage of Cisco\\u2019s DECT solution over Wi-Fi?\"}, {\"role\": \"assistant\", \"content\": \"One advantage of Cisco\\u2019s DECT solution over Wi-Fi is that the DECT solution components, the phones and the base stations have the same architecture and are designed to work exclusively with each other.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"Can third-party DECT base stations support Cisco handsets?\"}, {\"role\": \"assistant\", \"content\": \"No, third-party DECT base stations, repeaters, and handsets are not supported with the Cisco DECT Phone solution. The product design ensures that the DECT base station and the handset run on compatible frequencies.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the frequency band used by DECT to avoid interference?\"}, {\"role\": \"assistant\", \"content\": \"DECT works close to the 1.9 GHz frequency band to avoid interference with Bluetooth, Wi-Fi, and microwave frequencies.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended synchronization method for dual cell and multicell deployments?\"}, {\"role\": \"assistant\", \"content\": \"For dual cell and multicell deployments, LAN synchronization is recommended.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the coverage radius for the DBS-110, DBS-210 base stations, and RPT-110 repeater indoors?\"}, {\"role\": \"assistant\", \"content\": \"The coverage radius indoors is 20-50 meters (60-164 feet) depending on the nature and quantity of any radio signal impeding items or material in the installation site.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the primary use case for a single cell DECT system?\"}, {\"role\": \"assistant\", \"content\": \"The single cell system is mostly used in small businesses and home offices. The DBS-110 is cost-effective for a single cell system not expected to grow, while the DBS-210 is ideal for future expansion.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the key factors to consider in capacity planning for DECT systems?\"}, {\"role\": \"assistant\", \"content\": \"Key factors include the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the indoor and outdoor coverage radii for DECT base stations and repeaters?\"}, {\"role\": \"assistant\", \"content\": \"Indoors, the coverage radius is 20-50 meters (60-164 feet), and outdoors, it is 300 meters (984 feet).\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How does the signal area produced by a DECT base station behave?\"}, {\"role\": \"assistant\", \"content\": \"The signal area produced by the base station is omnidirectional and resembles a sphere. Mounting the base station very close to the ground or in a corner can orangeuce the optimal signal strength.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the best practice for mounting base stations in a large hall?\"}, {\"role\": \"assistant\", \"content\": \"For a large hall, the base station should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the purpose of using the site survey tool?\"}, {\"role\": \"assistant\", \"content\": \"The site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that might require additional coverage.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there are dead spots during the site survey?\"}, {\"role\": \"assistant\", \"content\": \"Move the base station towards the dead spot and repeat the site survey until you get the coverage you need, or add a second base station in multicell mode.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the primary use of the DECT site survey tool?\"}, {\"role\": \"assistant\", \"content\": \"The DECT site survey tool is used to determine the best base station locations for maximum coverage.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How many base stations and repeaters can a single cell DECT system support?\"}, {\"role\": \"assistant\", \"content\": \"A single cell DECT system with DBS-110 can support 6 repeaters, and with DBS-210, it can support 3 repeaters.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the difference between the DBS-110 and DBS-210 base stations?\"}, {\"role\": \"assistant\", \"content\": \"The DBS-110 is cost-effective and ideal for single cell systems not expected to grow, while the DBS-210 is suitable for future expansion and can support more base stations.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the maximum number of base stations in a multicell deployment?\"}, {\"role\": \"assistant\", \"content\": \"A multicell deployment can have 3 to 254 base stations.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What synchronization method is recommended for multicell systems?\"}, {\"role\": \"assistant\", \"content\": \"LAN synchronization is recommended for multicell systems.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended distance between base stations to minimize interference in high density areas?\"}, {\"role\": \"assistant\", \"content\": \"Base stations should be installed at least 2 meters (6.5 feet) away from each other.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How does the wideband codec affect channel capacity?\"}, {\"role\": \"assistant\", \"content\": \"The wideband codec occupies 2 channels, so if you expect more simultaneous calls, you may add more base stations to increase the channel capacity.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there are radio signal blockers between base stations in a multicell deployment?\"}, {\"role\": \"assistant\", \"content\": \"Ensure that there is a clear line of sight between the base stations or add additional base stations to work around the signal blockers.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended practice for base station density in high-density areas?\"}, {\"role\": \"assistant\", \"content\": \"In high-density areas, install base stations at least 2 meters (6.5 feet) away from each other. In the EU spectrum (20 MHz), the density should be 7 or fewer base stations in 100 square meters. In the Americas spectrum (10 MHz), the density should be 4 or fewer base stations in 100 square meters.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the best practice for firmware upgrades for DECT devices?\"}, {\"role\": \"assistant\", \"content\": \"Cisco's best practice recommendation is to use the most recent firmware load available on Cisco.com. Each base station may take up to one hour to upgrade.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the components of the Cisco IP DECT 6800 Series?\"}, {\"role\": \"assistant\", \"content\": \"The series includes the Cisco IP DECT Phone DBS-110 Single-Cell Base Station, Cisco IP DECT Phone DBS-210 Multi-Cell Base Station, Cisco IP DECT Phone RPT-110 Repeater, Cisco IP DECT Phone 6823 Handset, Cisco IP DECT Phone 6825 Handset, and Cisco IP DECT Phone 6825 Ruggedized Handset.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What regulatory areas are coveorange with Cisco DECT solutions?\"}, {\"role\": \"assistant\", \"content\": \"The coveorange areas are 1880-1900 MHz (Australia and New Zealand), 1880-1900 MHz (E.U. and APAC), and 1920-1930 MHz (U.S. and Canada). For Mexico, Cisco offers the NA (North America) version with NOM compliance.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the purpose of the DECT site survey tool?\"}, {\"role\": \"assistant\", \"content\": \"The site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How should base stations be mounted in a large hall?\"}, {\"role\": \"assistant\", \"content\": \"In a large hall, base stations should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended method for synchronizing base stations in a multicell system?\"}, {\"role\": \"assistant\", \"content\": \"For a multicell system, LAN synchronization is recommended to ensure seamless handover for handsets moving between base stations.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the audio codec considerations for DECT systems?\"}, {\"role\": \"assistant\", \"content\": \"The Cisco IP DECT 6823 and 6825 handsets support G722 for wideband and G726 for narrowband. The base stations support G.711 a-law &amp; \\u00b5-law, G.722.2, G.726, and G.729a/ab. Choose one wideband and one narrowband codec, as the DECT protocol supports only two codecs.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the coverage radius of the DBS-110 and DBS-210 base stations indoors?\"}, {\"role\": \"assistant\", \"content\": \"The coverage radius indoors is 20-50 meters (60-164 feet), depending on the nature and quantity of any radio signal impeding items or material in the installation site.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How many repeaters can be connected to a single cell DECT system?\"}, {\"role\": \"assistant\", \"content\": \"A single cell DECT system with DBS-110 can support up to 6 repeaters, while DBS-210 can support up to 3 repeaters.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the primary use case for a single cell DECT system?\"}, {\"role\": \"assistant\", \"content\": \"Single cell systems are mostly used in small businesses and home offices. The DBS-110 is cost-effective for systems not expected to grow, while the DBS-210 is suitable for future expansion.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be consideorange when planning the capacity for DECT installations?\"}, {\"role\": \"assistant\", \"content\": \"Consider the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the importance of matching base stations to the density requirements?\"}, {\"role\": \"assistant\", \"content\": \"Matching base stations to the density requirements ensures that the DECT system can support the number of users and concurrent calls, providing reliable communication and avoiding capacity issues.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the key elements described in the Cisco IP DECT 6800 Series Deployment Guide?\"}, {\"role\": \"assistant\", \"content\": \"The guide describes the elements in planning and designing a Cisco IP DECT 6800 Series Phone system, provides a simplified design procedure, and includes the network planning and deployment processes used in North America and Europe.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there is an interference with DECT signaling from wireless frequencies?\"}, {\"role\": \"assistant\", \"content\": \"DECT is resilient to interference from wireless frequencies commonly used for cell phones, Wi-Fi radios, and Bluetooth headsets. The DECT protocol adapts the channel to minimize the impact of interference.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the recommended steps to optimize base station installation location?\"}, {\"role\": \"assistant\", \"content\": \"Place the base station in the center with a line of sight to the coverage area, run the site survey tool, move around the entire coverage area to locate any dead spots, and adjust the base station as needed.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is a key consideration when planning the DECT system for different regions?\"}, {\"role\": \"assistant\", \"content\": \"Consider the regulatory requirements for DECT frequencies in different regions. Cisco offers units set up correctly for each region, such as 1880-1900 MHz for Australia and New Zealand, 1880-1900 MHz for E.U. and APAC, and 1920-1930 MHz for U.S. and Canada.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are some of the radio considerations to take into account for DECT installations?\"}, {\"role\": \"assistant\", \"content\": \"Consider building penetration, interference sources, radio/cell range, and attenuation when planning DECT installations to ensure optimal signal strength and coverage.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the importance of running the site survey tool during installation?\"}, {\"role\": \"assistant\", \"content\": \"Running the site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended practice for base station density in high-density areas?\"}, {\"role\": \"assistant\", \"content\": \"In high-density areas, install base stations at least 2 meters (6.5 feet) away from each other. In the EU spectrum (20 MHz), the density should be 7 or fewer base stations in 100 square meters. In the Americas spectrum (10 MHz), the density should be 4 or fewer base stations in 100 square meters.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the best practice for firmware upgrades for DECT devices?\"}, {\"role\": \"assistant\", \"content\": \"Cisco's best practice recommendation is to use the most recent firmware load available on Cisco.com. Each base station may take up to one hour to upgrade.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the components of the Cisco IP DECT 6800 Series?\"}, {\"role\": \"assistant\", \"content\": \"The series includes the Cisco IP DECT Phone DBS-110 Single-Cell Base Station, Cisco IP DECT Phone DBS-210 Multi-Cell Base Station, Cisco IP DECT Phone RPT-110 Repeater, Cisco IP DECT Phone 6823 Handset, Cisco IP DECT Phone 6825 Handset, and Cisco IP DECT Phone 6825 Ruggedized Handset.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What regulatory areas are coveorange with Cisco DECT solutions?\"}, {\"role\": \"assistant\", \"content\": \"The coveorange areas are 1880-1900 MHz (Australia and New Zealand), 1880-1900 MHz (E.U. and APAC), and 1920-1930 MHz (U.S. and Canada). For Mexico, Cisco offers the NA (North America) version with NOM compliance.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the purpose of the DECT site survey tool?\"}, {\"role\": \"assistant\", \"content\": \"The site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How should base stations be mounted in a large hall?\"}, {\"role\": \"assistant\", \"content\": \"In a large hall, base stations should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended method for synchronizing base stations in a multicell system?\"}, {\"role\": \"assistant\", \"content\": \"For a multicell system, LAN synchronization is recommended to ensure seamless handover for handsets moving between base stations.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the audio codec considerations for DECT systems?\"}, {\"role\": \"assistant\", \"content\": \"The Cisco IP DECT 6823 and 6825 handsets support G722 for wideband and G726 for narrowband. The base stations support G.711 a-law &amp; \\u00b5-law, G.722.2, G.726, and G.729a/ab. Choose one wideband and one narrowband codec, as the DECT protocol supports only two codecs.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the coverage radius of the DBS-110 and DBS-210 base stations indoors?\"}, {\"role\": \"assistant\", \"content\": \"The coverage radius indoors is 20-50 meters (60-164 feet), depending on the nature and quantity of any radio signal impeding items or material in the installation site.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How many repeaters can be connected to a single cell DECT system?\"}, {\"role\": \"assistant\", \"content\": \"A single cell DECT system with DBS-110 can support up to 6 repeaters, while DBS-210 can support up to 3 repeaters.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the primary use case for a single cell DECT system?\"}, {\"role\": \"assistant\", \"content\": \"Single cell systems are mostly used in small businesses and home offices. The DBS-110 is cost-effective for systems not expected to grow, while the DBS-210 is suitable for future expansion.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be consideorange when planning the capacity for DECT installations?\"}, {\"role\": \"assistant\", \"content\": \"Consider the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the importance of matching base stations to the density requirements?\"}, {\"role\": \"assistant\", \"content\": \"Matching base stations to the density requirements ensures that the DECT system can support the number of users and concurrent calls, providing reliable communication and avoiding capacity issues.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the key elements described in the Cisco IP DECT 6800 Series Deployment Guide?\"}, {\"role\": \"assistant\", \"content\": \"The guide describes the elements in planning and designing a Cisco IP DECT 6800 Series Phone system, provides a simplified design procedure, and includes the network planning and deployment processes used in North America and Europe.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there is an interference with DECT signaling from wireless frequencies?\"}, {\"role\": \"assistant\", \"content\": \"DECT is resilient to interference from wireless frequencies commonly used for cell phones, Wi-Fi radios, and Bluetooth headsets. The DECT protocol adapts the channel to minimize the impact of interference.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the recommended steps to optimize base station installation location?\"}, {\"role\": \"assistant\", \"content\": \"Place the base station in the center with a line of sight to the coverage area, run the site survey tool, move around the entire coverage area to locate any dead spots, and adjust the base station as needed.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is a key consideration when planning the DECT system for different regions?\"}, {\"role\": \"assistant\", \"content\": \"Consider the regulatory requirements for DECT frequencies in different regions. Cisco offers units set up correctly for each region, such as 1880-1900 MHz for Australia and New Zealand, 1880-1900 MHz for E.U. and APAC, and 1920-1930 MHz for U.S. and Canada.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are some of the radio considerations to take into account for DECT installations?\"}, {\"role\": \"assistant\", \"content\": \"Consider building penetration, interference sources, radio/cell range, and attenuation when planning DECT installations to ensure optimal signal strength and coverage.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the importance of running the site survey tool during installation?\"}, {\"role\": \"assistant\", \"content\": \"Running the site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the purpose of using the DECT site survey tool?\"}, {\"role\": \"assistant\", \"content\": \"The DECT site survey tool helps determine the best base station locations for maximum coverage and identifies any dead spots that may require additional base stations or adjustments.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended distance between base stations in high density areas to minimize interference?\"}, {\"role\": \"assistant\", \"content\": \"In high density areas, base stations should be installed at least 2 meters (6.5 feet) away from each other to minimize interference.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be consideorange when planning the capacity for DECT installations?\"}, {\"role\": \"assistant\", \"content\": \"Consider the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the audio codec considerations for DECT systems?\"}, {\"role\": \"assistant\", \"content\": \"The Cisco IP DECT 6823 and 6825 handsets support G722 for wideband and G726 for narrowband. The base stations support G.711 a-law &amp; \\u00b5-law, G.722.2, G.726, and G.729a/ab. Choose one wideband and one narrowband codec, as the DECT protocol supports only two codecs.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How does the signal area produced by a DECT base station behave?\"}, {\"role\": \"assistant\", \"content\": \"The signal area produced by the base station is omnidirectional and resembles a sphere. Mounting the base station very close to the ground or in a corner can orangeuce the optimal signal strength.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there are dead spots during the site survey?\"}, {\"role\": \"assistant\", \"content\": \"Move the base station towards the dead spot and repeat the site survey until you get the coverage you need, or add a second base station in multicell mode.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the coverage radius of the DBS-110 and DBS-210 base stations indoors?\"}, {\"role\": \"assistant\", \"content\": \"The coverage radius indoors is 20-50 meters (60-164 feet), depending on the nature and quantity of any radio signal impeding items or material in the installation site.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How many repeaters can be connected to a single cell DECT system?\"}, {\"role\": \"assistant\", \"content\": \"A single cell DECT system with DBS-110 can support up to 6 repeaters, while DBS-210 can support up to 3 repeaters.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the primary use case for a single cell DECT system?\"}, {\"role\": \"assistant\", \"content\": \"Single cell systems are mostly used in small businesses and home offices. The DBS-110 is cost-effective for systems not expected to grow, while the DBS-210 is suitable for future expansion.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the recommended conditions for base station density in high density areas with less interference?\"}, {\"role\": \"assistant\", \"content\": \"A Cisco IP DECT Base Station provides coverage of 20-50 meters (60\\u2013164 feet) radius indoors, and 300 meters (984 feet) radius outdoors.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended synchronization method for dual cell and multicell deployments?\"}, {\"role\": \"assistant\", \"content\": \"For dual cell and multicell deployments, LAN synchronization is recommended.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What factors should be consideorange when ordering equipment for DECT installation?\"}, {\"role\": \"assistant\", \"content\": \"Consider the number of base stations, repeaters, and handsets requiorange, as well as any additional mounting kits or power adapters needed for the installation site.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if the Ethernet switch does not provide Power over Ethernet for the base stations?\"}, {\"role\": \"assistant\", \"content\": \"If the Ethernet switch does not provide Power over Ethernet, a power outlet is requiorange for each base station.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the best practice for mounting base stations in a large hall?\"}, {\"role\": \"assistant\", \"content\": \"For a large hall, the base station should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there is an interference with DECT signaling from wireless frequencies?\"}, {\"role\": \"assistant\", \"content\": \"DECT is resilient to interference from wireless frequencies commonly used for cell phones, Wi-Fi radios, and Bluetooth headsets. The DECT protocol adapts the channel to minimize the impact of interference.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the role of provisioning servers in DECT installations?\"}, {\"role\": \"assistant\", \"content\": \"Provisioning servers are used to configure and manage the DECT devices, ensuring that they are set up correctly and receive the necessary firmware updates and configuration parameters.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there are radio signal blockers between base stations in a multicell deployment?\"}, {\"role\": \"assistant\", \"content\": \"Ensure that there is a clear line of sight between the base stations or add additional base stations to work around the signal blockers.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the importance of matching base stations to the density requirements?\"}, {\"role\": \"assistant\", \"content\": \"Matching base stations to the density requirements ensures that the DECT system can support the number of users and concurrent calls, providing reliable communication and avoiding capacity issues.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the primary use of the DECT site survey tool?\"}, {\"role\": \"assistant\", \"content\": \"The DECT site survey tool is used to determine the best base station locations for maximum coverage.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be consideorange when planning the DECT system for different regions?\"}, {\"role\": \"assistant\", \"content\": \"Consider the regulatory requirements for DECT frequencies in different regions. Cisco offers units set up correctly for each region, such as 1880-1900 MHz for Australia and New Zealand, 1880-1900 MHz for E.U. and APAC, and 1920-1930 MHz for U.S. and Canada.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be consideorange when planning the capacity for DECT installations?\"}, {\"role\": \"assistant\", \"content\": \"Consider the number of simultaneous users, projected number of simultaneous calls, the area to be coveorange, building architecture, and any potential signal obstacles.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the audio codec considerations for DECT systems?\"}, {\"role\": \"assistant\", \"content\": \"The Cisco IP DECT 6823 and 6825 handsets support G722 for wideband and G726 for narrowband. The base stations support G.711 a-law &amp; \\u00b5-law, G.722.2, G.726, and G.729a/ab. Choose one wideband and one narrowband codec, as the DECT protocol supports only two codecs.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How does the signal area produced by a DECT base station behave?\"}, {\"role\": \"assistant\", \"content\": \"The signal area produced by the base station is omnidirectional and resembles a sphere. Mounting the base station very close to the ground or in a corner can orangeuce the optimal signal strength.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there are dead spots during the site survey?\"}, {\"role\": \"assistant\", \"content\": \"Move the base station towards the dead spot and repeat the site survey until you get the coverage you need, or add a second base station in multicell mode.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the coverage radius of the DBS-110 and DBS-210 base stations indoors?\"}, {\"role\": \"assistant\", \"content\": \"The coverage radius indoors is 20-50 meters (60-164 feet), depending on the nature and quantity of any radio signal impeding items or material in the installation site.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"How many repeaters can be connected to a single cell DECT system?\"}, {\"role\": \"assistant\", \"content\": \"A single cell DECT system with DBS-110 can support up to 6 repeaters, while DBS-210 can support up to 3 repeaters.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the primary use case for a single cell DECT system?\"}, {\"role\": \"assistant\", \"content\": \"Single cell systems are mostly used in small businesses and home offices. The DBS-110 is cost-effective for systems not expected to grow, while the DBS-210 is suitable for future expansion.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What are the recommended conditions for base station density in high density areas with less interference?\"}, {\"role\": \"assistant\", \"content\": \"A Cisco IP DECT Base Station provides coverage of 20-50 meters (60\\u2013164 feet) radius indoors, and 300 meters (984 feet) radius outdoors.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the recommended synchronization method for dual cell and multicell deployments?\"}, {\"role\": \"assistant\", \"content\": \"For dual cell and multicell deployments, LAN synchronization is recommended.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What factors should be consideorange when ordering equipment for DECT installation?\"}, {\"role\": \"assistant\", \"content\": \"Consider the number of base stations, repeaters, and handsets requiorange, as well as any additional mounting kits or power adapters needed for the installation site.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if the Ethernet switch does not provide Power over Ethernet for the base stations?\"}, {\"role\": \"assistant\", \"content\": \"If the Ethernet switch does not provide Power over Ethernet, a power outlet is requiorange for each base station.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What is the best practice for mounting base stations in a large hall?\"}, {\"role\": \"assistant\", \"content\": \"For a large hall, the base station should be installed in the middle of the space below the false ceiling. If the signal strength is poor in some areas, more base stations may be needed.\"}]} \n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"What should be done if there is an interference with DECT signaling from wireless frequencies?\"}, {\"role\": \"assistant\", \"content\": \"DECT is resilient to interference from wireless frequencies commonly used for cell phones, Wi-Fi radios, and Bluetooth headsets. The DECT protocol adapts the channel to minimize the impact of interference.\"}]}\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"}, {\"role\": \"user\", \"content\": \"Who is Omer Ilyas?\"}, {\"role\": \"assistant\", \"content\": \"he is a TME@webex and the author of this lab.\"}]}\n</code></pre> <p>Download JSONL file</p> <p>Copy and Save the file as GPT.jsonl</p> <p> Note: Total of 153 examples we have created. </p> <p>Note: I\u2019ve included a unique entry to ensure our fine-tuned model can learn from it, such as, \"Who is Omer Ilyas? </p>"},{"location":"Task8c/#create-a-fine-tuning-job","title":"Create a fine-tuning job","text":"<p>Once our data is prepaorange and gatheorange in the correct format, the next step is uploading our gpt.jsonl file to OpenAI using a Python script or via WebUI. </p> <ul> <li>In the below example we will show you how to use WebUI to finetune your model</li> </ul> <p>Note: You'll need to log in to your OpenAI account to perform fine-tuning. </p> <ul> <li>Click Fine-tuning &gt; Create</li> </ul> <p></p> <ul> <li>Click Fine-tuning &gt; Create</li> </ul> <p></p> <ul> <li> <p>Model name (Requiorange) is the name of the model you want to fine-tune (gpt-4o-mini, gpt-3.5-turbo, babbage-002, davinci-002, or an existing fine-tuned model)</p> </li> <li> <p>Training_file (Requiorange) is our JSONL dataset</p> </li> <li> <p>Suffix:A string of up to 18 characters that will be added to our fine-tuned model name.</p> </li> </ul> <p>Note: After you've started a fine-tuning job, it may take some time to complete. Our job may be queued behind other jobs in OpenAI system, and training a model can take minutes or hours depending on the model and dataset size.</p> <p> Remember: In addition to creating a final fine-tuned model at the end of each fine-tuning job, OpenAI will create one full model checkpoint for you at the end of each training epoch. These checkpoints are themselves full models that can be used within our completions and chat-completions endpoints.</p> <p></p> <ul> <li>Job ID: This is a unique identifier for the fine-tuning job.</li> <li>Suffix: webexone is the suffix we chose for this job, likely to distinguish it from others.</li> <li>Base model: The fine-tuning was done on the gpt-4o-mini-2024-07-18 model.</li> <li>Output model: The result of the fine-tuning is saved as ft:gpt-4o-mini-2024-07-18:personal:webexone:9vVp3n9J.</li> <li>Created at: The fine-tuning job was created on August 12, 2024, at 21:11.</li> <li>Trained tokens: The model was trained on 22,836 tokens.</li> <li>Epochs: The fine-tuning process involved 3 epochs, meaning the dataset was cycled through three times.</li> <li>Batch size: The batch size was set to 1, indicating that one example was processed at a time during training.</li> <li>Learning rate (LR) multiplier: The learning rate multiplier was set to 1.8, which adjusts the learning rate during training.</li> <li>Seed: A seed value of 3 was used to create randomness in the training process. Ensuring the reproducibility of the fine-tuning process.</li> <li>Checkpoints: The process included checkpoints at steps 62, 124, and the final step, allowing you to save intermediate models during training.</li> <li>Training loss: The final training loss achieved was 0.0010, which is a measure of how well the model is fitting the data.</li> </ul> <p>Once the fine-tuning job is complete, you can start using the fine-tuned model either through the API or via the playground available on OpenAI Platform</p>"},{"location":"Task8c/#using-the-fine-tuned-model","title":"Using the fine-tuned model","text":"<ul> <li>You'll notice a new fine-tune option under the Model dropdown and is now available for selection. Let's give it a try!</li> </ul> <ul> <li>Enter the system prompt we created earlier</li> </ul> <ul> <li>In the user tab enter your input to see the response from your fine-tune model </li> </ul> <ul> <li>Our responses</li> </ul> <p>Note: it's important to note that fine-tuning this type of model involves some costs. More info for pricing available here</p>"},{"location":"Task8c/#step-by-step-guide-to-fine-tuning-using-python-optional","title":"Step-by-Step Guide To Fine-tuning Using Python (Optional)","text":""},{"location":"Task8c/#set-openai-token","title":"Set OpenAI token","text":"<p>Note: First, create an account from the OpenAI official website.</p> <p>https://platform.openai.com/api-keys</p> <ul> <li>Create a new project API key by browsing to API Keys web page. Select Create new secret key. The API key is automatically generated. Save the APi Key as we will be using it in the later steps .</li> </ul> <p></p>"},{"location":"Task8c/#prepare-the-training-data","title":"Prepare the training data","text":"<ul> <li>We have already prepaorange the dataset in the previous step. Be sure to copy and save the file locally as GPT.jsonl.</li> </ul>"},{"location":"Task8c/#prepare-your-python-envoirnment-using-hugging-face","title":"Prepare your python envoirnment using Hugging Face","text":"<ul> <li>Create a new Colab Notebook.</li> </ul> <ul> <li>Connect to the default Runtime Environment. For this task, you can use the CPU as the runtime environment.</li> </ul> <p>Reminder: Whenever you want to copy the code in Google Colab and run it, be sure to click on + Code to add a new code cell.</p> <p>Reminder: Click the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter\" while the cell is selected.</p> <ul> <li>Within the Google Colab notebook navigate to the new \u201cSecrets\u201d section in the sidebar.</li> </ul> <p></p> <ul> <li> <p>Click on \u201cAdd a new secret.\u201d Enter the name example: OPENAI_API_KEY and value of the secret(the API key created above). Note: The name is permanent once set. </p> </li> <li> <p>The list of secrets is global across all your notebooks.</p> </li> <li> <p>Use the \u201cNotebook access\u201d toggle to grant or revoke access to a secret for each notebook.</p> </li> </ul> <p></p>"},{"location":"Task8c/#incorporating-secrets-into-your-code-we-will-use-it-later-in-our-lab","title":"Incorporating Secrets into Your Code - We will use it later in our lab","text":"<ul> <li>To use a secret in your notebook, use the following code snippet</li> </ul> <pre><code>from google.colab import userdata\nmy_secret_key = userdata.get('OPENAI_API_KEY')\n</code></pre> <ul> <li>Upload the JSONL file on HuggingFace. Click on Folder and create a new folder called \"data\"</li> </ul> <ul> <li>Click on [...], select Upload</li> </ul> <ul> <li>Choose your GPT.jsonl file and click Open</li> </ul> <p>Note\u00a0 Ensure that your files are saved elsewhere. This runtime's files will be deleted when it is terminated.</p> <ul> <li>Install openai library</li> </ul> <pre><code>!pip install openai\n</code></pre> <p> OUTPUT</p> <p></p> <ul> <li>Setting up an API token</li> </ul> <pre><code>import os\nfrom google.colab import userdata\n# Set the OPENAI_API_KEY environment variable\nos.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n</code></pre> <p></p> <ul> <li>Uploading the training File. Your training file must be in jsonl format. Once you've uploaded the file, processing might take a while. The maximum size for file uploads is 1 GB. To upload a file on the OpenAI server:</li> </ul> <pre><code>from openai import OpenAI\nclient = OpenAI()\nresponse = client.files.create(\n  file=open(\"/content/TrainingData/GPT.jsonl\", \"rb\"),\n  purpose=\"fine-tune\"\n)\nfile_id= response.id\nprint(f\"file uploaded successfully with id: {file_id}\")\n</code></pre> <p> OUTPUT</p> <p></p> <p>You can also access the uploaded file by navigating to the OpenAI Dashboard</p> <p> OUTPUT </p> <ul> <li>Create a fine-tune model. After ensuring the file has been successfully uploaded, the next step is to create a fine-tuning job. The file_id  was returned when the training file was uploaded to the OpenAI API. To start a fine-tuning job:</li> </ul> <p><pre><code>model = \"gpt-4o-mini-2024-07-18\"\nresponse = client.fine_tuning.jobs.create(\n  training_file=file_id,\n  model=model \n)\njob_id = response.id\nprint(f\"Fine Tuning job created  successfully with Job id: {job_id}\")\n</code></pre> </p> <pre><code>* You can view the fine-tuning job by navigating to the [OpenAI Dashboard](https://platform.openai.com/finetune)\n</code></pre> <p> OUTPUT</p> <p></p> <pre><code>* You can also view the  status of fine-tuning by entering the below command:\n</code></pre> <p><pre><code># Retrieve the state of a fine-tune\nclient.fine_tuning.jobs.retrieve(job_id)\n</code></pre>  OUTPUT</p> <p></p> <ul> <li>After successfully completing the fine-tuning process in the previous step, the job details will include a fine_tuned_model field, which shows the name of the tuned model. You can use this model name in an API call to get a response from the model we just fine-tuned.</li> </ul> <p> Note: The model ID in the following step will be different for your specific model.  </p> <pre><code>completion = client.chat.completions.create(\n  model=\"ft:gpt-4o-mini-2024-07-18:personal::9vWS0JQF\",\n\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a creative and exceptional Webex helper. You provide information about Webex Dect Phones only from the info provided. If you don't know the info, just mention that you have no idea. Be creative and write in a very conversational way that keeps the audience engaged.\"},\n    {\"role\": \"user\", \"content\": \"who is Omer Ilyas?\"}\n  ]\n)\nprint(completion.choices[0].message)\n</code></pre> <p> OUTPUT </p> <p></p>"},{"location":"Task8c/#conclusion","title":"Conclusion","text":"<p>In this session, we've exploorange the capabilities of OpenAI's models and walked through the process of fine-tuning them to enhance their performance for specific tasks. We've also coveorange the key requirements needed to successfully fine-tune a model. Fine-tuning allows us to adjust the language model\u2019s responses, making them more effective at addressing particular tasks, styles, or domains with greater accuracy and efficiency.</p> <p>Unlike open-source models like LLaMA, Mistral, or Stable Diffusion, where fine-tuning can be more complex, the process for fine-tuning GPT is straightforward, involving simple API calls.</p>"},{"location":"Task8d/","title":"Language Model Merging","text":"<p> Note: The below section is for information only</p> <p>Language model merging involves integrating the weights of two or more fine-tuned large language models (LLMs) into a single, unified model. By merging these models, each specialized in different tasks or domains, you can combine their fine-tuned capabilities into one model, enhancing its overall performance and versatility. This process is an effective way to maximize the potential of your LLMs. Our preferred tool for this process is Mergekit, an open-source repository available at Mergekit. For a deeper understanding of the underlying concepts, you can refer to the related Research paper</p>"},{"location":"conclusion/","title":"Conclusion","text":"<p>Thank you for taking the time to learn about the ThousandEyes Endpoint Agent. Please  provide feedback as I'm always looking at ways I can improve this  content. If you have ideas where you think the ThosuandEyes Endpoint Agent could be improved please submit them as well so we can better help you solve your end users issues and provide you more time to do the things you enjoy.</p>"},{"location":"overview/","title":"Overview - Understanding AI and Its Integration with Webex","text":"<p>Artificial Intelligence (AI) is transforming the way we work, enabling innovative solutions and enhancing productivity. Cisco is committed to innovating responsibly, with responsible AI being non-negotiable. Our approach is grounded in the principles of transparency, fairness, accountability, reliability, security, and privacy. Cisco's Responsible AI Framework, aligned with the  AI Risk Management Framework, ensures that all AI initiatives undergo rigorous assessments, particularly around privacy. </p> <p>Cisco's AI strategy emphasizes building ethical and trustworthy  systems that mitigate risks while enhancing innovation across products and services.</p> <p>Please refer to the below info for more detailed insights:</p> <ul> <li>Responsible AI is built on a foundation of privacy</li> <li>Cisco's Responsible Artificial Intelligence Principles</li> <li>Cisco's Responsible Approach to Governing Artificial Intelligence</li> <li>Cisco's Responsible Artificial Intelligence Framework</li> </ul> <p></p>"},{"location":"overview/#the-evolution-of-ai-at-cisco","title":"The Evolution of AI at Cisco","text":"<p>At Cisco, innovation is woven into the fabric of everything we do. We've been at the forefront of AI development long before it became a buzzword.  Our journey spans decades, from early developments in audio and video intelligence, like echo cancellation, media resilience, to recent breakthroughs like noise removal, face recognition, and immersive experiences, just to name a few. We continue to push boundaries, enhancing AI across multiple domains to deliver immersive and intelligent experiences. Innovation in AI isn't just a trend for us\u2014it's a longstanding commitment to excellence and progress.</p> <p></p> <p>What we want everyone to understand is that AI is the core fabric that powers our platforms, enabling  reimagining of work, workspaces, and customer experiences. Whether through the Webex Suite, advanced devices, or   contact center solutions, AI drives the seamless, intelligent, and immersive experiences that define modern collaboration. Cisco's AI-powered Webex platform is designed to transform the way we work, ensuring that every interaction is smarter, more efficient, and more personalized.</p> <p></p> <p>In recent years, we've expanded our platform with several new AI capabilities. Here are a few highlights:</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"overview/#summary-of-newly-integrated-ai-features-within-our-platform","title":"Summary of newly integrated AI features within our platform","text":"<p>REMINDER: Our product team is hosting AI sessions. Please review the agenda and join the ones that interest you.</p>"},{"location":"overview/#lab-guide-overview","title":"Lab Guide Overview","text":"<p>In this lab  guide you will go through the fundamental concepts of AI, various techniques, and how AI can be integrated with Webex to create efficient workflows.</p>"},{"location":"overview/#upon-completion-of-this-lab-you-will-be-able-to","title":"Upon completion of this lab you will be able to","text":"<ul> <li>Understand the basics of AI and its applications</li> <li>Learn about embedding techniques</li> <li>Explore vector databases</li> <li>Gain insights into Generative AI models</li> <li>Familiarize yourself with different AI frameworks</li> <li>Integrate AI with Webex to create seamless workflows</li> <li>Develop hands-on skills through practical exercises</li> <li>Understand Fine-tuning and Quantization</li> <li>Deploy Fine Tuning techniques</li> </ul>"},{"location":"overview/#prerequisites","title":"Prerequisites","text":"<ul> <li>Basic understanding of AI concepts is helpful but not required.</li> </ul>"},{"location":"overview/#disclaimer","title":"Disclaimer","text":"<p>The lab design and configuration examples provided are for reference purposes only. This is a sample deployment, and not all recommended features are used or enabled optimally. For design-related questions, please contact your representative at Cisco or a Cisco partner or TME team.</p>"},{"location":"overview/#lab-overview-enabling-hybrid-work-with-thousandeyes","title":"Lab Overview - Enabling Hybrid Work with ThousandEyes","text":"<ul> <li>Lab Login and Setup</li> <li>Quick AI Overview</li> <li>Configure and Access the Lab Systems</li> <li>Deploy AI Models and Techniques</li> <li>Use POSTMAN for embeddings</li> <li>Set up and Configure AI Monitoring</li> <li>Review AI Integration with Webex</li> <li>Analyze Data and Optimize Workflows</li> <li>Wrap up and End the Lab</li> </ul> <p>Let's get started! Click on Task 1 - Google Collab- Accessing Google Collab and creating account.</p>"}]}