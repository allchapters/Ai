{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"Task1/","title":"Task 1: Lab Login and Setup","text":"<p>Click to access the lab</p> <p>This lab requires a set of characters which will be aligned with roles to access ThousandEyes and Webex. Optional you can also register your Webex device on the platform that can be used with your demo.</p> <p>Click My Characters then click Add New Character as shown in the below image. You only need to create one character for the lab.</p> <p></p> <p>Click Create Character.  Note (They will be randomly created so yours may not match the below screenshot. Also you have an option to modify the names as per your preferences.)</p> <p></p> <p>Optional Step Click on the My Devices tab, select Add New Room Device, if you want your device to be available in the demo and thousandEyes agent installed on your device. Please remember its an optional step.</p> <p></p> <p>Make sure you are on your demo page Click Start Demo (you may have to use the back arrow to navigate back to the main overview page)</p> <p></p> <p>Next we need to provide a few details in order for the lab to be spun up.</p> <ul> <li>Audience: External</li> <li>External Type: Trade Show</li> <li>Tradeshow Name: Roadshow</li> <li>Demo Session Name: Enter your name \u2013 or leave it default</li> </ul> <p></p> <p>Click Next and then choose the character you created previously. (Note: this will be needed for automated session testing - AST)</p> <p></p> <p>Click Next and add a virtual workstation using the '+\" sign. This will be used to install the ThousandEyes Endpoint Agent (EPA) which can be configured to monitor web browser sessions, automtically monitor dynamic Webex meeting network connections and run scheduled tests in the background. Note you also have an option to install the ThousandEyes agent on your personal machine</p> <p></p> <p>Optional Step  If you have a Webex device select your device and click Next </p> <p></p> <p>Click Next select your duration and Click Start Demo as shown in the below screenshot.</p> <p></p> <p>This is roughly a 45 min lab but the access duration can be upto 3 days. It will take a few minutes for the lab to spin up. While this is occurring proceed on to the ThousandEyes Overview content and extra background information in Task 2.</p>"},{"location":"Task2/","title":"Task 2: ThousandEyes Overview","text":"<p>Feel free to take a few minutes while the lab spins up and review the Getting Started with Endpoint Agents guide.</p> <p></p> <p></p> <p></p> <p>Connectivity is your business, but it\u2019s changing rapidly. Your brand is only as good as your network.\u200b Digital experience is how you are measured, but most of the path is outside your control (outside the core)\u200b What do you need to do about it?\u200b How can you understand digital experience to the things your customers are accessing\u200b and understand health of the Internet cloud and peering providers. Continue your journey to learn how ThousandEyes can help answer these questions and help solve your network and application acceess issues.</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>Now that you have a great background on ThousandEyes it's time to go back and verify the lab has started and login. Task 3.</p> <p>Also feel free to check our awesome TE Blog and Webex site.</p>"},{"location":"Task20/","title":"Logging Out and Ending the Lab Session","text":"<p>Close out of the Chrome Browser Close out Webex Close the Windows VM browser tab Log out of the ThousandEyes and close the incognito browser</p> <p>In the Webex Demo Toolbox browser tab scroll to the bottom and click End</p> <p></p> <p>Click End Session in the pop up to shutdown the lab and close the tab</p> <p></p> <p>Time to wrap things and with the Lab Conclusion.</p>"},{"location":"Task3/","title":"Task 3: Log into the Lab Environment","text":"<p>Click My Demo Sessions select your ThousandEyes demo and click the green View button</p> <p></p> <p>Lab Administration Information (New Read Only Admin User)</p> <ul> <li>Webex Control Hub/ThousandEyes Admin Access - A new read only admin user will be created. This is the new user you'll use to access the Webex ControlHub and ThousandEyes Platform (Note: Your user will most likely be different than this one as they are radomly assigned.)</li> <li>Email Address will be used for the SSO login access as well as the Password</li> </ul> <p></p> <ul> <li>Access information to the Webex ControlHub Portal -  right click and use an Incognito Browser</li> </ul> <p></p> <ul> <li>Access information to the ThousandEyes Portal be sure to right click and use an Incognito Browser</li> </ul> <p></p> <p>First thing will be to get your VM set up</p> <ul> <li>Click the Workstation 1 link. You should see a Windows Desktop show up in new browser tab.</li> </ul> <p></p> <p>Right Click on the This PC desktop icon and click Properties so you can rename the VM.</p> <p></p> <p>Click Rename this PC</p> <p></p> <p>Name the PC your-name-Roadshow (no spaces), click Next and click Restart Now</p> <p></p> <p>While the VM reboots go back to your previous tab for demo . Right click the Control Hub URL and ThousandEyes Administration Portal link and open both in incognito browsers as we will be using them in the coming steps. The same creds can be used to login into Webex Control Hub and ThousandEyes  </p> <p></p> <p>Use the credentials from the ControlHub/ThousandEyes Read Only Admin in the next steps.</p> <p></p> <p>Your incognito browser will open to the ThousandEyes SSO login page as shown in the below image. Use the Username and Password from the ThousandEyes Read Only Admin to complete the login process. Click Don\u2019t show this again and Yes in the pop up window after you have completed the SSO login process.</p> <p></p> <p></p> <p>You should now see the ThousandEyes Default Dashboard (see the below image). You can leave this browser open and we will come back to it later.</p> <p></p> <p>Note: Follow the above creds/steps to login into Webex Control Hub as we will be using them in coming steps.</p> <p>Log back into the Windows VM. Navigate back to the tab that had the Windows VM running in it and click \u201cReconnect\u201d or if that tab closed you click on the Workstation 1 link to open a new session to it.</p> <p></p> <p>Note if a Let\u2019s finish setting up your PC window appears just click \u201dRemind me Later\". Also close the CC Cleaner browser and Accept the Webex EULA (if they appear).</p> <p></p> <p>Time to install the ThousandEyes Endpoint Agent (EPA) continue to Task 4.</p>"},{"location":"Task4/","title":"Task 4: Install the ThousandEyes EPA","text":"<p>Once on your VM station,make sure no browser sessions are running on Window VM then click the ThousandEyes Agent Installer</p> <p></p> <p>You should NOT have to do this but if you don\u2019t see the ThousandEyes Agent Installer go back to the tab for the lab and click the Instructions link then copy the link for the Windows x64 Agent Install (MSI) \u2013 Full from the Demo Downloads and Links section. Navigate back to the Windows VM tab, open a browser and paste the link into it to download the installer. Locate the installer and click it to install it.</p> <p></p> <p>Click Next and Accept the License Agreement</p> <p></p> <p>Click the disk icon for ThousandEyes Endpoint Agent and Google Chrome and select Entire feature will be installed on local hard drive then click Next and Finish.</p> <p></p> <p>Note the above step will install ThousandEyes Endpoint agent on the VM provided. As mentioned earlier you can also get the install file from the Instruction tab and install the same on your personal machine (windows/mac)</p>"},{"location":"Task4/#start-up-a-webex-meeting-on-your-vm","title":"Start up a Webex Meeting on your VM","text":"<p>This will generate Webex traffic which we will view later in the lab. Navigate back to your lab information tab. Copy the email address for the character you created to schedule a Webex meeting with. You will use this to login into Webex App and start a Webex meeting session.</p> <p></p> <p>Navigate back to your VM web browser tab and click on the Webex icon then sign in using the email address and password from your character.</p> <p></p> <p></p> <p>Click the Webex icon on the task bar. Click Meetings. Click Start a Personal Room meeting.  Note Your WebexApp might do a quick update.</p> <p></p> <p>Click Join meeting and then click Start meeting.</p> <p></p> <p>This will generate Webex traffic which you will view later in the lab. Note: Since no one is joining the meeting it may have a pop up after a while warning the meeting will end unless you click to keep it active. Feel free to click to keep it active or you can add another participant in that meeting or you can always go back and Start a Personal Room Meeting again.</p>"},{"location":"Task4/#login-to-webex-controlhub","title":"Login to Webex ControlHub","text":"<p>Once the user join a meeting you can login into Webex Control Hub using the (read only admin) credentials provided.  </p> <p></p> <p>Click on Troubleshooting search for your userid that you have used to join the Webex meeting.</p> <p></p>"},{"location":"Task4/#locate-your-thousandeyes-epa","title":"Locate your ThousandEyes EPA","text":"<p>By now you have your ThousandEyes Endpoint Agent running. Let\u2019s verify it has connected to the ThousandEyes Platform.</p> <p>Navigate back to your incognito browser that is logged into ThousandEyes.</p> <p>Click Endpoint Agents &gt; Agent Settings (if you were already in the tab you may have to click refresh)</p> <p>Search for your EPA </p> <ul> <li>In the search bar type the name you gave your VM (if it doesn\u2019t show up contact a lab proctor). Also verify that the Google Chrome Browser Extension shows up as shown in the below screen shot.</li> </ul> <p></p> <p>If your Google Chrome Browser Plug-in didn\u2019t install. (Note sometimes it take a minute to show up. Please refresh the browser.) Navigate back to your VM and click on the Google Chrome icon on the task bar.</p> <ul> <li>Install the Google ThousandEyes Google Chrom Plug-in by pasting this link in your Google Chrome Browser</li> <li>https://chrome.google.com/webstore/detail/thousandeyes-endpoint-age/ddnennmeinlkhkmajmmfaojcnpddnpgb</li> </ul> <p>If asked Turn on Sync. Navigate back to the incognito browser logged into ThousandEyes and your ThousandEyes EPA should look like the one below.</p> <p></p> <p>You are now ready to continue your journey see how AST (Automated Session tests) can automatically monitor Webex meetings. Customize and see how your EPA monitors browser sessions and set up scheduled tests to montior the health of critical applications in the background. Scheduled tests are a great way to provide a baseline for application and network health. The browser sessions provide the view of what the end users session is like when sites are accessed in the domains you are interested in monitoring. And Automated sessions tests will integrate with Webex and monitor traffic automatically whenever a user joins a Webex meeting from Webex App or the RoomOS devices. Let's carry on with Task 5.</p>"},{"location":"Task5/","title":"Task 5: Configure ThousandEyes Automated Session tests and EPA Monitoring","text":""},{"location":"Task5/#set-up-automated-session-tests-for-webex-meetings-optional-step","title":"Set up Automated Session tests for Webex Meetings - Optional Step","text":"<p>Automated Session Tests enable the Endpoint Agents installed on your  workstations to monitor and identify network connections between a user\u2019s application and the destination node (Webex); thereby, removing the ambiguity of knowing whether the IP addresses created in synthetic tests are going to the right datacentre or service. Automated Session Tests capture the performance of a desktop application e.g. Webex App, without you having to manually configure an IP address or hostname for the application.</p> <p>Note: The below configuration steps are for information purpose only</p> <ul> <li>Navigate to the Endpoint Agents &gt; Monitoring Settings &gt; Automated Session Tests tab.</li> <li>Click the Add New Test button.</li> </ul> <p></p> <ul> <li>Create an AST to monitor Webex Meetings in your organization  </li> </ul> <p></p> <p>Note: The above steps have already been configured. Showing for information purpose only. </p> <p>Note: More info can be found on Webex help that explains how to create a configuration between ControlHub and ThousandEyes platform.</p> <p>When the user (that was created by you) initiate and join a Webex meeting from the WebexApp, you be able to view the ThousandEyes path in ControlHub troubleshooting section.</p> <ul> <li>If you have logged out, log back in ControlHub using Readonly admin creds provided . Click on Troubleshooting,  search for your userid that you have used to join the Webex meeting and click the meeting that is in progress.</li> </ul> <p>Note Make sure the Webex meeting is still going on in the virtual machine. As you are the only participant, it will disconnect in some time. If disconnected, please start the meeting again.</p> <p></p> <ul> <li>Click your demo user id</li> </ul> <p></p> <ul> <li>You will notice ThousandEyes path. ThousandEyes AST starts capturing network path data as soon as the meeting starts. However, there could be a delay of up to five minutes before that data populates in Troubleshooting section. </li> </ul> <p></p> <ul> <li>The network path route shows the details for each node that the hop connected to. Click on any of the dotted lines </li> </ul> <p></p> <ul> <li> <p>You can hover over a dotted line to see the user's latency (round-trip) average value during that interval. The color changes depending on the threshold that the value met. Thresholds in Webex are are calculated as:</p> <pre><code>- Poor (red)\u2014Latency &gt; 400ms or Loss (round-trip) &gt; 5%\n- Good (green)\u2014Latency &lt; 300ms or Loss (round-trip) &lt; 3%\n- Fair (yellow)\u2014Neither of the above.\n- Unknown (grey)\u2014Not available yet. You still be able to retrieve the metric from the TE dashboard.\n</code></pre> </li> <li> <p>You can also click on Launch the ThousandEyes dashboard . It will cross-launch from the Webex ControlHub Network Path into ThousandEyes platform. You will be navigated to the Automated Session Tests view, which is found within the Endpoint Agents &gt; Views &gt; Automated Session Tests section of the web application. The view is pre-filtered to the corresponding user and time segment from Webex Control Hub.</p> </li> </ul> <p></p>"},{"location":"Task5/#understanding-scheduled-tests","title":"Understanding Scheduled tests","text":"<p>Before setting up scheduled tests it's a good idea to create an Agent Label and assign your EPA to it. Labels are a super powerful way to dynamically manage how ThousandEyes Endpoint Agents are configured for testing and reporting.</p> <p>For more information on Endpoint Agent Labels check out our documentation.</p> <p>Click the Agent Labels if you are still viewing your EPA otherwise navigate to Endpoint Agents &gt; Agent Settings &gt; Agent Labels.</p> <p>Click Add New Label. Name the label e.g RS_PC, select any color.</p> <p>In the Filter section select Agent in and use the pull down to select your agent (note you can use the search field to quickly find your agent). Click Save. See the image below for and example of how to add your agent to your label.</p> <p></p>"},{"location":"Task5/#set-up-scheduled-tests-for-your-thousandeyes-epa","title":"Set up Scheduled Tests for your ThousandEyes EPA","text":"<p>You will build a test that will run every minute to https://office.com for this lab but feel free to build other tests. You can have up to 10 tests run on an EPA.</p> <p>Navigate to Endpoint Agents &gt; Monitoring Settings</p> <p>Click Add New Test</p> <ul> <li>Type Web, HTTP Server (this is the default)</li> <li>Test Name: Set a unique name</li> <li>URL: https://office.com</li> <li>Interval: 1 minute</li> <li>Agents: Agent label then select the label you created</li> <li>Click the prioritize slider (as this is an important test)</li> <li>Click Add New Test (note you can also Run Once but if you do this don\u2019t forget to save the test!)</li> </ul> <p></p>"},{"location":"Task5/#set-up-browser-sessions-for-your-thousandeyes-epa","title":"Set up Browser Sessions for your ThousandEyes EPA","text":"<p>Set up domains to be monitored when the browser on the Windows VM accesses them (Note: Only Chrome, Edge or IE 11+ browsers are supported). Typically these consist of the domains that are critical for your users and businses operations. You'll see shortly how powerful this can for troubleshooting users issues. </p> <p>Navigate to Endpoint Agents &gt; Monitoring Settings &gt; Browser Sessions. For more information on Browser Session monitoring click here.</p> <p>Click Add New Monitored Domain Set</p> <ul> <li>Domain Set Name: Set a unique name</li> <li>Monitored Domains: office.com, webex.com, cisco.com (feel free to add in other domains)</li> <li>Agents: Agent Labels and select your agent label that you created earlier  </li> <li>Click Add New Monitored Domain Set</li> </ul> <p></p>"},{"location":"Task5/#automated-sessions-tests-ast-for-your-thousandeyes-epa","title":"Automated Sessions Tests (AST) for your ThousandEyes EPA","text":""},{"location":"Task5/#navigate-back-to-your-vm","title":"Navigate back to your VM","text":"<p>Open the Chrome Browser and navigate to the domains you set for browser sessions. Open a tab and bring up a site in each tab:</p> <ul> <li>https://cisco.com</li> <li>https://webex.com</li> <li>https://office.com</li> </ul> <p></p> <p>Click refresh on each tab a few times to create some extra sessions. Do this for a few minutes randomly to generate web browser traffic which we will analyze later. If you need to test out having browser traffic randomly generated to a site or set of sites a great chrome plug in to use is Auto Refresh Plus. We won't go into configuring or installing it for this lab.</p> <p>You should have some good data captured with the Webex session running in the background on the VM being catpured with the Webex AST, the scheduled tests runing in background providing a baseline and then the browser sessions. Time to move onto Task 6 and start analyzing the data!</p>"},{"location":"Task6/","title":"Analyzing ThousandEyes EPA Data","text":"<p>Typically when a user experiences an issue they will either suffer in silence, wait for the issue to go away and when it crops up again get frustrated and call in for help. Sometimes while they are working with support or the helpdesk the issue resolves itself. This makes it really difficult to troubleshoot issues if they aren't presistent. ThousandEyes stores 30 days of data so you have the abilty to go back in time and see what was occuring or see if this issue has been occuring and the user just didn't call into support.</p>"},{"location":"Task6/#code-annotation","title":"Code Annotation","text":""},{"location":"Task6/#codeblocks","title":"CODEBLOCKS","text":"<p>Some <code>Code</code> will be below:</p>"},{"location":"Task6/#a-plain-code-block","title":"A plain Code Block","text":"<pre><code>Some Code here\n\nprint(A)\n</code></pre> omer.py<pre><code>Some Code here\n\nprint(A)\n</code></pre> <pre><code>Some Code here\n\nprint(A)\n</code></pre> <pre><code>Some Code here\n\nprint(A)\n</code></pre> <p> If you are troubleshooting a issue and want to quickly see all the test data for a users system Agent Views provides the perfect visualization.</p> <p>Navigate to VM session and browse to ThousandEyes portal. Open Endpoint Agents &gt; Agent Views (be sure to use the incognito browser). Use the search box to find your agent which will be what you named your VM. Then you can begin to explore the metrics and tests. The top section contains your system\u2019s performance metrics.</p> <ul> <li>Use the Metrics pull down to view the different system metrics</li> </ul> <p></p> <p>The middle section shows Automated Session Tests (ASTs) and Scheduled Tests (up to 10 max).</p> <ul> <li>Use the pull down to view the different web and network metrics.</li> </ul> <p></p> <p>The bottom section shows browser sessions. If you don\u2019t see anything you might need to refresh the tabs in your VM\u2019s browser a few extra times or refresh the Agent Views page.</p> <ul> <li>Use the pull down to view the different browser and network metrics.</li> </ul> <p></p>"},{"location":"Task6/#drill-into-a-automated-session-test","title":"Drill into a Automated Session Test","text":"<p>Now that you\u2019ve explored the Agent Views page click on the AST metric to dive into the detailed view associated with the Webex Test. If you don\u2019t have any network loss try changing the metric to latency.</p> <p></p> <p>You will now see a filtered view for your agent showing the network path which is dynamically created based on the endpoints your Webex session is connected to while the Webex session is running.</p> <p>Here\u2019s an example view. I used the upper right Save and Share feature to create a snapshot that anyone can view for a full year! This can be very helpful as it can be attached to tickets, shared with the end user, anoter team or a service provider. They will see what you see making it simple to collaborate and reduce any finger pointing. (think back to the last slide in the ThousandEyes Overview).</p> <ul> <li>Open the snapshot in another browser tab</li> <li>You can mouse over the nodes for extra information</li> <li>Try changing the metric and drag over and navigate the time bar to see how the test changes</li> </ul> <p></p> <p>From this same view you can change the grouping to show IP Addresses and adjust the number of hops to get more a granular hop by hop network path.</p> <ul> <li>You can mouse over the nodes and links for extra information.</li> <li>You can also adjust the link delay. In the below screenshot used 10ms. You can also click on the 8 links to see all links highlighted that are over 10ms.</li> </ul> <p></p> <p>Feel free to navigate back to your Automated Session Test view showing your agent and click around to expermiement with how to see similar data.</p>"},{"location":"Task6/#drill-into-scheduled-tests","title":"Drill into Scheduled Tests","text":"<p>Scheduled tests provide a consistent baseline. Whenever an Endpoint Agent is online the test runs at the specified interval. Navigate back to Agent Views and search and select your agent.</p> <ul> <li>Click Agent Views and use the search box to find your agent.</li> <li>Click into the scheduled test to drill into a filtered view. (If you set up other scheduled tests feel free to use one of them instead)</li> </ul> <p></p> <p>Now you're in a filtered test view. Note the filters at the top of the screen showing the test and your agent. See the below screen shot as an example.</p> <ul> <li>Adjust the metric to latency and change the grouping to IP Address</li> <li>Adjust the hops to max using the slider</li> <li>Set the link delay to 10ms and then click on the links to highlight them in the network path</li> </ul> <p></p> <p>If you wanted to see all agents that are runnig the scheduled test you could just remove the agent filter (this won't work in this lab as we have only one agent). This would be a great way to figure out if an issue is effecting multiple users or start to isolate the users that are having issues as they might all be in the same building or connecting through the same router that is causing congestion, latency or loss. You can also right click on the agent to pull up the traceroute which is run every time the test is executed.</p> <p>Another powerful feature is the Run Now option for when you are actively troubleshooting and need test results right away or you can make changes and run it. Feel free to test it out.</p> <p></p> <p>Note: It might take a few minutes for the test to complete and then be processed for visualization. So you may want to kick it off and then continue on with the lab and come back to the tab in a few minutes.</p>"},{"location":"Task6/#drill-into-browser-sessions","title":"Drill into Browser Sessions","text":"<p>Browser Sessions are generated using the browser plugin and will monitor the user experience and network path for your monitored domain set. The experience score is a calculated metric to help gauge the end users web performance. You can change the metric based on what you are wanting to use for troubleshooting. Navigate back to Agent Views and search and select your agent. Click on the www.cisco.com session to drill into a filtered view. Note if your browser sessions aren\u2019t showing up, verify your agent is associated with the agent label and then make sure to go back to the browser and refresh the tabs.</p> <p></p> <p>The browser session view shows the visited pages and experience score. See the below screenshot for an example. Note the filter for the Visited Site and Agent which was automatically applied based on the browser session test you clicked from the Agent View.</p> <p></p> <p>You can easily explore the other metrics from the session. Click on the web site to bring up the session, system and network details and review the tabs for the path trace and waterfall details. Additional metric will be pulled in based on how the Enpoint Agent is connected to the network like wireless, vpn or proxy.</p> <p> </p> <p>ThousandEyes takes a layered approach with visualizing the data to help you isolate and troubleshoot issues. The Network Layer will show the network path filter on the browser session. Click on the Network Layer that is associated with the Browser Session. Explore the different metrics that are captured in context in time like CPU Load.</p> <p></p>"},{"location":"Task6/#local-network-view","title":"Local Network View","text":"<p>The Local Networks view will provide the local network and DNS information. This can be very helpful for finding bad DNS settings or Wi-Fi related issues. Click into the Local Networks &gt; Network Access layer and make sure your agent is still in the agent filter or clear it out with the X to see all agents. Explore the different metrics as well using the pull down. If this was a production environment the filters could be used for isolation of issues.</p> <p></p>"},{"location":"Task6/#endpoint-agent-overview","title":"Endpoint Agent Overview","text":"<p>This page provides a quick overall health view of your Endpoint Agents. Navigate to the Endpoint Agents &gt; Overview to see all the stats from all the agents. Try adjusting the time range as well.</p> <p></p> <p>Now that you've learned about the metrics, tests and various way that ThousandEyes can help you troubleshoot, isolate and resolve end users issues you're one short step from the final stage of this learning jounery. The last step will be learning about some of the ways a dashboard can be used to visualize the endpoint agent data and shared with other stakeholders. Check out Task 7 to learn about Endpoint Agent data in Dashboards.</p>"},{"location":"Task7/","title":"Fine-Tuning Large Language Models","text":""},{"location":"Task7/#fine-tuning-llms","title":"Fine-Tuning LLMs","text":"<p>Goals: Equip audience with knowledge and practical skills in finetuning techniques accompanied by code examples. Discuss the approach to finetuning LLMs.</p> <p>The section centers around fine-tuning LLMs, addressing their various aspects and methodologies. As the module progresses, the focus will be given to specialized instruction tuning techniques, namely \u00a0LoRA. It will examine domain-specific applications (Webex Calling), ensuring a holistic understanding of fine-tuning techniques and their real-world implications.</p> <ul> <li>Techniques for Finetuning LLMs: The lesson highlights the challenges, particularly the resource intensity of traditional approaches. We will introduce instruction tuning methods like \u00a0LoRA.</li> <li>Deep Dive into LoRA and SFT: This lesson offers an in-depth exploration of LoRA and SFT techniques. We will uncover the mechanics and underlying principles of these methods.</li> <li>Finetuning using LoRA : This lesson guides a practical application of LoRA and SFT to finetune an LLM to follow instructions, using data from the \u201cHuggingFace Dataset\u201d .</li> </ul>"},{"location":"Task7a/","title":"Techniques for Finetuning LLMs","text":""},{"location":"Task7a/#introduction","title":"Introduction","text":"<p>In this lesson, we will examine the main techniques for fine-tuning Large Language Models for superior performance on specific tasks. We explore why and how to fine-tune LLMs, the strategic importance of instruction fine-tuning, and several fine-tuning methods, such as  Low-Rank Adaptation (LoRA), Supervised Finetuning (SFT). We also touch upon the benefits of the Parameter-Efficient Fine-tuning (PEFT) approach using Hugging Face's PEFT library, promising both efficiency and performance gains in fine-tuning.</p>"},{"location":"Task7a/#why-we-finetune-llms","title":"Why We Finetune LLMs","text":"<p>While pretrained Large Language Models (LLMs) provide a broad understanding of language, it doesn't equip them with the specialized knowledge needed for complex tasks. For instance, a pre-trained LLM may excel at generating text but encounter difficulties when tasked with sentiment analysis or even providing information from your own Knowledge base. This is where fine-tuning comes into play.</p> <p>Fine-tuning is the process of adapting a pretrained model to a specific task by further training it using task-specific data. For example, if we aim to make an LLM proficient in answering questions about Webex Calling or Webex CC, we would fine-tune it using a dataset comprising Webex question-answer pairs. This process enables the model to recalibrate its internal parameters and representations to align with the intended task, enhancing its capacity to address domain-specific challenges effectively.</p> <p>However, fine-tuning LLMs conventionally can be resource-intensive and costly. It involves adjusting  the parameters in the pretrained LLM models, which can number in the billions, necessitating significant computational power and time. Consequently, it's crucial to explore more efficient and cost-effective methods for fine-tuning, such as Low-Rank Adaptation (LoRA).</p>"},{"location":"Task7a/#a-reminder-on-instruction-and-conversational-finetuning","title":"A Reminder On Instruction and Conversational Finetuning","text":"<p>In Conversational fine tuning the model engages in a dialogue with the user, maintaining context over multiple turns.The interaction mimics a natural conversation, with the model responding in a way that feels like a human interlocutor.</p> <p>Instruction fine-tuning is a specific type of fine-tuning that grants precise control over a model's behavior. The objective is to train a Language Model (LLM) to interpret prompts as instructions rather than simply treating them as text to continue generating. </p>"},{"location":"Task7a/#introduction-to-efficient-finetuning-with-parameter-efficient-fine-tuning-peft","title":"Introduction to Efficient Finetuning with Parameter-Efficient Fine-tuning (PEFT)","text":"<p>Parameter-Efficient Fine-tuning (PEFT) approaches address the need for computational and storage efficiency in fine-tuning LLMs. Hugging Face developed the PEFT library specifically for this purpose. PEFT leverages architectures that only fine-tune a small number of additional model parameters while freezing most parameters of the pretrained LLMs, significantly reducing computational and storage costs.</p> <p>PEFT methods offer benefits beyond just efficiency. These methods have been proven to outperform standard fine-tuning methods, particularly in low-data situations, and provide improved generalization for out-of-domain scenarios. Furthermore, they contribute to the portability of models by generating tiny model checkpoints that require substantially less storage space compared to extensive full fine-tuning checkpoints.</p> <p>The PEFT library supports popular methods such as Low-Rank Adaptation (LoRA) and Prompt Tuning. </p>"},{"location":"Task7a/#a-reminder-of-the-techniques-for-finetuning-llms","title":"A Reminder of the Techniques For Finetuning LLMs","text":"<p>There are several techniques to make the finetuning process more efficient and effective:</p> <ul> <li> <p>Full Finetuning: This method involves adjusting all the parameters in the pretrained LLM models to adapt to a specific task. While effective, it is resource-intensive and requires extensive computational power, therefore it\u2019s rarely used. Not in our Scope</p> </li> <li> <p>Low-Rank Adaptation (LoRA): LoRA is a technique that aims to adapt LLMs to specific tasks and datasets while simultaneously reducing computational resources and costs. By applying low-rank approximations to the downstream layers of LLMs, LoRA significantly reduces the number of parameters to be trained, thereby lowering the GPU memory requirements and training costs. We\u2019ll also see QLoRA, a variant of LoRA that is more optimized and leverages quantization.</p> </li> </ul> <p>With a focus on the number of parameters involved in finetuning, there are multiple methods, such as:</p> <ul> <li> <p>Supervised Finetuning (SFT): SFT involves doing standard supervised finetuning with a pretrained LLM on a small amount of demonstration data. This method is less resource-intensive than full finetuning but still requires significant computational power. Scope of this lab</p> </li> <li> <p>Reinforcement Learning from Human Feedback (RLHF): RLHF is a training methodology where models are trained to follow human feedback over multiple iterations. This method can be more effective than SFT, as it allows for continuous improvement based on human feedback. We\u2019ll also see some alternatives to RLHF, such as Direct Preference Optimization (DPO), and Reinforcement Learning from AI Feedback (RLAIF).Not in our Scope</p> </li> </ul>"},{"location":"Task7a/#conclusion","title":"Conclusion","text":"<p>In this lesson, we've learned that while pretraining equips LLMs with a broad understanding of language, fine-tuning is necessary to specialize these models for complex tasks. We've looked into various fine-tuning techniques, including Full Finetuning, Low-Rank Adaptation (LoRA), Supervised Finetuning (SFT), and Reinforcement Learning from Human Feedback (RLHF). </p>"},{"location":"Task8/","title":"Deep Dive into LoRA and SFT","text":""},{"location":"Task8/#introduction","title":"Introduction","text":"<p>In this lesson, we will dive deeper into the mechanics of LoRA, a powerful method for optimizing the fine-tuning process of Large Language Models, its practical uses in various fine-tuning tasks, and the open-source resources that simplify its implementation. We will also introduce QLoRA, a highly efficient version of LoRA. By the end of this lesson, you will have an in-depth understanding of how LoRA and QLoRA can enhance the efficiency and accessibility of fine-tuning LLMs.</p>"},{"location":"Task8/#the-functioning-of-lora-in-fine-tuning-llms","title":"The Functioning of LoRA in Fine-tuning LLMs","text":"<p>LoRA, or Low-Rank Adaptation, is a method developed by Microsoft researchers to optimize the fine-tuning of Large Language Models. This technique tackles the issues related to the fine-tuning process, such as extensive memory demands and computational inefficiency. LoRA introduces a compact set of parameters, referred to as low-rank matrices, to store the necessary changes in the model instead of altering all parameters.</p> <p>Here are the key features of how LoRA operates:</p> <ul> <li>Maintaining Pretrained Weights: LoRA adopts a unique strategy by preserving the pretrained weights of the model. This approach reduces the risk of catastrophic forgetting, ensuring the model maintains the valuable knowledge it gained during pretraining.</li> <li>Efficient Rank-Decomposition: LoRA incorporates rank-decomposition weight matrices, known as update matrices, to the existing weights. These update matrices have significantly fewer parameters than the original model, making them highly memory-efficient. By training only these newly added weights, LoRA achieves a faster training process with reduced memory demands. These LoRA matrices are typically integrated into the attention layers of the original model.</li> </ul> <p>By using the low-rank decomposition approach, the memory demands for training large language models are significantly reduced. This allows running fine-tuning tasks on consumer-grade GPUs, making the benefits of LoRA available to a broader range of researchers and developers.</p>"},{"location":"Task8/#a-reminder-on-instruction-and-conversational-finetuning","title":"A Reminder On Instruction and Conversational Finetuning","text":"<p>In Conversational fine tuning the model engages in a dialogue with the user, maintaining context over multiple turns.The interaction mimics a natural conversation, with the model responding in a way that feels like a human interlocutor.</p> <p>Instruction fine-tuning is a specific type of fine-tuning that grants precise control over a model's behavior. The objective is to train a Language Model (LLM) to interpret prompts as instructions rather than simply treating them as text to continue generating.</p>"},{"location":"Task8/#introduction-to-efficient-finetuning-with-parameter-efficient-fine-tuning-peft","title":"Introduction to Efficient Finetuning with Parameter-Efficient Fine-tuning (PEFT)","text":"<p>Parameter-Efficient Fine-tuning (PEFT) approaches address the need for computational and storage efficiency in fine-tuning LLMs. Hugging Face developed the PEFT library specifically for this purpose. PEFT leverages architectures that only fine-tune a small number of additional model parameters while freezing most parameters of the pretrained LLMs, significantly reducing computational and storage costs.</p> <p>PEFT methods offer benefits beyond just efficiency. These methods have been proven to outperform standard fine-tuning methods, particularly in low-data situations, and provide improved generalization for out-of-domain scenarios. Furthermore, they contribute to the portability of models by generating tiny model checkpoints that require substantially less storage space compared to extensive full fine-tuning checkpoints.</p> <p>The PEFT library supports popular methods such as Low-Rank Adaptation (LoRA) and Prompt Tuning.</p>"},{"location":"Task8/#a-reminder-of-the-techniques-for-finetuning-llms","title":"A Reminder of the Techniques For Finetuning LLMs","text":"<p>There are several techniques to make the finetuning process more efficient and effective:</p> <ul> <li>Full Finetuning: This method involves adjusting all the parameters in the pretrained LLM models to adapt to a specific task. While effective, it is resource-intensive and requires extensive computational power, therefore it\u2019s rarely used. Not in our Scope</li> <li>Low-Rank Adaptation (LoRA): LoRA is a technique that aims to adapt LLMs to specific tasks and datasets while simultaneously reducing computational resources and costs. By applying low-rank approximations to the downstream layers of LLMs, LoRA significantly reduces the number of parameters to be trained, thereby lowering the GPU memory requirements and training costs. We\u2019ll also see QLoRA, a variant of LoRA that is more optimized and leverages quantization.</li> </ul> <p>With a focus on the number of parameters involved in finetuning, there are multiple methods, such as:</p> <ul> <li>Supervised Finetuning (SFT): SFT involves doing standard supervised finetuning with a pretrained LLM on a small amount of demonstration data. This method is less resource-intensive than full finetuning but still requires significant computational power. Scope of this lab</li> <li>Reinforcement Learning from Human Feedback (RLHF): RLHF is a training methodology where models are trained to follow human feedback over multiple iterations. This method can be more effective than SFT, as it allows for continuous improvement based on human feedback. We\u2019ll also see some alternatives to RLHF, such as Direct Preference Optimization (DPO), and Reinforcement Learning from AI Feedback (RLAIF).Not in our Scope</li> </ul>"},{"location":"Task8/#conclusion","title":"Conclusion","text":"<p>In this lesson, we've learned that while pretraining equips LLMs with a broad understanding of language, fine-tuning is necessary to specialize these models for complex tasks. We've looked into various fine-tuning techniques, including Full Finetuning, Low-Rank Adaptation (LoRA), Supervised Finetuning (SFT), and Reinforcement Learning from Human Feedback (RLHF).</p>"},{"location":"conclusion/","title":"Conclusion","text":"<p>Thank you for taking the time to learn about the ThousandEyes Endpoint Agent. Please  provide feedback as I'm always looking at ways I can improve this  content. If you have ideas where you think the ThosuandEyes Endpoint Agent could be improved please submit them as well so we can better help you solve your end users issues and provide you more time to do the things you enjoy.</p>"},{"location":"overview/","title":"Overview - Enabling Hybrid Work with ThousandEyes","text":"<p>Work from the Office. Work from Home. Hybrid work has opened up the possibility of work from wherever the internet is available. At the same time, it brings new challenges to the IT team managing the end host's security, application performance, local network connection, VPN, proxy, and user's total digital experience. ThousandEyes provides this visibility with Endpoint Agents monitoring. In the lab, you will go through guided steps to start monitoring Endpoint hosts.</p>"},{"location":"overview/#upon-completion-of-this-lab-you-will-be-able-to","title":"Upon completion of this lab you will be able to","text":"<ul> <li>Deploy ThousandEyes Endpoint Agents</li> <li>Start monitoring SaaS services</li> <li>Learn how to enable Automated Session Testing (AST)</li> <li>Configure browser session monitoring</li> <li>Use the collected data for live troubleshooting</li> <li>Create a snapshot to share with others for colloboration</li> <li>Create/Duplicate a Hybrid/Remote Worker Dashboard</li> </ul>"},{"location":"overview/#prerequisites","title":"Prerequisites","text":"<ul> <li>Understanding of ThousandEyes is helpful, but not required.</li> </ul>"},{"location":"overview/#disclaimer","title":"Disclaimer","text":"<p>Although the lab design and configuration examples could be used as a reference, this is a sample deployment, thus not all recommended features are used, or enabled optimally. For the design related questions please contact your representative at Cisco, or a Cisco partner or TME's.</p>"},{"location":"overview/#lab-overview-enabling-hybrid-work-with-thousandeyes","title":"Lab Overview - Enabling Hybrid Work with ThousandEyes","text":"<ul> <li>Lab Login and Setup</li> <li>Quick ThousandEyes Overview</li> <li>Configure and Access the Lab Systems</li> <li>Deploy a ThousandEyes EPA</li> <li>Setup and Configure AST and EPA Monitoring</li> <li>Review Agent Views and Analyze Test Data</li> <li>Review Home Worker Dashboard and Alerting</li> <li>Wrap up and End the Lab</li> </ul> <p>Let's get started! Click on Task 1 - Lab Login and Setup.</p>"}]}