
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Webex and GenAI">
      
      
        <meta name="author" content="Omer Ilyas">
      
      
      
        <link rel="prev" href="../overview/">
      
      
        <link rel="next" href="../Task2/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.29">
    
    
      
        <title>Task 1 - Lab Setup - Google Colab, Hugging Face, Langchain, Ollama - Collaboration - Technical Marketing Engineering</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.76a95c52.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pre-requisites-and-setup" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Collaboration - Technical Marketing Engineering" class="md-header__button md-logo" aria-label="Collaboration - Technical Marketing Engineering" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Collaboration - Technical Marketing Engineering
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Task 1  - Lab Setup - Google Colab, Hugging Face, Langchain, Ollama
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../overview/" class="md-tabs__link">
          
  
    
  
  Lab

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Collaboration - Technical Marketing Engineering" class="md-nav__button md-logo" aria-label="Collaboration - Technical Marketing Engineering" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Collaboration - Technical Marketing Engineering
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Lab
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Lab
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Task 1  - Lab Setup - Google Colab, Hugging Face, Langchain, Ollama
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Task 1  - Lab Setup - Google Colab, Hugging Face, Langchain, Ollama
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#google-colab-accessing-google-colab-and-creating-account" class="md-nav__link">
    <span class="md-ellipsis">
      Google Colab - Accessing Google Colab and creating account
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#getting-started-with-google-colab" class="md-nav__link">
    <span class="md-ellipsis">
      Getting Started With Google Colab
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notes-on-gpu-and-tpu-access" class="md-nav__link">
    <span class="md-ellipsis">
      Notes: On GPU and TPU Access:
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-huggingface-hub-to-share-our-datasets" class="md-nav__link">
    <span class="md-ellipsis">
      Using Huggingface Hub to share our Datasets
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#accessing-hugging-face-hub-and-creating-account" class="md-nav__link">
    <span class="md-ellipsis">
      Accessing Hugging Face Hub and creating account
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Accessing Hugging Face Hub and creating account">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#signing-up" class="md-nav__link">
    <span class="md-ellipsis">
      Signing up
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hugging-face-api-keys" class="md-nav__link">
    <span class="md-ellipsis">
      Hugging Face API Keys
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#accessing-hugging-face-api-in-google-colab" class="md-nav__link">
    <span class="md-ellipsis">
      Accessing Hugging Face API in Google Colab
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Accessing Hugging Face API in Google Colab">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#incorporating-secrets-into-your-code-we-will-use-it-later-in-our-lab" class="md-nav__link">
    <span class="md-ellipsis">
      Incorporating Secrets into Your Code - We will use it later in our lab
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-secrets-as-environment-variables-optional-step-we-will-use-it-later-in-our-lab" class="md-nav__link">
    <span class="md-ellipsis">
      Using Secrets as Environment Variables - Optional Step , we will use it later in our lab
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#getting-started-with-langchain" class="md-nav__link">
    <span class="md-ellipsis">
      Getting Started with Langchain
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Getting Started with Langchain">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#setup-langchain-envoirnment-sample-code" class="md-nav__link">
    <span class="md-ellipsis">
      Setup Langchain envoirnment - Sample Code
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optional-step-running-ollama-locally" class="md-nav__link">
    <span class="md-ellipsis">
      Optional Step - Running Ollama locally
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Optional Step - Running Ollama locally">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#prerequisites-for-installing-ollama-locally" class="md-nav__link">
    <span class="md-ellipsis">
      Prerequisites for Installing Ollama Locally
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#installing-ollama-locally" class="md-nav__link">
    <span class="md-ellipsis">
      Installing Ollama Locally
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#web-interface" class="md-nav__link">
    <span class="md-ellipsis">
      Web Interface
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 2  - AI/ML Revolution Unveiled
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 3  - Tokenization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 4  - Embeddings and Vector Database
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 5  - Context Windows and Retrieval Augmented Generation (RAG)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 6  - Multimodal RAG
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 6a  - GenAI Frameworks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 7  - Understanding Fine-Tuning for Large Language Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 8  - Fine Tuning - Deep Dive into Quantization , LoRA and SFT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task8a/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 8a - Configuring and Fine Tuning - Using llama2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task8b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 8b - Configuring and Fine Tuning - Using llama3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task8c/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 8c - Configuring and Fine Tuning - Using ChatGPT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task8d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 8d - Model Merging
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task20/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 9 - Log out and Shutdown the Lab
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../conclusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Conclusion
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="pre-requisites-and-setup">Pre-Requisites and Setup</h1>
<h2 id="google-colab-accessing-google-colab-and-creating-account">Google Colab - Accessing Google Colab and creating account</h2>
<p>Google Colab is a free, cloud-based platform that provides a convenient environment for running notebooks. If you want to create a machine learning model but don't have a computer that can handle the workload, Google Colab is the platform for you. In our lab, we will be using Google Colab to test and run our code. However, if you have your own Python environment and prefer to run the code on your local machine, please feel free to do so.</p>
<p>Here are some reasons why using Google Colab can be beneficial for this lab:</p>
<ul>
<li>Free Access to GPUs and TPUs: Google Colab offers free access to powerful GPUs and TPUs, which can significantly accelerate the training and fine-tuning of machine learning models.</li>
<li>No Setup Required: With Colab, there is no need to set up your local environment. Everything runs in the cloud, which saves time and avoids configuration issues.</li>
<li>Easy Collaboration: Colab notebooks can be easily shared and collaborated on with team members, making it an ideal tool for collaborative projects.</li>
<li>Integration with Google Drive: Colab integrates seamlessly with Google Drive, allowing you to save and manage your work conveniently.</li>
<li>Pre-installed Libraries: Many popular machine learning libraries, including TensorFlow and PyTorch, come pre-installed in Colab, making it easy to start working on your projects immediately.</li>
</ul>
<h2 id="getting-started-with-google-colab">Getting Started With Google Colab</h2>
<p>To start working with Google Collaboratory Notebook you first need to log in to your Google account, then go to this link <a href="https://colab.research.google.com">Google Colab</a></p>
<ul>
<li>Create a new Jupyter Notebook  </li>
</ul>
<p><img alt="Colab_SignUP" src="../assets/task1/Colab_signup.png" /></p>
<ul>
<li>On creating a new notebook, it will create a Jupyter notebook with Untitled0.ipynb and save it to your google drive in a folder named Colab Notebooks. Now as it is essentially a Jupyter Notebook, all commands of Jupyter Notebooks will work here. </li>
</ul>
<p><img alt="Colab_Untitled" src="../assets/task1/Colab_unt.png" /></p>
<ul>
<li>
<p>There might be times when we need to fine-tune models or perform specific tasks that require changing the runtime environment in Colab. Google Colab offers different runtime environments that can be selected based on your requirements:</p>
</li>
<li>
<p><strong>Python Versions:</strong> You can select between different versions of Python (e.g., Python 2 or Python 3)depending on the compatibility of the code and libraries. We will be using Python3 for our lab.</p>
</li>
<li>
<p><strong>Hardware Accelerators:</strong> Colab provides access to hardware accelerators, which can be particularly useful for intensive computations. You can choose between:</p>
</li>
</ul>
<div class="highlight"><pre><span></span><code>None: No hardware acceleration, suitable for basic tasks.

GPU: Accelerate your computations with a Graphics Processing Unit.

TPU: Use a Tensor Processing Unit for even faster performance, especially beneficial for deep learning tasks.
</code></pre></div>
<ul>
<li>
<p>Click the arrow next to “Connect” to open the dropdown</p>
</li>
<li>
<p>Change Runtime Environment: Click the “Runtime” dropdown menu at the top of the Colab interface.</p>
</li>
</ul>
<p><img alt="Colab_runtime" src="../assets/task1/Colab_chg.png" /></p>
<ul>
<li>
<p>Select “Change runtime type”: This will open a dialog box where you can configure the runtime environment.</p>
</li>
<li>
<p>Select Python Version: Choose Python 3 from the “Runtime type” dropdown menu.</p>
</li>
<li>
<p>Select Hardware Accelerator: From the “Hardware accelerator” dropdown menu, choose  GPU, or TPU . </p>
<ul>
<li>
<p>GPU (Graphics Processing Unit): Best for tasks requiring extensive parallel processing, such as training neural networks (the main focus in our lab guide).</p>
</li>
<li>
<p>TPU (Tensor Processing Unit): Optimized for deep learning tasks</p>
</li>
</ul>
</li>
</ul>
<p><img alt="Colab_savruntime" src="../assets/task1/savColab_chg.png" /></p>
<ul>
<li>
<p>Save Settings: Click “Save” to apply the changes.</p>
</li>
<li>
<p><strong>New Cell:</strong> Whenever you want to copy the code in Google Colab and run it, be sure to click on + Code to add a new code cell.</p>
</li>
</ul>
<p><img alt="Colab_newcell" src="../assets/task8/newcell.png" /></p>
<ul>
<li><strong>Execute Code:</strong> Click the play button to the left of the code, or use the keyboard shortcut "Command/Ctrl+Enter" while the cell is selected.</li>
</ul>
<p><img alt="Colab_newcell_execute" src="../assets/task8/exec.png" /></p>
<hr />
<h2 id="notes-on-gpu-and-tpu-access">Notes: On GPU and TPU Access:</h2>
<p>While Google Colab offers free access to GPUs and TPUs, there are limitations. For more consistent access to high-performance GPUs and TPUs, you might need to subscribe to <a href="https://colab.research.google.com/signup">Colab Pro or Colab Pro+ accounts</a>. These paid plans provide priority access to better hardware, longer runtimes, and more memory.</p>
<hr />
<h2 id="using-huggingface-hub-to-share-our-datasets">Using Huggingface Hub to share our Datasets</h2>
<p>In this lab, we will be utilizing the <a href="https://huggingface.co/">Hugging Face Hub</a> to load our custom datasets. Hugging Face provides an extensive repository of datasets that can be easily integrated into your machine learning workflows. For the purposes of this lab, we will demonstrate how to access/upload and use our custom datasets effectively.</p>
<p>However, when fine-tuning models in your own work environment, especially if you are using private data, there are important considerations to keep in mind:</p>
<ul>
<li><strong>Private Datastores:</strong> If you are working with proprietary or sensitive data, it is crucial to use your organization's secure datastores. Ensure that all data handling complies with your organization's data privacy policies and regulations.</li>
<li><strong>Hugging Face Datasets:</strong> If you prefer to use Hugging Face for dataset storage and management, make sure to mark your datasets as private. This setting ensures that your data cannot be accessed by anyone outside your organization, maintaining the confidentiality and integrity of your information. Please refer to Huggingface documentation for more info.</li>
</ul>
<p><strong>Few more Condsideration</strong></p>
<ul>
<li><strong>Upload Dataset:</strong> When uploading your dataset to Hugging Face, choose the appropriate privacy settings. You can set your dataset to private during the upload process.</li>
<li><strong>Check Permissions:</strong> Regularly review and manage the permissions of your datasets to ensure they remain private and secure.</li>
<li><strong>Collaborator Access:</strong> If you need to share the dataset with specific team members, use the Hugging Face interface to grant access to trusted collaborators only.</li>
</ul>
<p>By following these guidelines, you can ensure that your data remains secure while leveraging the powerful tools and resources provided by Hugging Face. This approach not only enhances your workflow efficiency but also upholds the best practices in data security and privacy.</p>
<h2 id="accessing-hugging-face-hub-and-creating-account">Accessing Hugging Face Hub and creating account</h2>
<p>Hugging Face can be accessed by browsing to <a href="https://huggingface.co/">huggingface</a></p>
<p><img alt="HLF" src="../assets/task8a/HF.png" /></p>
<h3 id="signing-up">Signing up</h3>
<ul>
<li>Browse to Hugging Face home page and click on Sign up. Follow the instructions as per below images</li>
</ul>
<p><img alt="SignUP" src="../assets/task8a/signup.png" /></p>
<p><img alt="Prof" src="../assets/task8a/HFProfile.png" /></p>
<ul>
<li>Please check your email address for a confirmation link and click to verify your account </li>
</ul>
<p><img alt="Verify" src="../assets/task8a/HFverify.png" /></p>
<ul>
<li>Organization Creation (Optional): While you can upload datasets and fine-tune models directly on Hugging Face without creating an organization, you have the option to create an organization on Hugging Face. This can be particularly useful for team collaboration, as it allows you to upload all your datasets and models in one centralized location.</li>
</ul>
<p><img alt="Optional" src="../assets/task8a/HFOptional.png" /></p>
<ul>
<li>Access Your Models and Datasets: The same can be accessed by clicking your profile picture on the top right corner of the Hugging Face website. This will take you to your personal dashboard where you can view and manage your models and datasets.</li>
</ul>
<p><img alt="Mo_DS1" src="../assets/task8a/HFNoMD1.png" /></p>
<ul>
<li>At this stage, you will see no models or datasets created under your account.</li>
</ul>
<p><img alt="Mo_DS" src="../assets/task8a/HFNoMD.png" /></p>
<h3 id="hugging-face-api-keys">Hugging Face API Keys</h3>
<p><strong>Create an API Key:</strong> As we will be uploading our datasets to the Hugging Face Hub, we need to create an API key for our account. This API key will be used to authenticate and interact with the Hugging Face services programmatically.</p>
<p>you can browse to <a href="https://huggingface.co/settings/token">huggingface API Key</a></p>
<p>or </p>
<p>Click on your profile picture &gt; Settings &gt; Access Tokens</p>
<p><img alt="HF_API" src="../assets/task8a/HF_APi.png" /></p>
<p><img alt="HF_WT" src="../assets/task8a/writetoken.png" /></p>
<p>Under the "Access Tokens" section, click on "Create new token." You will see options to select the token type and provide a token name. For example, you might name your token "Webexone" and select the approperiate permissions.  </p>
<ul>
<li>
<p>Fine-grained: tokens with this role can be used to provide fine-grained access to specific resources, such as a specific model or models in a specific organization. This type of token is useful in production environments, as you can use your own token without sharing access to all your resources.</p>
</li>
<li>
<p>Read: tokens with this role can only be used to provide read access to repositories you could read. That includes public and private repositories that you, or an organization you’re a member of, own. Use this role if you only need to read content from the Hugging Face Hub 
(e.g. when downloading private models or doing inference).</p>
</li>
<li>
<p>Write: tokens with this role additionally grant write access to the repositories you have write access to. Use this token if you need to create or push content to a repository (e.g., when training a model or modifying a model card).</p>
</li>
</ul>
<p>As we have a lab envoirnment we will be using the "Write" permission. This token will have read and write access to all your resources and can make calls to inference API on your behalf, as shown in the image below.</p>
<p><img alt="HF_CT" src="../assets/task8a/createtoken.png" /></p>
<p><strong>Save and Secure the Token:</strong> Once the token is generated, save it securely. This token will be required for accessing and managing your datasets via the API. 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</p>
<p><img alt="HF_GT" src="../assets/task8a/gentoken.png" /></p>
<h2 id="accessing-hugging-face-api-in-google-colab">Accessing Hugging Face API in Google Colab</h2>
<ul>
<li>Open the Google Colab notebook and navigate to the new “Secrets” section in the sidebar.</li>
</ul>
<p><img alt="HF_GT_sec" src="../assets/task8a/gensec.png" /></p>
<ul>
<li>
<p>Click on “Add a new secret.” Enter the name example: HF_TOKEN and value of the secret. Note: The name is permanent once set. </p>
</li>
<li>
<p>The list of secrets is global across all your notebooks.</p>
</li>
<li>
<p>Use the “Notebook access” toggle to grant or revoke access to a secret for each notebook.</p>
</li>
</ul>
<p><img alt="HF_GT_sec_created" src="../assets/task8a/addsec.png" /></p>
<p><span style="color: RED;"> Optional Steps below </span> </p>
<h3 id="incorporating-secrets-into-your-code-we-will-use-it-later-in-our-lab">Incorporating Secrets into Your Code - We will use it later in our lab</h3>
<ul>
<li>To use a secret in your notebook, use the following code snippet</li>
</ul>
<div class="highlight"><pre><span></span><code>from google.colab import userdata
my_secret_key = userdata.get(&#39;HF_TOKEN&#39;)
</code></pre></div>
<ul>
<li>Replace <name_of_your_secret> with your secret's name.</li>
</ul>
<h3 id="using-secrets-as-environment-variables-optional-step-we-will-use-it-later-in-our-lab">Using Secrets as Environment Variables -  Optional Step , we will use it later in our lab</h3>
<ul>
<li>For Python modules requiring API keys as environment variables, use the below snippet:</li>
</ul>
<div class="highlight"><pre><span></span><code># Import Colab Secrets userdata module

from google.colab import userdata
import os

# Set other API keys similarly
os.environ[&quot;HF_TOKEN&quot;] = userdata.get(&#39;HF_TOKEN&#39;)
</code></pre></div>
<h2 id="getting-started-with-langchain">Getting Started with Langchain</h2>
<p>Let's explore how to create a LangChain account and obtain the API key, which we will use later in our lab. </p>
<p>To start building applications with LangChain, you'll need an API key. This key allows your applications to securely connect with LangChain's services, ensuring proper authentication and usage tracking.</p>
<p>Lets start by visiting the official <a href="https://smith.langchain.com/settings">LangChain website</a> and create an account. You'll need to enter some basic information about yourself or your organization. In this example, I will be using my Google account to sign up.</p>
<p><img alt="ls1" src="../assets/task1/ls1.png" /></p>
<p>To create an API key head to the Settings page. Then click Create API Key.</p>
<p><img alt="ls2" src="../assets/task1/ls2.png" /></p>
<h3 id="setup-langchain-envoirnment-sample-code">Setup Langchain envoirnment - Sample Code</h3>
<ul>
<li>In the code snippet below, we'll configure our environment to enable tracing of AI calls and set up the API key for interacting with LangChain's services, as we will be using these in the upcoming section.</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><th colspan="2" class="filename"><span class="filename">Sample Code</span></th></tr><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">langchain</span><span class="o">-</span><span class="n">community</span>
<span class="n">export</span> <span class="n">LANGCHAIN_TRACING_V2</span><span class="o">=</span><span class="n">true</span>
<span class="n">export</span> <span class="n">LANGCHAIN_API_KEY</span><span class="o">=&lt;</span><span class="n">your</span><span class="o">-</span><span class="n">api</span><span class="o">-</span><span class="n">key</span><span class="o">&gt;</span>
</code></pre></div></td></tr></table></div>
<h2 id="optional-step-running-ollama-locally">Optional Step - Running Ollama locally</h2>
<p>Have you ever used GPT and amazed at its ability to understand and respond to your queries? But did you know that you can also harness the power of open-source models using Ollama? With Ollama, you can download and interact with these models directly, getting responses that are tailored to your needs.</p>
<p>In this lab, I'll show you how to install Ollama locally on your machine and start using it to generate responses. You'll learn how to download and load open-source models, and then use Ollama's intuitive interface to interact with them. More info for <a href="https://ollama.com/">Ollama can be found here</a></p>
<p><span style="color: RED;"> Note: The steps below are provided for informational purposes. If you are using the demo laptop in this lab, feel free to follow these instructions. However, if you are using your personal or work machine, please ensure that you have the necessary privileges and authorization from your organization's administrator to install Ollama locally.</span> </p>
<h3 id="prerequisites-for-installing-ollama-locally">Prerequisites for Installing Ollama Locally</h3>
<ul>
<li>Ensure that Docker is installed and running on your machine. It is available for various operating systems, including macOS, Windows, and Linux. You can download it from the <a href="https://www.docker.com/">official Docker website</a> and follow the installation instructions for your specific OS.</li>
</ul>
<h3 id="installing-ollama-locally">Installing Ollama Locally</h3>
<p><span style="color: RED;"> Note: Since we're using a Mac, I'll demonstrate how you can install it on macOS. </span></p>
<ul>
<li>
<p>First, you need to install Ollama. You can download it <a href="ollama.com">here</a> and clicking on the download button. Follow the instructions.</p>
</li>
<li>
<p>Once installed, Ollama functions as a command-line application, allowing you to interact with it directly through the terminal. To get started, open the terminal and enter the following command:</p>
</li>
</ul>
<div class="highlight"><span class="filename">SHELL</span><pre><span></span><code><span class="n">ollama</span>
</code></pre></div>
<p>It will output the below commands</p>
<p><img alt="Ollama" src="../assets/task1/olama.png" /></p>
<ul>
<li>Ollama supports a list of models available <a href="ollama.com/library">here</a>. Below are some example models that can be downloaded:</li>
</ul>
<p><img alt="Ollama1" src="../assets/task1/olama1.png" /></p>
<ul>
<li>To download a model, for example, gemma:2b, which is a lighter model, we can simply type:</li>
</ul>
<div class="highlight"><span class="filename">SHELL</span><pre><span></span><code><span class="n">ollama</span> <span class="n">pull</span> <span class="n">gemma</span><span class="p">:</span><span class="mi">2</span><span class="n">b</span>
</code></pre></div>
<p><img alt="pull" src="../assets/task1/pull.png" /></p>
<ul>
<li>After pulling the model we can interact with it in the terminal by typing:</li>
</ul>
<div class="highlight"><span class="filename">SHELL</span><pre><span></span><code><span class="n">ollama</span> <span class="n">run</span> <span class="n">gemma</span><span class="p">:</span><span class="mi">2</span><span class="n">b</span>
</code></pre></div>
<p><img alt="pull1" src="../assets/task1/pull1.png" /></p>
<ul>
<li>We can now ask our question directly in the terminal</li>
</ul>
<p><img alt="pull2" src="../assets/task1/pull2.png" /></p>
<ul>
<li>To remove model you can type</li>
</ul>
<div class="highlight"><span class="filename">SHELL</span><pre><span></span><code><span class="n">ollama</span> <span class="n">rm</span> <span class="n">gemma</span><span class="p">:</span><span class="mi">2</span><span class="n">b</span>
</code></pre></div>
<ul>
<li>To see the models installed, just enter </li>
</ul>
<div class="highlight"><span class="filename">SHELL</span><pre><span></span><code><span class="n">ollama</span> <span class="nb">list</span>
</code></pre></div>
<h3 id="web-interface">Web Interface</h3>
<p>Once we've installed Ollama, we can interact with it directly through the terminal, as demonstrated earlier. But what if you prefer a web interface? There are several open-source tools available, but I'll show you how to use <a href="https://github.com/open-webui/open-webui">Open WebUI</a>, which was previously known as Ollama WebUI.</p>
<p>Open WebUI is a versatile, feature-rich, and user-friendly web interface that you can host yourself and use entirely offline. It offers a ChatGPT-style interface, allowing you to interact with language models running on locally (Ollama). This tool is especially useful for those who want to run language models locally or in a self-hosted environment, ensuring both data privacy and control.</p>
<ul>
<li>After installing Ollama, simply run the following Docker command to set up the interface</li>
</ul>
<div class="highlight"><span class="filename">SHELL</span><pre><span></span><code><span class="n">docker</span> <span class="n">run</span> <span class="o">-</span><span class="n">d</span> <span class="o">-</span><span class="n">p</span> <span class="mi">3000</span><span class="p">:</span><span class="mi">8080</span> <span class="o">--</span><span class="n">add</span><span class="o">-</span><span class="n">host</span><span class="o">=</span><span class="n">host</span><span class="o">.</span><span class="n">docker</span><span class="o">.</span><span class="n">internal</span><span class="p">:</span><span class="n">host</span><span class="o">-</span><span class="n">gateway</span> <span class="o">-</span><span class="n">v</span> <span class="nb">open</span><span class="o">-</span><span class="n">webui</span><span class="p">:</span><span class="o">/</span><span class="n">app</span><span class="o">/</span><span class="n">backend</span><span class="o">/</span><span class="n">data</span> <span class="o">--</span><span class="n">name</span> <span class="nb">open</span><span class="o">-</span><span class="n">webui</span> <span class="o">--</span><span class="n">restart</span> <span class="n">always</span> <span class="n">ghcr</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="nb">open</span><span class="o">-</span><span class="n">webui</span><span class="o">/</span><span class="nb">open</span><span class="o">-</span><span class="n">webui</span><span class="p">:</span><span class="n">main</span>
</code></pre></div>
<p><img alt="pull3" src="../assets/task1/pull3.png" /></p>
<ul>
<li>Once installed, you can access Open WebUI at http://localhost:3000. </li>
</ul>
<p><span style="color: RED;">Note: Before accessing the web interface, you will be prompted to create an account. Please follow the instructions.</span></p>
<ul>
<li>In the dropdown menu, you'll see the model you previously installed via the terminal (gemma:2b).</li>
</ul>
<p><img alt="pull4" src="../assets/task1/pull4.png" /></p>
<ul>
<li>You can now interact with the model via WebUi</li>
</ul>
<p><img alt="pull5" src="../assets/task1/pull5.png" /></p>
<ul>
<li>You no longer need to use the terminal to download a model. Simply navigate to the “Settings --&gt; Models” section in the WebUI, and select the specific model you want to download.</li>
</ul>
<p><img alt="pull6" src="../assets/task1/pull6.png" /></p>
<ul>
<li>After installing, all the installed models will be displayed in the UI.</li>
</ul>
<p><img alt="pull7" src="../assets/task1/pull7.png" /></p>
<p><span style="color: RED;">Note: Using LangChain with Ollama allows you to leverage Ollama's capabilities within the LangChain ecosystem. You can find <a href="https://python.langchain.com/v0.1/docs/get_started/quickstart/">more information here</a> </span></p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Omer Ilyas - Technical Marketing Engineer - oilyas@cisco.com
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/omerilyas4ccie/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.sections", "toc.integrate", "navigation.tabs.sticky", "navigation.indexes", "navigation.instant", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
    
  </body>
</html>