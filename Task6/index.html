
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Webex and GenAI">
      
      
        <meta name="author" content="Omer Ilyas">
      
      
      
        <link rel="prev" href="../Task5/">
      
      
        <link rel="next" href="../Task9/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.29">
    
    
      
        <title>Task 6 - Multimodal RAG - Collaboration - Technical Marketing Engineering</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.76a95c52.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#multimodal-rag" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Collaboration - Technical Marketing Engineering" class="md-header__button md-logo" aria-label="Collaboration - Technical Marketing Engineering" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Collaboration - Technical Marketing Engineering
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Task 6  - Multimodal RAG
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../overview/" class="md-tabs__link">
          
  
    
  
  Lab

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Collaboration - Technical Marketing Engineering" class="md-nav__button md-logo" aria-label="Collaboration - Technical Marketing Engineering" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Collaboration - Technical Marketing Engineering
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Lab
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Lab
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 1  - Lab Setup - Google Colab, Hugging Face, Langchain, Ollama
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 2  - AI/ML Revolution Unveiled
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 3  - Tokenization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 4  - Embeddings and Vector Database
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 5  - Context Windows and Retrieval Augmented Generation (RAG)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Task 6  - Multimodal RAG
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Task 6  - Multimodal RAG
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#three-different-approaches-for-multimodal-rag" class="md-nav__link">
    <span class="md-ellipsis">
      Three Different approaches for Multimodal RAG
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#contrastive-language-image-pretraining-clip-model" class="md-nav__link">
    <span class="md-ellipsis">
      Contrastive Language-Image Pretraining - CLIP Model
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Contrastive Language-Image Pretraining - CLIP Model">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#zero-shot-learning-zsl" class="md-nav__link">
    <span class="md-ellipsis">
      Zero-Shot Learning (ZSL)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#openclip-model" class="md-nav__link">
    <span class="md-ellipsis">
      OpenCLIP Model
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deploy-multimodal-rag" class="md-nav__link">
    <span class="md-ellipsis">
      Deploy Multimodal RAG
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#task-1-log-into-the-lab-environment" class="md-nav__link">
    <span class="md-ellipsis">
      Task 1: Log into the Lab Environment
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Task 1: Log into the Lab Environment">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#set-openai-token-multimodal" class="md-nav__link">
    <span class="md-ellipsis">
      Set OpenAI token - MultiModal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#update-google-colab-envoirnment-and-install-packages" class="md-nav__link">
    <span class="md-ellipsis">
      Update Google Colab envoirnment and install packages
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pdf-with-table" class="md-nav__link">
    <span class="md-ellipsis">
      PDF with table
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lets-now-create-summary-from-our-data-by-passing-the-info-to-multimodal" class="md-nav__link">
    <span class="md-ellipsis">
      Lets now create summary from our data by passing the info to Multimodal
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lets-now-create-our-multivector-retriever-and-rag-system-incl-storing-summary-embeddings-in-vector-db" class="md-nav__link">
    <span class="md-ellipsis">
      Lets now create our MultiVector Retriever and RAG system - incl storing summary embeddings in Vector DB
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Lets now create our MultiVector Retriever and RAG system - incl storing summary embeddings in Vector DB">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#create-our-multivector-retriever" class="md-nav__link">
    <span class="md-ellipsis">
      Create our MultiVector Retriever
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#create-our-rag-multimodal" class="md-nav__link">
    <span class="md-ellipsis">
      Create our RAG (Multimodal)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#lets-query-our-multimodal-retriever" class="md-nav__link">
    <span class="md-ellipsis">
      Lets Query our Multimodal Retriever
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task9/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 6a  - GenAI Frameworks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 7  - Understanding Fine-Tuning for Large Language Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task8/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 8  - Fine Tuning - Deep Dive into Quantization , LoRA and SFT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task8a/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 8a - Configuring and Fine Tuning - Using llama2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task8b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 8b - Configuring and Fine Tuning - Using llama3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task8c/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 8c - Configuring and Fine Tuning - Using ChatGPT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task8d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 8d - Model Merging
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Task20/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Task 9 - Log out and Shutdown the Lab
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../conclusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Conclusion
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="multimodal-rag">Multimodal RAG</h1>
<p>In the previous section, we explored RAG systems primarily designed for handling text. However, in real-world scenarios, many documents within organizations contain valuable information in the form of images, tables, and other non-text elements. When building a robust RAG system, it's crucial to have the capability to retrieve not just text-based information but also relevant images and other visual data. This multimodal approach significantly enhances the effectiveness of information retrieval. In this section, we will explore methods to retrieve both images and text in response to user queries, enabling a more comprehensive and efficient RAG based system.</p>
<h2 id="three-different-approaches-for-multimodal-rag">Three Different approaches for Multimodal RAG</h2>
<p><img alt="C1" src="../assets/task6/1.png" /></p>
<p><span class="colour" style="color:orange">Embedding for images can be done via CLIP model.</span></p>
<p><img alt="C2" src="../assets/task6/2.png" /></p>
<p><span class="colour" style="color:orange"> We will be using OpTion 2 for our lab </span></p>
<p><img alt="C3" src="../assets/task6/3.png" /></p>
<h2 id="contrastive-language-image-pretraining-clip-model">Contrastive Language-Image Pretraining - CLIP Model</h2>
<p>Unlike other embedding models that focus on single modality (either text or images) the <a href="https://openai.com/index/clip/">CLIP (Contrastive Language-Image Pretraining)</a>, was developed by OpenAI in 2021.</p>
<p><span class="colour" style="color:orange">Note: CLIP models are embedding models, not traditional Large Language Models (LLMs).</span></p>
<p>The primary function of CLIP (Contrastive Language-Image Pretraining) is to create a shared embedding space where both text and images are represented as vectors. The key idea is to learn representations where images and their corresponding text descriptions are close to each other in this embedding space, while unrelated image-text pairs are far apart. This allows CLIP to perform tasks like image classification, zero-shot learning, and text-to-image retrieval based on the semantic similarity between text and images. So in summary CLIP models create a relationship between images and text.</p>
<h3 id="zero-shot-learning-zsl">Zero-Shot Learning (ZSL)</h3>
<p>Zero-Shot Learning (ZSL): This technique enhances the ability of AI systems to classify and recognize objects they have not been explicitly trained on. Instead of relying solely on trained data, ZSL uses auxiliary information to make predictions. For example, in an image classification scenario where a model is trained to recognize dogs and cats, if it encounters an image of a zebra (which the model has never seen before), it can still classify it correctly if it has auxiliary information describing a zebra as an animal with black and white stripes.</p>
<p>Using ZSL, CLIP models can perform tasks they were not specifically trained on, in real-time. Essentially, they have capabilities similar to text-based embedding models. Just as we create chunks of text and use a user query to find similar text chunks, the same concept applies to images using CLIP.</p>
<h2 id="openclip-model">OpenCLIP Model</h2>
<p>It's important to note that the original CLIP model by OpenAI is not publicly available. However, people have taken the concepts from OpenAI's CLIP paper and developed open-source models like OpenCLIP.</p>
<p><span class="colour" style="color:orange"> Note: <a href="https://github.com/mlfoundations/open_clip">OpenCLIP</a> is an open-source implementation and extension of the original CLIP (Contrastive Language-Image Pretraining) model developed by OpenAI.</span></p>
<ul>
<li>
<p><strong>Different types of Multimodal Embeddings and LLM</strong>
<img alt="C4" src="../assets/task6/4.png" /></p>
</li>
<li>
<p><strong>Usecases for Multimodal RAG</strong></p>
</li>
</ul>
<p><img alt="C5" src="../assets/task6/5.png" /></p>
<p>Lets contine and jump to our lab</p>
<h2 id="deploy-multimodal-rag">Deploy Multimodal RAG</h2>
<p>Whenever we develop applications based on Large Language Models (LLMs), handling data is a crucial aspect. As discussed in the previous section (RAG), data injection is the initial step in this process. It's important to note that there are typically three types of data structure.</p>
<p><img alt="C6" src="../assets/task6/6.png" /></p>
<h2 id="task-1-log-into-the-lab-environment">Task 1: Log into the Lab Environment</h2>
<ul>
<li>Open Google Colab and create a new notebook. Click on "File" &gt; "New notebook". Please refer to the <a href="../Task1/">following section</a> to create Google Colab account.</li>
</ul>
<p><img alt="GCOLAB" src="../assets/task3/gcolab.png" /></p>
<ul>
<li>Change Runtime Environment: Click the “Runtime” dropdown menu at the top of the Colab interface.</li>
</ul>
<p><img alt="Colab_runtime" src="../assets/task1/Colab_chg.png" /></p>
<ul>
<li>
<p>Select “Change runtime type”: This will open a dialog box where you can configure the runtime environment.</p>
</li>
<li>
<p>Select Hardware Accelerator: From the “Hardware accelerator” dropdown menu, choose &gt;&gt; T4 GPU and enable toggle for High RAM</p>
</li>
</ul>
<p><img alt="Colab_savruntime" src="../assets/task8a/savColab_chg_ram.png" /></p>
<ul>
<li>Save Settings: Click “Save” to apply the changes.</li>
</ul>
<p><span class="colour" style="color:red">Reminder: </span>Whenever you want to copy the code in Google Colab and run it, be sure to click on + Code to add a new code cell.</p>
<p><img alt="Colab_newcell" src="../assets/task8/newcell.png" /></p>
<p><span class="colour" style="color:red">Reminder: </span>Click the play button to the left of the code, or use the keyboard shortcut "Command/Ctrl+Enter" while the cell is selected.</p>
<p><img alt="Colab_newcell_execute" src="../assets/task8/exec.png" /></p>
<h3 id="set-openai-token-multimodal">Set OpenAI token - MultiModal</h3>
<p><span class="colour" style="color:orange">Note: First, create an account from the <a href="https://platform.openai.com/">OpenAI official website</a>.If you have already completed this step please ignore and jump to Update Google Colab envoirnment section.</span></p>
<ul>
<li>Create a new project API key by browsing to <a href="https://platform.openai.com/api-keys">API Keys web page</a>. Select Create new secret key. The API key is automatically generated. Save the APi Key as we will be using it in the later steps .</li>
</ul>
<p><img alt="GPT1_apiKey" src="../assets/task8c/ap.png" /></p>
<ul>
<li>Within your existing Google Colab notebook navigate to the new “Secrets” section in the sidebar.</li>
</ul>
<p><img alt="HF_GT_sec" src="../assets/task8a/gensec.png" /></p>
<ul>
<li>
<p>Click on “Add a new secret.” Enter the name example: OPENAI_API_KEY and value of the secret(the API key created above). Note: The name is permanent once set. </p>
</li>
<li>
<p>The list of secrets is global across all your notebooks.</p>
</li>
<li>
<p>Use the “Notebook access” toggle to grant or revoke access to a secret for each notebook.</p>
</li>
</ul>
<p><img alt="HF_GT_sec_created_8c" src="../assets/task8c/kei.png" /></p>
<h3 id="update-google-colab-envoirnment-and-install-packages">Update Google Colab envoirnment and install packages</h3>
<p>PDFs often contain tables and other structured data that can be challenging to split accurately using character-based embedding techniques. For PDFs, it's important to extract and chunk all elements, including tables, effectively. We'll accomplish this using the <a href="https://unstructured.io/">Unstructured library</a>, which is specifically designed for handling such tasks. If you have a large collection of PDFs, <a href="https://unstructured.io/">Unstructured</a> is an excellent tool to manage them efficiently.</p>
<ul>
<li>Install relevant libraries including <a href="https://unstructured.io/">Unstructured - ELT tool</a>. Unstructured will partition PDF files by first removing all embedded image blocks. Then it will use a layout model (YOLOX) to get bounding boxes (for tables) as well as titles.</li>
</ul>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="s2">&quot;unstructured[all-docs]&quot;</span> <span class="n">pillow</span> <span class="n">pydantic</span> <span class="n">lxml</span> <span class="n">matplotlib</span> <span class="n">langchain</span> <span class="n">langchain_community</span> <span class="n">chromadb</span> <span class="n">langchain</span><span class="o">-</span><span class="n">experimental</span> <span class="n">langchain_openai</span>
</code></pre></div></td></tr></table></div>
<img alt="unstrc" src="../assets/task6/unstr.png" /></p>
<p><span class="colour" style="color:orange">Note: Make sure to restart your notebook after installing the packages</span></p>
<ul>
<li>Since Google Colab is built on top of an Ubuntu environment, it's necessary to update the Google Colab environment to ensure we can effectively extract information from images or PDFs for analysis and processing.</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="err">!</span><span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">update</span>
</code></pre></div></td></tr></table></div>
<p><img alt="aptu" src="../assets/task6/aptu.png" /></p>
<ul>
<li>Poppler-utils will help us extracting info from our pdf</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="err">!</span><span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">poppler</span><span class="o">-</span><span class="n">utils</span>
</code></pre></div></td></tr></table></div>
<p><img alt="poppler" src="../assets/task6/poppler.png" /></p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="err">!</span><span class="n">sudo</span> <span class="n">apt</span><span class="o">-</span><span class="n">get</span> <span class="n">install</span> <span class="n">libleptonica</span><span class="o">-</span><span class="n">dev</span> <span class="n">tesseract</span><span class="o">-</span><span class="n">ocr</span> <span class="n">libtesseract</span><span class="o">-</span><span class="n">dev</span> <span class="n">python3</span><span class="o">-</span><span class="n">pil</span> <span class="n">tesseract</span><span class="o">-</span><span class="n">ocr</span><span class="o">-</span><span class="n">eng</span> <span class="n">tesseract</span><span class="o">-</span><span class="n">ocr</span><span class="o">-</span><span class="n">script</span><span class="o">-</span><span class="n">latn</span>
</code></pre></div></td></tr></table></div>
<p><img alt="ap12" src="../assets/task6/ap12.png" /></p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">unstructured</span><span class="o">-</span><span class="n">pytesseract</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">tesseract</span><span class="o">-</span><span class="n">ocr</span>
</code></pre></div></td></tr></table></div>
<p><img alt="ap13" src="../assets/task6/ap13.png" /></p>
<ul>
<li>In Google Colab, I noticed some challenges with the NLTK library, so let's set the path correctly to resolve these issues.</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>
<span class="c1"># Set the NLTK_DATA environment variable to the correct path</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;NLTK_DATA&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;/root/nltk_data&#39;</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>Lets make sure we have nltk version 3.9.1 installed</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">upgrade</span> <span class="n">nltk</span>
</code></pre></div></td></tr></table></div>
<p><img alt="ap14" src="../assets/task6/ap14.png" /></p>
<h3 id="pdf-with-table">PDF with table</h3>
<ul>
<li>Let's load our PDF files into Google Colab. For this example, we can use the article titled "Webex Customer Experience Essentials" from the <a href="https://help.webex.com/en-us/article/72sb3r/Webex-Customer-Experience-Essentials">Webex Help Center</a>. You can also <a download="CX-Essentials.pdf" href="../assets/static/CX-Essentials.pdf" target="_blank">download the modified article here</a> as we will be using in the next step.</li>
</ul>
<p><span class="colour" style="color:orange"> Note: To save time and speed up processing in this lab, I have modified the CX-Essentials.pdf file by reducing it to only a few pages. You can download this version from the modified link provided above. </span></p>
<ul>
<li>Within Google Colab, Click on Folder and create a new folder called "dat"</li>
</ul>
<p><img alt="HL_Format_fold" src="../assets/task8a/fold.png" /></p>
<ul>
<li>Click on [...], select Upload</li>
</ul>
<p><img alt="HL_Format_fold_created" src="../assets/task8a/dc_created.png" /></p>
<ul>
<li>Choose your CX-Essentials.pdf file and click Open</li>
</ul>
<p><img alt="r8" src="../assets/task6/8.png" /></p>
<ul>
<li>Let's process our PDF document by splitting it into smaller, manageable chunks based on titles, extracting images, and handling text in a way that ensures the chunks are neither too large nor too small. We will store the extracted elements (text, images, etc.) in the pdf_elements variable, and images are saved in the specified path(image_path). To understand more about <a href="https://docs.unstructured.io/open-source/core-functionality/partitioning#partition-csv">unstructured partition_pdf click here</a> </li>
</ul>
<p>Unstructured will partition PDF files by first extracting embedded images if specified. It then processes the document's layout, dividing the content into structured elements such as titles, tables, and paragraphs based on the layout and text structure. For more detailed layout analysis, it may use advanced models like YOLOX to identify and extract bounding boxes for elements like tables and titles. This allows for the precise extraction and organization of text and images, making the content more suitable for further analysis and processing.</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">unstructured.partition.pdf</span> <span class="kn">import</span> <span class="n">partition_pdf</span>
<span class="n">image_path</span> <span class="o">=</span> <span class="s2">&quot;./content/images&quot;</span>
<span class="n">pdf_elements</span> <span class="o">=</span> <span class="n">partition_pdf</span><span class="p">(</span>
    <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;/content/dat/CX-Essentials.pdf&quot;</span><span class="p">,</span>
    <span class="n">chunking_strategy</span><span class="o">=</span><span class="s2">&quot;by_title&quot;</span><span class="p">,</span>
    <span class="n">extract_images_in_pdf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="c1"># extract_image_block_types=[&quot;Image&quot;, &quot;Table&quot;],</span>
    <span class="n">max_characters</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="c1"># Sets the maximum number of characters</span>
    <span class="n">new_after_n_chars</span><span class="o">=</span><span class="mi">2800</span><span class="p">,</span> <span class="c1"># Character threshold after which a new chunk will start. Ensures  chunks are created before the max_characters limit is reached</span>
    <span class="n">combine_text_under_n_chars</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="c1">#If chunk of text is smaller than 2000 characters, it should be combined with the following chunk to create a more substantial piece </span>
    <span class="n">image_output_dir_path</span><span class="o">=</span><span class="n">image_path</span>
<span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p><img alt="r9" src="../assets/task6/9.png" /></p>
<p><span class="colour" style="color:orange"> Note: This process may take a few minutes to complete as we are extracting information from the PDF.</span></p>
<ul>
<li>You'll also notice that a folder has been created containing all the extracted images.</li>
</ul>
<p><img alt="r11" src="../assets/task6/11.png" /></p>
<ul>
<li>To see different elements fr om our pdf we can look into the variable</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">pdf_elements</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p><img alt="r10" src="../assets/task6/10.png" /></p>
<ul>
<li>Lets categorize extracted elements from a PDF into two types: text elements and table elements. </li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="c1"># Categorize elements by type</span>
<span class="k">def</span> <span class="nf">categorize_elements</span><span class="p">(</span><span class="n">raw_pdf_elements</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    raw_pdf_elements: List of unstructured.documents.elements</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tables</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">texts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">raw_pdf_elements</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;unstructured.documents.elements.Table&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">element</span><span class="p">)):</span>
            <span class="n">tables</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">element</span><span class="p">))</span>
        <span class="k">elif</span> <span class="s2">&quot;unstructured.documents.elements.CompositeElement&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">element</span><span class="p">)):</span>
            <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">element</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">texts</span><span class="p">,</span> <span class="n">tables</span>

<span class="n">texts</span><span class="p">,</span> <span class="n">tables</span> <span class="o">=</span> <span class="n">categorize_elements</span><span class="p">(</span><span class="n">pdf_elements</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">texts</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p><img alt="texts" src="../assets/task6/text.png" /></p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">tables</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p><img alt="table" src="../assets/task6/table.png" /></p>
<h3 id="lets-now-create-summary-from-our-data-by-passing-the-info-to-multimodal">Lets now create summary from our data by passing the info to Multimodal</h3>
<p><span class="colour" style="color:orange">Note: We will be using GPT-4o as our Multimodal to create summary </span></p>
<ul>
<li>Let's retrieve an OpenAI API key and set it as an environment variable within the Colab environment</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">userdata</span>
<span class="n">OPENAI_API_TOKEN</span><span class="o">=</span><span class="n">userdata</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;OPENAI_API_KEY&#39;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">OPENAI_API_TOKEN</span>
<span class="n">load_dotenv</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>Lets create a summary for our text element</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatVertexAI</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">VertexAI</span>
<span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain.schema.output_parser</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain_core.messages</span> <span class="kn">import</span> <span class="n">AIMessage</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnableLambda</span>
<span class="kn">from</span> <span class="nn">langchain_core.output_parsers</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="c1"># Generate summaries of text elements</span>
<span class="k">def</span> <span class="nf">generate_text_summaries</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">tables</span><span class="p">,</span> <span class="n">summarize_texts</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Summarize text elements</span>
<span class="sd">    texts: List of str</span>
<span class="sd">    tables: List of str</span>
<span class="sd">    summarize_texts: Bool to summarize texts</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Prompt</span>
    <span class="n">prompt_text</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are an assistant tasked with summarizing tables and text for retrieval. </span><span class="se">\</span>
<span class="s2">    These summaries will be embedded and used to retrieve the raw text or table elements. </span><span class="se">\</span>
<span class="s2">    Give a concise summary of the table or text that is well-optimized for retrieval. Table </span><span class="se">\</span>
<span class="s2">    or text: </span><span class="si">{element}</span><span class="s2"> &quot;&quot;&quot;</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">prompt_text</span><span class="p">)</span>
    <span class="n">empty_response</span> <span class="o">=</span> <span class="n">RunnableLambda</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">AIMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s2">&quot;Error processing document&quot;</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># Model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o&quot;</span><span class="p">)</span>
    <span class="n">summarize_chain</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;element&quot;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">}</span> <span class="o">|</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">model</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>

    <span class="c1"># Initialize empty summaries</span>
    <span class="n">text_summaries</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">table_summaries</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Apply to text if texts are provided and summarization is requested</span>
    <span class="k">if</span> <span class="n">texts</span> <span class="ow">and</span> <span class="n">summarize_texts</span><span class="p">:</span>
        <span class="n">text_summaries</span> <span class="o">=</span> <span class="n">summarize_chain</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;max_concurrency&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>
    <span class="k">elif</span> <span class="n">texts</span><span class="p">:</span>
        <span class="n">text_summaries</span> <span class="o">=</span> <span class="n">texts</span>

    <span class="c1"># Apply to tables if tables are provided</span>
    <span class="k">if</span> <span class="n">tables</span><span class="p">:</span>
        <span class="n">table_summaries</span> <span class="o">=</span> <span class="n">summarize_chain</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">tables</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;max_concurrency&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span>

    <span class="k">return</span> <span class="n">text_summaries</span><span class="p">,</span> <span class="n">table_summaries</span>


<span class="c1"># Get text, table summaries</span>
<span class="n">text_summaries</span><span class="p">,</span> <span class="n">table_summaries</span> <span class="o">=</span> <span class="n">generate_text_summaries</span><span class="p">(</span>
    <span class="n">texts</span><span class="p">,</span> <span class="n">tables</span><span class="p">,</span> <span class="n">summarize_texts</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>Now lets create summary for our images </li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">base64</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">from</span> <span class="nn">langchain_core.messages</span> <span class="kn">import</span> <span class="n">HumanMessage</span>

<span class="k">def</span> <span class="nf">encode_image</span><span class="p">(</span><span class="n">image_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Getting the base64 string&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">image_file</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">image_file</span><span class="o">.</span><span class="n">read</span><span class="p">())</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">image_summarize</span><span class="p">(</span><span class="n">img_base64</span><span class="p">,</span> <span class="n">prompt</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Make image summary&quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o&quot;</span><span class="p">)</span>
    <span class="n">msg</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">HumanMessage</span><span class="p">(</span>
                <span class="n">content</span><span class="o">=</span><span class="p">[</span>
                    <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">},</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;image_url&quot;</span><span class="p">,</span>
                        <span class="s2">&quot;image_url&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;data:image/jpeg;base64,</span><span class="si">{</span><span class="n">img_base64</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">},</span>
                    <span class="p">},</span>
                <span class="p">]</span>
            <span class="p">)</span>
        <span class="p">]</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">msg</span><span class="o">.</span><span class="n">content</span>

<span class="k">def</span> <span class="nf">generate_img_summaries</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate summaries and base64 encoded strings for images</span>
<span class="sd">    path: Path to list of .jpg files extracted by Unstructured</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Store base64 encoded images</span>
    <span class="n">img_base64_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Store image summaries</span>
    <span class="n">image_summaries</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Prompt</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are an assistant tasked with summarizing images for retrieval. </span><span class="se">\</span>
<span class="s2">    These summaries will be embedded and used to retrieve the raw image. </span><span class="se">\</span>
<span class="s2">    Give a concise summary of the image that is well optimized for retrieval.&quot;&quot;&quot;</span>

    <span class="c1"># Apply to images</span>
    <span class="k">for</span> <span class="n">img_file</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">img_file</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.jpg&quot;</span><span class="p">):</span>
            <span class="n">img_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">img_file</span><span class="p">)</span>
            <span class="n">base64_image</span> <span class="o">=</span> <span class="n">encode_image</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
            <span class="n">img_base64_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">base64_image</span><span class="p">)</span>
            <span class="n">image_summaries</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_summarize</span><span class="p">(</span><span class="n">base64_image</span><span class="p">,</span> <span class="n">prompt</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">img_base64_list</span><span class="p">,</span> <span class="n">image_summaries</span>

<span class="n">fpath</span> <span class="o">=</span> <span class="s2">&quot;/content/figures&quot;</span>
<span class="c1"># Image summaries</span>
<span class="n">img_base64_list</span><span class="p">,</span> <span class="n">image_summaries</span> <span class="o">=</span> <span class="n">generate_img_summaries</span><span class="p">(</span><span class="n">fpath</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="n">image_summaries</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
<img alt="Sum1" src="../assets/task6/sum1.png" /></p>
<p><img alt="Sum2" src="../assets/task6/sum2.png" /></p>
<h3 id="lets-now-create-our-multivector-retriever-and-rag-system-incl-storing-summary-embeddings-in-vector-db">Lets now create our MultiVector Retriever and RAG system - incl storing summary embeddings in Vector DB</h3>
<p><img alt="Sum3" src="../assets/task6/sum3.png" /></p>
<h4 id="create-our-multivector-retriever">Create our MultiVector Retriever</h4>
<ul>
<li>Lets install packages for chroma our inmemory db and MultiVectorRetriever</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">uuid</span>
<span class="kn">from</span> <span class="nn">langchain.retrievers.multi_vector</span> <span class="kn">import</span> <span class="n">MultiVectorRetriever</span>
<span class="kn">from</span> <span class="nn">langchain.storage</span> <span class="kn">import</span> <span class="n">InMemoryStore</span>
<span class="kn">from</span> <span class="nn">langchain_community.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
<span class="kn">from</span> <span class="nn">langchain_core.documents</span> <span class="kn">import</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
</code></pre></div></td></tr></table></div>
<ul>
<li>Let's create our function to build a multi-vector retriever. We will use OpenAI embeddings and create a Chroma vector store to index our summaries. This function will allow us to index summaries of texts, tables, and images, while retrieving the raw data (texts, tables, or images) based on those summaries. By leveraging the OpenAI embeddings, our Chroma vector store will effectively handle and retrieve multimodal content.</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">uuid</span>

<span class="kn">from</span> <span class="nn">langchain.embeddings</span> <span class="kn">import</span> <span class="n">VertexAIEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain.retrievers.multi_vector</span> <span class="kn">import</span> <span class="n">MultiVectorRetriever</span>
<span class="kn">from</span> <span class="nn">langchain.schema.document</span> <span class="kn">import</span> <span class="n">Document</span>
<span class="kn">from</span> <span class="nn">langchain.storage</span> <span class="kn">import</span> <span class="n">InMemoryStore</span>
<span class="kn">from</span> <span class="nn">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>


<span class="k">def</span> <span class="nf">create_multi_vector_retriever</span><span class="p">(</span>
    <span class="n">vectorstore</span><span class="p">,</span> <span class="n">text_summaries</span><span class="p">,</span> <span class="n">texts</span><span class="p">,</span> <span class="n">table_summaries</span><span class="p">,</span> <span class="n">tables</span><span class="p">,</span> <span class="n">image_summaries</span><span class="p">,</span> <span class="n">images</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create retriever that indexes summaries, but returns raw images or texts</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Initialize the storage layer</span>
    <span class="n">store</span> <span class="o">=</span> <span class="n">InMemoryStore</span><span class="p">()</span>
    <span class="n">id_key</span> <span class="o">=</span> <span class="s2">&quot;doc_id&quot;</span>

    <span class="c1"># Create the multi-vector retriever</span>
    <span class="n">retriever</span> <span class="o">=</span> <span class="n">MultiVectorRetriever</span><span class="p">(</span>
        <span class="n">vectorstore</span><span class="o">=</span><span class="n">vectorstore</span><span class="p">,</span>
        <span class="n">docstore</span><span class="o">=</span><span class="n">store</span><span class="p">,</span>
        <span class="n">id_key</span><span class="o">=</span><span class="n">id_key</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># Helper function to add documents to the vectorstore and docstore</span>
    <span class="k">def</span> <span class="nf">add_documents</span><span class="p">(</span><span class="n">retriever</span><span class="p">,</span> <span class="n">doc_summaries</span><span class="p">,</span> <span class="n">doc_contents</span><span class="p">):</span>
        <span class="n">doc_ids</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">uuid</span><span class="o">.</span><span class="n">uuid4</span><span class="p">())</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">doc_contents</span><span class="p">]</span>
        <span class="n">summary_docs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">Document</span><span class="p">(</span><span class="n">page_content</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="n">id_key</span><span class="p">:</span> <span class="n">doc_ids</span><span class="p">[</span><span class="n">i</span><span class="p">]})</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">doc_summaries</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">retriever</span><span class="o">.</span><span class="n">vectorstore</span><span class="o">.</span><span class="n">add_documents</span><span class="p">(</span><span class="n">summary_docs</span><span class="p">)</span>
        <span class="n">retriever</span><span class="o">.</span><span class="n">docstore</span><span class="o">.</span><span class="n">mset</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">doc_ids</span><span class="p">,</span> <span class="n">doc_contents</span><span class="p">)))</span>

    <span class="c1"># Add texts, tables, and images</span>
    <span class="c1"># Check that text_summaries is not empty before adding</span>
    <span class="k">if</span> <span class="n">text_summaries</span><span class="p">:</span>
        <span class="n">add_documents</span><span class="p">(</span><span class="n">retriever</span><span class="p">,</span> <span class="n">text_summaries</span><span class="p">,</span> <span class="n">texts</span><span class="p">)</span>
    <span class="c1"># Check that table_summaries is not empty before adding</span>
    <span class="k">if</span> <span class="n">table_summaries</span><span class="p">:</span>
        <span class="n">add_documents</span><span class="p">(</span><span class="n">retriever</span><span class="p">,</span> <span class="n">table_summaries</span><span class="p">,</span> <span class="n">tables</span><span class="p">)</span>
    <span class="c1"># Check that image_summaries is not empty before adding</span>
    <span class="k">if</span> <span class="n">image_summaries</span><span class="p">:</span>
        <span class="n">add_documents</span><span class="p">(</span><span class="n">retriever</span><span class="p">,</span> <span class="n">image_summaries</span><span class="p">,</span> <span class="n">images</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">retriever</span>

<span class="c1"># The vectorstore to use to index the summaries</span>
<span class="n">vectorstore</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">(</span>
    <span class="n">collection_name</span><span class="o">=</span><span class="s2">&quot;mm_webexone_cl&quot;</span><span class="p">,</span>
    <span class="n">embedding_function</span><span class="o">=</span><span class="n">OpenAIEmbeddings</span><span class="p">(),</span>
    <span class="c1"># embedding_function=VertexAIEmbeddings(model_name=&quot;textembedding-gecko@latest&quot;),</span>
<span class="p">)</span>

<span class="c1"># Create retriever</span>
<span class="n">retriever_multi_vector_img</span> <span class="o">=</span> <span class="n">create_multi_vector_retriever</span><span class="p">(</span>
    <span class="n">vectorstore</span><span class="p">,</span>
    <span class="n">text_summaries</span><span class="p">,</span>
    <span class="n">texts</span><span class="p">,</span>
    <span class="n">table_summaries</span><span class="p">,</span>
    <span class="n">tables</span><span class="p">,</span>
    <span class="n">image_summaries</span><span class="p">,</span>
    <span class="n">img_base64_list</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></td></tr></table></div>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="n">retriever_multi_vector_img</span>
</code></pre></div></td></tr></table></div>
<p><img alt="Sum31" src="../assets/task6/sum31.png" /></p>
<h4 id="create-our-rag-multimodal">Create our RAG (Multimodal)</h4>
<ul>
<li>Lets create a multi_modal_rag_chain(retriever). This pipeline integrates both text and image data to enhance the quality of responses generated by an AI model</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  1</span>
<span class="normal">  2</span>
<span class="normal">  3</span>
<span class="normal">  4</span>
<span class="normal">  5</span>
<span class="normal">  6</span>
<span class="normal">  7</span>
<span class="normal">  8</span>
<span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">base64</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span> <span class="k">as</span> <span class="n">PILImage</span>
<span class="kn">from</span> <span class="nn">langchain.schema.runnable</span> <span class="kn">import</span> <span class="n">RunnableLambda</span><span class="p">,</span> <span class="n">RunnablePassthrough</span>


<span class="k">def</span> <span class="nf">looks_like_base64</span><span class="p">(</span><span class="n">sb</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if the string looks like base64&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="s2">&quot;^[A-Za-z0-9+/]+[=]{0,2}$&quot;</span><span class="p">,</span> <span class="n">sb</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

<span class="k">def</span> <span class="nf">is_image_data</span><span class="p">(</span><span class="n">b64data</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Check if the base64 data is an image by looking at the start of the data</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">image_signatures</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sa">b</span><span class="s2">&quot;</span><span class="se">\xFF\xD8\xFF</span><span class="s2">&quot;</span><span class="p">:</span> <span class="s2">&quot;jpg&quot;</span><span class="p">,</span>
        <span class="sa">b</span><span class="s2">&quot;</span><span class="se">\x89\x50\x4E\x47\x0D\x0A\x1A\x0A</span><span class="s2">&quot;</span><span class="p">:</span> <span class="s2">&quot;png&quot;</span><span class="p">,</span>
        <span class="sa">b</span><span class="s2">&quot;</span><span class="se">\x47\x49\x46\x38</span><span class="s2">&quot;</span><span class="p">:</span> <span class="s2">&quot;gif&quot;</span><span class="p">,</span>
        <span class="sa">b</span><span class="s2">&quot;</span><span class="se">\x52\x49\x46\x46</span><span class="s2">&quot;</span><span class="p">:</span> <span class="s2">&quot;webp&quot;</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">header</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">b64data</span><span class="p">)[:</span><span class="mi">8</span><span class="p">]</span>  <span class="c1"># Decode and get the first 8 bytes</span>
        <span class="k">for</span> <span class="n">sig</span><span class="p">,</span> <span class="nb">format</span> <span class="ow">in</span> <span class="n">image_signatures</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">header</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">sig</span><span class="p">):</span>
                <span class="k">return</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>


<span class="k">def</span> <span class="nf">resize_base64_image</span><span class="p">(</span><span class="n">base64_string</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Resize an image encoded as a Base64 string</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Decode the Base64 string</span>
    <span class="n">img_data</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">base64_string</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">PILImage</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">img_data</span><span class="p">))</span>

    <span class="c1"># Resize the image</span>
    <span class="n">resized_img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">PILImage</span><span class="o">.</span><span class="n">LANCZOS</span><span class="p">)</span>

    <span class="c1"># Save the resized image to a bytes buffer</span>
    <span class="n">buffered</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">resized_img</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">buffered</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="n">img</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>

    <span class="c1"># Encode the resized image to Base64</span>
    <span class="k">return</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">buffered</span><span class="o">.</span><span class="n">getvalue</span><span class="p">())</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">split_image_text_types</span><span class="p">(</span><span class="n">docs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Split base64-encoded images and texts</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">b64_images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">texts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
        <span class="c1"># Check if the document is of type Document and extract page_content if so</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">Document</span><span class="p">):</span>
            <span class="n">doc</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">page_content</span>
        <span class="k">if</span> <span class="n">looks_like_base64</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_image_data</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
            <span class="n">doc</span> <span class="o">=</span> <span class="n">resize_base64_image</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1300</span><span class="p">,</span> <span class="mi">600</span><span class="p">))</span>
            <span class="n">b64_images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">texts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">b64_images</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;images&quot;</span><span class="p">:</span> <span class="n">b64_images</span><span class="p">[:</span><span class="mi">1</span><span class="p">],</span> <span class="s2">&quot;texts&quot;</span><span class="p">:</span> <span class="p">[]}</span>
    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;images&quot;</span><span class="p">:</span> <span class="n">b64_images</span><span class="p">,</span> <span class="s2">&quot;texts&quot;</span><span class="p">:</span> <span class="n">texts</span><span class="p">}</span>

<span class="k">def</span> <span class="nf">img_prompt_func</span><span class="p">(</span><span class="n">data_dict</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Join the context into a single string</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">formatted_texts</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;context&quot;</span><span class="p">][</span><span class="s2">&quot;texts&quot;</span><span class="p">])</span>
    <span class="n">messages</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Adding the text for analysis</span>
    <span class="n">text_message</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span>
        <span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="p">(</span>
            <span class="s2">&quot;You are an AI scientist tasking with providing factual answers.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;You will be given a mixed of text, tables, and image(s) usually of charts or graphs.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;Use this information to provide answers related to the user question. </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;User-provided question: </span><span class="si">{</span><span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;question&#39;</span><span class="p">]</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">&quot;</span>
            <span class="s2">&quot;Text and / or tables:</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">formatted_texts</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">),</span>
    <span class="p">}</span>
    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text_message</span><span class="p">)</span>
    <span class="c1"># Adding image(s) to the messages if present</span>
    <span class="k">if</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;context&quot;</span><span class="p">][</span><span class="s2">&quot;images&quot;</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="p">[</span><span class="s2">&quot;context&quot;</span><span class="p">][</span><span class="s2">&quot;images&quot;</span><span class="p">]:</span>
            <span class="n">image_message</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;image_url&quot;</span><span class="p">,</span>
                <span class="s2">&quot;image_url&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;url&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;data:image/jpeg;base64,</span><span class="si">{</span><span class="n">image</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">},</span>
            <span class="p">}</span>
            <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_message</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">HumanMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="n">messages</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">multi_modal_rag_chain</span><span class="p">(</span><span class="n">retriever</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Multi-modal RAG chain</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-4o&quot;</span><span class="p">)</span>

    <span class="c1"># RAG pipeline</span>
    <span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">{</span>
            <span class="s2">&quot;context&quot;</span><span class="p">:</span> <span class="n">retriever</span> <span class="o">|</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">split_image_text_types</span><span class="p">),</span>
            <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">(),</span>
        <span class="p">}</span>
        <span class="o">|</span> <span class="n">RunnableLambda</span><span class="p">(</span><span class="n">img_prompt_func</span><span class="p">)</span>
        <span class="o">|</span> <span class="n">model</span>
        <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">chain</span>

<span class="c1"># Create RAG chain</span>
<span class="n">chain_multimodal_rag</span> <span class="o">=</span> <span class="n">multi_modal_rag_chain</span><span class="p">(</span><span class="n">retriever_multi_vector_img</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<h3 id="lets-query-our-multimodal-retriever">Lets Query our Multimodal Retriever</h3>
<ul>
<li>Open your CX-Essentials.pdf, and let's try querying some information from it.</li>
</ul>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;how can I Upgrade call queue from Customer Experience Basic to Customer Experience Essentials. explain images if any there as well&quot;&quot;&quot;</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">chain_multimodal_rag</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;how can I Upgrade call queue from Customer ExperienceBasic to Customer Experience Essentials. explain images if any there as well&quot;&quot;&quot;</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">retriever_multi_vector_img</span><span class="o">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="c1"># To display the image</span>
<span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">looks_like_base64</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span> <span class="ow">and</span> <span class="n">is_image_data</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
        <span class="n">image_data</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64decode</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
        <span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">image_data</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
* You'll notice that in our multimodal RAG system, I'm now able to retrieve images, tables, and text seamlessly.</p>
<p><img alt="Sumaryyyy" src="../assets/task6/yy.png" /></p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Omer Ilyas - Technical Marketing Engineer - oilyas@cisco.com
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/omerilyas4ccie/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.sections", "toc.integrate", "navigation.tabs.sticky", "navigation.indexes", "navigation.instant", "navigation.top", "search.suggest", "search.highlight", "content.code.copy", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
    
  </body>
</html>